[
  {
    "id": "http://arxiv.org/abs/2512.10953v1",
    "title": "Bidirectional Normalizing Flow: From Data to Noise and Back",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.10953v1",
    "summary": "Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation (\"1-NFE\") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Yiyang Lu",
    "category": "Science",
    "originalContent": "Normalizing Flows (NFs) have been established as a principled framework for generative modeling. Standard NFs consist of a forward process and a reverse process: the forward process maps data to noise, while the reverse process generates samples by inverting it. Typical NF forward transformations are constrained by explicit invertibility, ensuring that the reverse process can serve as their exact analytic inverse. Recent developments in TARFlow and its variants have revitalized NF methods by combining Transformers and autoregressive flows, but have also exposed causal decoding as a major bottleneck. In this work, we introduce Bidirectional Normalizing Flow ($\\textbf{BiFlow}$), a framework that removes the need for an exact analytic inverse. BiFlow learns a reverse model that approximates the underlying noise-to-data inverse mapping, enabling more flexible loss functions and architectures. Experiments on ImageNet demonstrate that BiFlow, compared to its causal decoding counterpart, improves generation quality while accelerating sampling by up to two orders of magnitude. BiFlow yields state-of-the-art results among NF-based methods and competitive performance among single-evaluation (\"1-NFE\") methods. Following recent encouraging progress on NFs, we hope our work will draw further attention to this classical paradigm.",
    "titleJa": "双方向正規化フロー：データからノイズへ、そして戻る",
    "summaryJa": "研究背景として、正規化フロー（NFs）は生成モデリングの基礎的な枠組みですが、標準的なNFは、データからノイズへの順方向変換が厳密な可逆性を持つ必要があり、逆方向変換はその解析的な逆関数として機能します。しかし、Transformerと自己回帰フローを組み合わせた最近の手法（TARFlowなど）では、因果デコーディングが大きなボトルネックとなっていました。本研究では、この解析的な逆関数の制約を不要とする新しい枠組み「双方向正規化フロー（BiFlow）」を提案しています。BiFlowは、ノイズからデータへの逆マッピングを近似的に学習することで、より柔軟な損失関数やアーキテクチャの採用を可能にしました。ImageNetでの実験結果に基づき、BiFlowは因果デコーディングを行う既存手法と比較して、生成品質を向上させつつ、サンプリング速度を最大で二桁向上させることに成功しました。BiFlowは、NFベースの手法の中で最先端の結果を示し、単一評価の手法の中でも高い競争力を有しています。本研究は、この古典的なパラダイムへのさらなる注目を促すものです。",
    "explanationJa": "従来の制約を外し、ノイズからのデータ生成を高速かつ高品質化した新しいAIモデルです。",
    "translationJa": "正規化フロー（Normalizing Flows, NFs）は、生成モデリングのための確立された原理的な枠組みとして知られています。標準的なNFは、順方向プロセスと逆方向プロセスで構成されます。順方向プロセスがデータをノイズにマッピングするのに対し、逆方向プロセスはこれを反転させることでサンプルを生成します。従来のNFにおける順方向変換は、逆方向プロセスがその厳密な解析的な逆関数として機能することを確実にするため、明示的な可逆性によって制約されてきました。Transformerと自己回帰フローを組み合わせたTARFlowなどの最近の開発により、NF手法は再び活性化しましたが、同時に因果デコーディングが主要なボトルネックとなっていることも露呈しました。\n\n本研究では、厳密な解析的な逆関数を必要としない枠組みである双方向正規化フロー（BiFlow）を導入します。BiFlowは、根底にあるノイズからデータへの逆マッピングを近似する逆モデルを直接学習します。これにより、研究者はより柔軟な損失関数とアーキテクチャを採用できるようになります。ImageNetを用いた実験結果は、BiFlowが、その因果デコーディングを行う対応手法と比較して、生成品質を向上させるとともに、サンプリングを最大で二桁（百倍）加速させることを示しています。BiFlowは、NFベースの手法の中で最先端の結果をもたらし、単一の関数評価（1-NFE）で行う手法の中でも競争力のある性能を発揮します。我々の研究が、近年再び勢いを増しているこの古典的なパラダイムに、さらなる関心を集めることを期待しています。",
    "insightJa": "この技術により、高速かつ高品質な画像やデータ生成が可能になり、ゲーム開発におけるリアルタイムアセット生成や、医療分野での高精度なデータ合成シミュレーションが加速されます。特に、大規模モデルの効率的な運用において重要な進歩となります。",
    "recommendedBooks": [
      "生成AI 理論",
      "正規化フロー 機械学習",
      "Transformerと自己回帰モデル"
    ],
    "tags": [
      "Normalizing Flows",
      "Generative AI",
      "Machine Learning",
      "BiFlow",
      "Image Generation"
    ],
    "imageUrl": "https://images.pexels.com/photos/17497303/pexels-photo-17497303.png?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10952v1",
    "title": "Hierarchical Dataset Selection for High-Quality Data Sharing",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.10952v1",
    "summary": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Xiaona Zhou",
    "category": "Science",
    "originalContent": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "titleJa": "高品質なデータ共有のための階層的データセット選択",
    "summaryJa": "現代の機械学習の成功は、高品質な訓練データへのアクセスに大きく依存しています。本研究では、公共のリポジトリからのデータ取得や機関間での共有など、現実世界の多くのシナリオにおいて、データがその関連性、品質、有用性において異なる個別のデータセットとして組織化されることに着目しました。有用なデータセットを探索するリポジトリや機関の選択、モデルの訓練に組み込むデータセットの選択は非常に重要です。既存の方法では、個々のサンプルを選択し、すべてのデータを等しく関連するものとして扱い、データセット間やそのソースの違いを無視していました。そこで本研究では、リソース制約下でダウンストリームの性能を向上させるために、大規模で異質なプールからデータセット全体を選択するという、データセット選択のタスクを形式化しました。そして、データセットとグループ（コレクション、機関など）の両方のレベルで有用性をモデル化し、限られた観測からの効率的な一般化を可能にするデータセット選択法DaSHを提案しました。Digit-FiveやDomainNetといった公開ベンチマークにおいて、DaSHは最先端のデータ選択ベースラインを最大26.2%上回る精度を示し、探索に必要なステップ数も大幅に削減しました。DaSHは、リソースが少ない環境や関連するデータセットがない状況でも堅牢であり、実用的なマルチソース学習ワークフローにおけるスケーラブルで適応的なデータセット選択に適しています。",
    "explanationJa": "機械学習において、どのデータセットを使うかを賢く選ぶことで、より良い結果が得られるようにする方法についての研究です。",
    "translationJa": "現代の機械学習の発展は、高品質な学習データへのアクセスに不可欠です。現実の多くの場面では、公共のリポジトリからデータを取得したり、複数の機関でデータを共有したりする際に、データの関連性、品質、有用性が異なる個別のデータセットとして構成されます。そのため、どのリポジトリや機関から有用なデータセットを探すか、そしてどのデータセットをモデルの学習に利用するかという選択が非常に重要になります。しかし、既存の多くの手法では、個々のデータサンプルを選択するだけで、全てのデータを同等に扱い、データセット間やその提供元の違いを考慮していませんでした。そこで本研究では、リソースに制約がある状況下で、大規模かつ多様なデータセット群から最適なデータセットを選択し、機械学習モデルの性能を向上させる「データセット選択」という課題を明確に定義しました。そして、データセットとグループ（例えば、コレクションや研究機関）の両方のレベルでデータの有用性を評価する「DaSH（Dataset Selection via Hierarchies）」という新しいデータセット選択手法を提案しました。この手法により、限られた情報からでも効率的に適切なデータセットを選択できるようになります。実験の結果、Digit-FiveやDomainNetといった公開データセットを用いた評価において、DaSHは既存の最先端の手法と比較して、精度が最大26.2%向上し、データ探索に必要なステップ数も大幅に削減できることが示されました。また、リソースが限られた状況や、関連性の高いデータセットが少ない状況でもDaSHは有効であり、実用的なマルチソース学習のワークフローにおいて、柔軟かつスケーラブルなデータセット選択を実現できることが示唆されました。",
    "insightJa": "この技術により、企業は様々な場所から集めたデータの中から、自社のビジネスに最適なデータを選び出して活用できるようになり、より効率的な意思決定やサービス改善につながる可能性があります。",
    "recommendedBooks": [
      "データサイエンス 入門",
      "機械学習 実践",
      "ビッグデータ 分析"
    ],
    "tags": [
      "Dataset Selection",
      "Machine Learning",
      "Data Quality",
      "Hierarchical Learning",
      "Multi-Source Learning"
    ],
    "imageUrl": "https://images.pexels.com/photos/8294824/pexels-photo-8294824.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10949v1",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.10949v1",
    "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "publishedAt": "2025-12-11T18:59:52Z",
    "author": "Yiwen Tang",
    "category": "Science",
    "originalContent": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "titleJa": "テキストから3D生成における強化学習の準備はできているか？進歩的な調査",
    "summaryJa": "本研究では、テキストから3Dモデルを自動生成する際に、強化学習（RL）を適用することの課題と可能性を調査します。3Dオブジェクトの複雑さから、RLの適用は困難でしたが、報酬設計、RLアルゴリズム、ベンチマーク、高度なRLパラダイムなどの多角的な視点から体系的な分析を行いました。その結果、人間の好みに合わせた報酬設計の重要性、トークンレベルの最適化の効果、そして階層的な3D生成手法の有効性が明らかになりました。これらの知見を基に、RLを活用した新たなテキストから3Dモデル生成モデルAR3D-R1を開発しました。この研究は、3D生成におけるRLの活用に関する洞察を提供し、今後の発展に貢献することが期待されます。",
    "explanationJa": "テキストから3Dモデルを作る際に、強化学習という技術がどこまで使えるのかを調べた研究です。",
    "translationJa": "強化学習（RL）は、大規模言語モデルやマルチモーダルモデルで有効であることが示されていますが、最近では2D画像生成の強化にも応用されています。しかし、3Dオブジェクトの空間的な複雑さから、3D生成へのRLの適用はほとんど探求されていません。3Dオブジェクトは、全体的に一貫した形状と、きめ細かい局所的なテクスチャを必要とするため、報酬設計とRLアルゴリズムに非常に敏感になります。これらの課題に対処するため、本研究では、テキストから3Dの自己回帰的な生成に対するRLについて、いくつかの側面から体系的な調査を行います。(1)報酬設計：報酬の次元とモデルの選択を評価し、人間の好みに合わせることが重要であること、そして一般的なマルチモーダルモデルが3D属性に対してロバストなシグナルを提供することを示します。(2)RLアルゴリズム：GRPOのバリアントを研究し、トークンレベルの最適化の有効性を強調し、さらにトレーニングデータと反復のスケールを調査します。(3)テキストから3Dベンチマーク：既存のベンチマークは、3D生成モデルにおける暗黙的な推論能力を測定できないため、MME-3DRを導入します。(4)高度なRLパラダイム：3D生成の自然な階層構造に触発されて、専用の報酬アンサンブルを通じてグローバルからローカルへの階層的な3D生成を最適化するHi-GRPOを提案します。これらの洞察に基づいて、粗い形状からテクスチャの洗練まで、RLで強化された最初のテキストから3DモデルであるAR3D-R1を開発しました。この研究が、3D生成のためのRL駆動型推論への洞察を提供することを願っています。",
    "insightJa": "テキストから3Dモデルを自動生成する技術は、エンターテインメントやデザイン分野での活用が期待され、私たちの生活やビジネスに大きな影響を与える可能性があります。",
    "recommendedBooks": [
      "3Dモデリング 入門",
      "強化学習 実践",
      "画像生成AI"
    ],
    "tags": [
      "Text-to-3D",
      "Reinforcement Learning",
      "3D Generation",
      "MME-3DR",
      "AR3D-R1"
    ],
    "imageUrl": "https://images.pexels.com/photos/17483874/pexels-photo-17483874.png?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10946v1",
    "title": "ImplicitRDP: An End-to-End Visual-Force Diffusion Policy with Structural Slow-Fast Learning",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.10946v1",
    "summary": "Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.",
    "publishedAt": "2025-12-11T18:59:46Z",
    "author": "Wendi Chen",
    "category": "Science",
    "originalContent": "Human-level contact-rich manipulation relies on the distinct roles of two key modalities: vision provides spatially rich but temporally slow global context, while force sensing captures rapid, high-frequency local contact dynamics. Integrating these signals is challenging due to their fundamental frequency and informational disparities. In this work, we propose ImplicitRDP, a unified end-to-end visual-force diffusion policy that integrates visual planning and reactive force control within a single network. We introduce Structural Slow-Fast Learning, a mechanism utilizing causal attention to simultaneously process asynchronous visual and force tokens, allowing the policy to perform closed-loop adjustments at the force frequency while maintaining the temporal coherence of action chunks. Furthermore, to mitigate modality collapse where end-to-end models fail to adjust the weights across different modalities, we propose Virtual-target-based Representation Regularization. This auxiliary objective maps force feedback into the same space as the action, providing a stronger, physics-grounded learning signal than raw force prediction. Extensive experiments on contact-rich tasks demonstrate that ImplicitRDP significantly outperforms both vision-only and hierarchical baselines, achieving superior reactivity and success rates with a streamlined training pipeline. Code and videos will be publicly available at https://implicit-rdp.github.io.",
    "titleJa": "ImplicitRDP：構造的な遅速学習を用いたエンドツーエンドの視覚-力覚拡散ポリシー",
    "summaryJa": "本研究では、視覚と力覚という異なる情報源を統合し、接触を伴うマニピュレーションタスクを実現する新しい手法、ImplicitRDPを提案します。視覚情報が空間的な全体像を提供する一方、力覚情報は高速な局所的な接触ダイナミクスを捉えます。この二つの情報を効果的に統合するため、Structural Slow-Fast Learningというメカニズムを導入し、非同期な視覚と力覚のトークンを同時に処理します。さらに、Virtual-target-based Representation Regularizationにより、異なるモダリティ間の重み調整の失敗を軽減します。実験の結果、ImplicitRDPは従来の視覚のみ、または階層的なベースラインよりも優れた性能を示し、高い反応性と成功率を達成しました。これはロボット制御における大きな進歩です。",
    "explanationJa": "視覚と力覚を組み合わせて、ロボットがより高度な作業をスムーズに行えるようにする新しい技術です。",
    "translationJa": "人間のような高度な接触を伴う操作は、空間的に豊かながら時間的に遅い全体的なコンテキストを提供する視覚と、高速かつ高周波な局所的な接触ダイナミクスを捉える力覚という、2つの主要なモダリティの役割に依存しています。これらの信号を統合することは、その根本的な周波数と情報的な乖離のために困難です。本研究では、単一のネットワーク内で視覚的計画と反応的な力制御を統合する、統一されたエンドツーエンドの視覚-力覚拡散ポリシーであるImplicitRDPを提案します。また、因果的注意を利用して非同期の視覚および力覚トークンを同時に処理するStructural Slow-Fast Learningというメカニズムを導入し、ポリシーがアクションチャンクの時間的コヒーレンスを維持しながら、力覚の周波数でクローズドループ調整を実行できるようにします。さらに、エンドツーエンドモデルが異なるモダリティ間の重みを調整できないモダリティ崩壊を軽減するために、Virtual-target-based Representation Regularizationを提案します。この補助的な目的は、力覚フィードバックをアクションと同じ空間にマッピングし、生の力覚予測よりも強力で物理的に基礎付けられた学習信号を提供します。接触を伴うタスクに関する広範な実験により、ImplicitRDPは視覚のみおよび階層的なベースラインの両方を大幅に上回り、合理化されたトレーニングパイプラインで優れた反応性と成功率を達成することが示されています。",
    "insightJa": "この技術は、工場の自動化や介護ロボットなど、精密な作業が求められる分野での応用が期待されます。より安全で効率的な作業環境の実現に貢献する可能性があります。",
    "recommendedBooks": [
      "ロボット工学",
      "強化学習",
      "コンピュータビジョン"
    ],
    "tags": [
      "robotics",
      "diffusion policy",
      "force control",
      "computer vision",
      "機械学習"
    ],
    "imageUrl": "https://images.pexels.com/photos/35147161/pexels-photo-35147161.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10938v1",
    "title": "Stronger Normalization-Free Transformers",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.10938v1",
    "summary": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\\mathrm{Derf}(x) = \\mathrm{erf}(αx + s)$, where $\\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.",
    "publishedAt": "2025-12-11T18:58:49Z",
    "author": "Mingzhi Chen",
    "category": "Science",
    "originalContent": "Although normalization layers have long been viewed as indispensable components of deep learning architectures, the recent introduction of Dynamic Tanh (DyT) has demonstrated that alternatives are possible. The point-wise function DyT constrains extreme values for stable convergence and reaches normalization-level performance; this work seeks further for function designs that can surpass it. We first study how the intrinsic properties of point-wise functions influence training and performance. Building on these findings, we conduct a large-scale search for a more effective function design. Through this exploration, we introduce $\\mathrm{Derf}(x) = \\mathrm{erf}(αx + s)$, where $\\mathrm{erf}(x)$ is the rescaled Gaussian cumulative distribution function, and identify it as the most performant design. Derf outperforms LayerNorm, RMSNorm, and DyT across a wide range of domains, including vision (image recognition and generation), speech representation, and DNA sequence modeling. Our findings suggest that the performance gains of Derf largely stem from its improved generalization rather than stronger fitting capacity. Its simplicity and stronger performance make Derf a practical choice for normalization-free Transformer architectures.",
    "titleJa": "より強力な正規化不要Transformer",
    "summaryJa": "本研究では、Transformerモデルにおける正規化層の代替として、新しい活性化関数Derfを提案します。従来の正規化層は不可欠と考えられていましたが、Dynamic Tanhのような代替手法の登場により、その必要性が再検討されています。本研究では、点ごとの関数が学習と性能に与える影響を詳細に分析し、大規模な探索を通じてDerfを発見しました。Derfは、画像認識、音声表現、DNA配列モデリングなど、幅広い分野でLayerNormやRMSNormなどの既存手法を上回る性能を示しました。この性能向上は、主に汎化能力の向上によるものであり、過学習を抑制する効果があると考えられます。Derfは、そのシンプルさと高い性能から、正規化層を使用しないTransformerアーキテクチャの実用的な選択肢となります。",
    "explanationJa": "この研究は、AIモデルの性能を向上させる新しい技術を開発し、より効率的なAIの実現を目指しています。",
    "translationJa": "正規化層は長らく深層学習アーキテクチャに不可欠な要素と考えられてきましたが、最近導入されたDynamic Tanh（DyT）は、代替手段が可能であることを示しました。DyTは、点ごとの関数であり、安定した収束のために極端な値を制限し、正規化層と同等の性能を達成します。本研究では、それを上回る関数設計をさらに追求します。まず、点ごとの関数の本質的な特性が学習と性能にどのように影響するかを調査します。これらの発見に基づいて、より効果的な関数設計の大規模な探索を行います。この探索を通じて、$\\mathrm{Derf}(x) = \\mathrm{erf}(αx + s)$を導入し、最も優れた性能を発揮する設計として特定します。ここで、$\\mathrm{erf}(x)$は、スケール変更されたガウス累積分布関数です。Derfは、画像認識および画像生成を含むビジョン、音声表現、DNA配列モデリングなど、幅広いドメインでLayerNorm、RMSNorm、およびDyTを上回ります。我々の発見は、Derfの性能向上は、より強力なフィッティング能力というよりは、主に汎化能力の向上に起因することを示唆しています。そのシンプルさと優れた性能により、Derfは正規化不要のTransformerアーキテクチャにとって実用的な選択肢となります。",
    "insightJa": "この技術は、AIモデルの計算コストを削減し、より少ないデータで学習できるようにすることで、様々な産業でのAIの利用を促進する可能性があります。例えば、医療診断や金融分析など、精度と効率が求められる分野での応用が期待されます。",
    "recommendedBooks": [
      "深層学習",
      "自然言語処理",
      "Transformer"
    ],
    "tags": [
      "Transformer",
      "Normalization",
      "Deep Learning",
      "Generalization",
      "Derf"
    ],
    "imageUrl": "https://images.pexels.com/photos/2635595/pexels-photo-2635595.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10775v1",
    "title": "Deflating the Spacetime-Matter Dichotomy",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.10775v1",
    "summary": "In this paper we analyse scalar-tensor theories-specific instances of which include mainstream inflation and dark energy models-in light of the spacetime-matter dichotomy. We argue that it is difficult to categorise the scalar fields as either a pure aspect of the spacetime structure or a pure form of matter, by focusing on the Jordan vs Einstein frames of these theories. We present and evaluate various interpretational options available, concluding that the spacetime-matter dichotomy becomes untenable in this context. At the same time, the ontological and conceptual category of spacetime can be decoupled from that of gravity, with the latter remaining viable in the context of scalar-tensor theories.",
    "publishedAt": "2025-12-11T16:11:47Z",
    "author": "Antonio Ferreiro",
    "category": "Science",
    "originalContent": "In this paper we analyse scalar-tensor theories-specific instances of which include mainstream inflation and dark energy models-in light of the spacetime-matter dichotomy. We argue that it is difficult to categorise the scalar fields as either a pure aspect of the spacetime structure or a pure form of matter, by focusing on the Jordan vs Einstein frames of these theories. We present and evaluate various interpretational options available, concluding that the spacetime-matter dichotomy becomes untenable in this context. At the same time, the ontological and conceptual category of spacetime can be decoupled from that of gravity, with the latter remaining viable in the context of scalar-tensor theories.",
    "titleJa": "時空と物質の二分法の解体",
    "summaryJa": "本研究では、スカラー・テンソル理論、特にインフレーションや暗黒エネルギーモデルに着目し、時空と物質の二分法について分析します。スカラー場を時空構造の一部、または物質の一形態として明確に分類することは困難であることを示唆しています。ジョルダン・フレームとアインシュタイン・フレームの比較を通じて、様々な解釈の可能性を検討した結果、時空と物質の二分法は維持できないという結論に至ります。同時に、時空の存在論的なカテゴリーと重力のカテゴリーは分離可能であり、重力自体はスカラー・テンソル理論の枠組みの中で依然として妥当性を持つと考えられます。",
    "explanationJa": "この研究は、宇宙の構成要素である時空と物質の区別が曖昧になる可能性を示唆しています。",
    "translationJa": "本論文では、スカラー・テンソル理論（その具体的な例として、主流のインフレーション模型や暗黒エネルギー模型を含む）を、時空と物質の二分法という観点から分析します。これらの理論におけるスカラー場を、時空構造の純粋な側面として、あるいは物質の純粋な形態として分類することが難しいことを、ジョルダン・フレームとアインシュタイン・フレームの違いに焦点を当てて議論します。利用可能な様々な解釈の選択肢を提示し、評価した結果、このような状況においては、時空と物質の二分法は成り立たないという結論に至ります。同時に、時空という存在論的、概念的なカテゴリーは、重力というカテゴリーから分離することができ、重力自体はスカラー・テンソル理論の文脈において存続可能です。",
    "insightJa": "宇宙論の根源的な問いに触れる研究であり、私たちの世界の捉え方、ひいては科学技術の発展に影響を与える可能性があります。",
    "recommendedBooks": [
      "宇宙論入門",
      "一般相対性理論",
      "暗黒物質"
    ],
    "tags": [
      "Scalar-Tensor Theory",
      "Spacetime",
      "Matter",
      "Inflation",
      "Dark Energy"
    ],
    "imageUrl": "https://images.pexels.com/photos/35146393/pexels-photo-35146393.png?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.09950v1",
    "title": "The meaning of \"Big Bang\"",
    "source": "arxiv",
    "url": "http://arxiv.org/pdf/2512.09950v1",
    "summary": "What does ``Big Bang'' actually mean? What was the origin of these two words? It has often been said that the expression ``Big Bang'' began as an insult. Even if this were true, it would be just an irrelevant part of the whole issue. There are many more aspects hidden under this name, and which are seldom explained. They will be discussed in this work. In order to frame the analysis, help will be sought from the highly authoritative voices of two exceptional writers: William Shakespeare and Umberto Eco. Both Shakespeare and Eco have explored the tension existing between words and the realities they name. With the conclusion that names are, in general, just labels, simple stickers put to identify things. And this includes those given to great theorems or spectacular discoveries. Not even ``Pythagoras' theorem'' was discovered by Pythagoras, as is now well-known. Stigler's law of eponymy is recalled to further substantiate those statements. These points will be at the heart of the investigation carried out here, concerning the very important concept of ``Big Bang''. Everybody thinks to know what ``the Big Bang'' is, but only very few do know it, in fact. When Fred Hoyle first pronounced these two words together, on a BBC radio program, listeners were actually left with the false image that Hoyle was trying to destroy. That is, the tremendous explosion of Lemaître's primeval atom (or cosmic egg), which scattered all its enormous matter and energy content throughout the rest of the Universe. This image is absolutely wrong! As will be concluded, today the label ``Big Bang'' is used in several different contexts: (a) the Big Bang Singularity; (b) as the equivalent of cosmic inflation; (c) speaking of the Big Bang cosmological model; (d) to name a very popular TV program; and more.",
    "publishedAt": "2025-12-09T10:46:11Z",
    "author": "Emilio Elizalde",
    "category": "Science",
    "originalContent": "What does ``Big Bang'' actually mean? What was the origin of these two words? It has often been said that the expression ``Big Bang'' began as an insult. Even if this were true, it would be just an irrelevant part of the whole issue. There are many more aspects hidden under this name, and which are seldom explained. They will be discussed in this work. In order to frame the analysis, help will be sought from the highly authoritative voices of two exceptional writers: William Shakespeare and Umberto Eco. Both Shakespeare and Eco have explored the tension existing between words and the realities they name. With the conclusion that names are, in general, just labels, simple stickers put to identify things. And this includes those given to great theorems or spectacular discoveries. Not even ``Pythagoras' theorem'' was discovered by Pythagoras, as is now well-known. Stigler's law of eponymy is recalled to further substantiate those statements. These points will be at the heart of the investigation carried out here, concerning the very important concept of ``Big Bang''. Everybody thinks to know what ``the Big Bang'' is, but only very few do know it, in fact. When Fred Hoyle first pronounced these two words together, on a BBC radio program, listeners were actually left with the false image that Hoyle was trying to destroy. That is, the tremendous explosion of Lemaître's primeval atom (or cosmic egg), which scattered all its enormous matter and energy content throughout the rest of the Universe. This image is absolutely wrong! As will be concluded, today the label ``Big Bang'' is used in several different contexts: (a) the Big Bang Singularity; (b) as the equivalent of cosmic inflation; (c) speaking of the Big Bang cosmological model; (d) to name a very popular TV program; and more.",
    "titleJa": "「ビッグバン」の意味",
    "summaryJa": "本論文では、「ビッグバン」という言葉の真の意味を探求します。その語源や、侮辱として始まったという説にとどまらず、その名の下に隠された多岐にわたる側面を考察します。シェイクスピアとウンベルト・エーコの言葉を引用し、言葉と現実の関係性を分析します。言葉は単なるラベルであり、「ビッグバン」も例外ではないという結論に至ります。フレッド・ホイルがこの言葉を使った際に生じた誤解や、現在における多様な用法についても議論します。",
    "explanationJa": "本論文は、「ビッグバン」という言葉が持つ多様な意味合いと、その背後にある歴史的・概念的な背景を解説するものです。",
    "translationJa": "「ビッグバン」とは実際には何を意味するのでしょうか？この言葉の起源はどこにあるのでしょうか？「ビッグバン」という表現は、もともと侮辱として始まったと言われることがよくあります。しかし、たとえそれが事実だとしても、それは問題全体のごく一部に過ぎません。この名前の下には、あまり説明されない多くの側面が隠されています。それらについて本論文で議論します。分析の枠組みを定めるために、ウィリアム・シェイクスピアとウンベルト・エーコという、非常に権威のある二人の作家の言葉を参考にします。シェイクスピアとエーコはどちらも、言葉とそれが指し示す現実との間に存在する緊張関係を探求してきました。その結論として、名前は一般的に単なるラベル、つまり物事を識別するために貼られた単純なステッカーに過ぎないということが挙げられます。そして、これは偉大な定理や目覚ましい発見に与えられた名前も含まれます。「ピタゴラスの定理」でさえ、現在ではよく知られているように、ピタゴラスによって発見されたものではありません。スティグラーの命名法則を想起することで、これらの主張をさらに裏付けます。これらの点は、「ビッグバン」という非常に重要な概念に関する本研究の中心となります。誰もが「ビッグバン」とは何かを知っていると思いがちですが、実際にはそれを知っている人はごくわずかです。フレッド・ホイルがBBCのラジオ番組で初めてこれらの言葉を一緒に発したとき、聴衆はホイルが破壊しようとしているという誤ったイメージを抱いてしまいました。つまり、ルメールの原始原子（または宇宙の卵）の巨大な爆発であり、その莫大な物質とエネルギーのすべてを宇宙の残りの部分に撒き散らしたというイメージです。このイメージは絶対に間違っています！結論として、「ビッグバン」というラベルは今日、いくつかの異なる文脈で使用されています。（a）ビッグバン特異点、（b）宇宙インフレーションと同義、（c）ビッグバン宇宙モデルについて語る場合、（d）非常に人気のあるテレビ番組の名前、など。",
    "insightJa": "ビッグバン理論の理解は、宇宙の起源だけでなく、科学的な用語がどのように社会に浸透し、影響を与えるかを考える上で重要です。ビジネスにおいては、新技術や概念の説明責任を明確にすることが重要になります。",
    "recommendedBooks": [
      "宇宙論 入門",
      "相対性理論",
      "科学史"
    ],
    "tags": [
      "Big Bang",
      "Cosmology",
      "History of Science",
      "Linguistics",
      "Scientific Terminology"
    ],
    "imageUrl": "https://images.pexels.com/photos/17505899/pexels-photo-17505899.jpeg?auto=compress&cs=tinysrgb&h=350"
  }
]