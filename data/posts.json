[
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "title": "Parents call for New York governor to sign landmark AI safety bill",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "summary": "A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill that would require developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.\nThe bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul reportedly proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the changes made to California's  …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T22:16:09.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STK485_STK414_AI_SAFETY_B.webp?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill <a href=\"https://legislation.nysenate.gov/pdf/bills/2025/S6953B\">that would require</a> developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.</p>\n<p class=\"has-text-align-none\">The bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul <a href=\"https://www.transformernews.ai/p/new-york-governor-hochul-raise-act-sb-53\">reportedly</a> proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the <a href=\"https://www.theverge.com/ai-artificial-intelligence/787918/sb-53-the-landmark-ai-transparency-bill-is-now-law-in-california\">changes made to California's  …</a></p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "親たちがニューヨーク州知事に画期的なAI安全法案への署名を要求",
    "summaryJa": "150人以上の親が、ホークルNY州知事に責任あるAI安全教育法（RAISE法）の修正なしでの署名を求めた。この法案は、大規模AIモデル開発企業に安全計画の作成と透明性規則の遵守を義務付けるもの。",
    "explanationJa": "ニューヨーク州でAIの安全に関する重要な法案が審議されており、親たちが知事に署名を求めています。",
    "translationJa": "150人以上の親たちのグループが金曜日、ニューヨーク州知事のキャシー・ホークルに書簡を送り、責任あるAI安全教育法（RAISE法）を修正なしで署名するよう促しました。RAISE法は、メタ、OpenAI、Deepseek、Googleなどの大規模AIモデルの開発企業に対し、安全計画の作成と安全事故の報告に関する透明性規則の遵守を義務付ける話題の法案です。\n\nこの法案は6月にニューヨーク州上院と下院の両方で可決されました。しかし今週、ホークル知事はRAISE法をほぼ完全に書き換え、テクノロジー企業にとってより有利なものにする提案をしたと報じられています。これは、カリフォルニア州で行われた変更の一部に似ています。\n\n詳細はThe Vergeの記事をご覧ください。",
    "insightJa": "AI技術の進化は、私たちの生活やビジネスに大きな影響を与えます。この法案が成立すれば、AIの安全性が向上し、より安心して技術を利用できるようになるでしょう。",
    "recommendedBooks": [
      "AIリスク",
      "AI倫理",
      "AI規制"
    ],
    "tags": [
      "AI Safety",
      "New York",
      "RAISE Act",
      "AI Regulation",
      "Kathy Hochul"
    ]
  },
  {
    "id": "https://techcrunch.com/?p=3075418",
    "title": "OK, what’s going on with LinkedIn’s algo?",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/ok-whats-going-on-with-linkedins-algo/",
    "summary": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "publishedAt": "Fri, 12 Dec 2025 19:38:16 +0000",
    "author": "Dominic-Madori Davis",
    "category": "AI",
    "originalContent": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "titleJa": "LinkedInのアルゴリズムに何が？",
    "summaryJa": "女性たちがLinkedInの新アルゴリズムが性差別的かどうかを実験し、それを証明したと考えたが、専門家はもっと複雑な要因が絡んでいると指摘しています。",
    "explanationJa": "LinkedInのアルゴリズムについて、性差別的な偏りがあるかどうかが議論されています。",
    "translationJa": "女性たちはLinkedInの新しいアルゴリズムが性差別的であるかどうかを検証する実験を行い、それを証明したと考えました。しかし、専門家によれば、より複雑な要因が関係しているようです。",
    "insightJa": "もしLinkedInのアルゴリズムに偏りがあれば、採用活動やキャリア形成に影響を与える可能性があります。アルゴリズムの透明性と公平性を確保することが重要です。",
    "recommendedBooks": [
      "アルゴリズム バイアス",
      "ジェンダーバイアス",
      "LinkedIn マーケティング"
    ],
    "tags": [
      "LinkedIn",
      "algorithm",
      "sexism",
      "バイアス",
      "アルゴリズム"
    ]
  },
  {
    "id": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "title": "Google Translate brings real-time speech translations to any headphones",
    "source": "rss",
    "url": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "summary": "Google Translate's latest update brings live speech translations, originally available only on the Pixel Buds, to any headphones you want, with support for over 70 languages. It's rolling out today in beta and just requires a compatible Android phone with the Translate app (unlike Apple's similar feature, which requires AirPods). \nIt's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T18:11:14.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/google-translate-text-update-12-12-25.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google Translate's latest update brings live speech translations, originally available only <a href=\"https://www.theverge.com/2017/11/16/16659314/google-pixel-buds-review-bluetooth-headphones\">on the Pixel Buds</a>, to any headphones you want, with support for over 70 languages. It's <a href=\"https://blog.google/products/search/gemini-capabilities-translation-upgrades/\">rolling out today in beta</a> and just requires a compatible Android phone with the Translate app (unlike <a href=\"https://www.theverge.com/news/629506/apple-airpods-live-translation-ios-19\">Apple's similar feature</a>, which requires AirPods). </p>\n<p class=\"has-text-align-none\">It's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …</p>\n<p><a href=\"https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "Google翻訳、リアルタイム音声翻訳をあらゆるヘッドホンで利用可能に",
    "summaryJa": "Google翻訳がアップデート。Pixel Buds限定だったリアルタイム音声翻訳が、70以上の言語に対応し、あらゆるヘッドホンで利用可能に。テキスト翻訳もGeminiで向上。",
    "explanationJa": "Google翻訳が進化し、どんなヘッドホンでもリアルタイムで外国語の会話が楽しめるようになります。",
    "translationJa": "Google翻訳の最新アップデートにより、Pixel Budsでのみ利用可能だったライブ音声翻訳が、70以上の言語をサポートし、あらゆるヘッドホンで利用できるようになります。本日ベータ版として公開され、互換性のあるAndroidスマートフォンと翻訳アプリがあれば利用できます（Appleの同様の機能であるAirPodsが必要なものとは異なります）。\n\nこれは、Google翻訳に追加されるいくつかの新機能のうちの1つであり、テキスト翻訳の改善も含まれています。Geminiを使用することで、翻訳は、単語を文字通りに訳した場合とは異なる意味を持つ、イディオムやスラングなどのフレーズをより正確に翻訳できるようになります。たとえば、「stealing my …」といった表現などです。\n\nThe Vergeで全文をお読みください。",
    "insightJa": "この機能により、言語の壁が低くなり、海外旅行や国際ビジネスがよりスムーズになることが期待されます。異なる文化を持つ人々とのコミュニケーションが容易になり、よりグローバルな活動が可能になるでしょう。",
    "recommendedBooks": [
      "機械翻訳",
      "多言語コミュニケーション",
      "AI翻訳 最新"
    ],
    "tags": [
      "Google Translate",
      "リアルタイム翻訳",
      "音声翻訳",
      "Gemini",
      "AI"
    ]
  },
  {
    "id": "https://techcrunch.com/?p=3075611",
    "title": "Trump’s AI executive order promises ‘one rulebook’ — startups may get legal limbo instead",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/trumps-ai-executive-order-promises-one-rulebook-startups-may-get-legal-limbo-instead/",
    "summary": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "publishedAt": "Fri, 12 Dec 2025 17:07:22 +0000",
    "author": "Rebecca Bellan",
    "category": "AI",
    "originalContent": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "titleJa": "トランプ氏のAIに関する大統領令、「単一の規則」を約束もスタートアップは法的混乱に陥る可能性",
    "summaryJa": "トランプ氏がAIに関する大統領令に署名。州法を対象とし、全国統一ルールを目指す。しかし、連邦議会が規則を議論する間、訴訟やスタートアップの不確実性を長引かせる可能性があると批判されている。",
    "explanationJa": "トランプ氏のAIに関する大統領令は、企業にとってルールの統一を目指すものですが、混乱を招く可能性もあるようです。",
    "translationJa": "トランプ氏は、州法を対象としたAIに関する大統領令に署名し、単一の全国的な規則を約束しました。しかし、批評家は、連邦議会が連邦規則を議論する間、法廷闘争を引き起こし、スタートアップ企業の不確実性を長引かせる可能性があると警告しています。",
    "insightJa": "この大統領令によって、AI関連ビジネスを展開する企業は、法規制の動向を注視する必要が出てきます。特に、新しい技術やサービスを開発するスタートアップ企業は、今後の訴訟リスクや規制変更に備えることが重要になるでしょう。",
    "recommendedBooks": [
      "人工知能 法規制",
      "AI スタートアップ",
      "テクノロジー政策"
    ],
    "tags": [
      "AI",
      "executive order",
      "regulation",
      "startups",
      "Trump"
    ]
  },
  {
    "id": "https://techcrunch.com/?p=3075551",
    "title": "Google Translate now lets you hear real-time translations in your headphones",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/google-translate-now-lets-you-hear-real-time-translations-in-your-headphones/",
    "summary": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "publishedAt": "Fri, 12 Dec 2025 17:00:00 +0000",
    "author": "Aisha Malik",
    "category": "AI",
    "originalContent": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "titleJa": "Google翻訳がヘッドホンでリアルタイム翻訳を提供開始",
    "summaryJa": "Google翻訳が、話し手の口調や強調、リズムをそのままに、リアルタイムでヘッドホンに翻訳を届ける機能を開始。会話の理解を助け、誰が話しているかの区別も容易にします。",
    "explanationJa": "Google翻訳の新しい機能で、ヘッドホンを通じて、より自然なリアルタイム翻訳が体験できるようになりました。",
    "translationJa": "リアルタイムのヘッドホン翻訳体験では、各話者の口調、強調、およびリズムがそのまま維持されるため、会話を追跡しやすく、誰が何を言っているのかを判別しやすくなります。",
    "insightJa": "この機能により、言語の壁を越えたコミュニケーションがよりスムーズになり、国際会議や旅行、ビジネスシーンなどで非常に役立つと考えられます。グローバル化が進む現代において、ますます重要なツールとなるでしょう。",
    "recommendedBooks": [
      "翻訳技術",
      "多言語コミュニケーション",
      "異文化理解"
    ],
    "tags": [
      "Google Translate",
      "Real-time Translation",
      "Headphones",
      "AI",
      "Language Barrier"
    ]
  },
  {
    "id": "https://techcrunch.com/?p=2607630",
    "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/chatgpt-everything-to-know-about-the-ai-chatbot/",
    "summary": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "publishedAt": "Fri, 12 Dec 2025 16:01:00 +0000",
    "author": "Kyle Wiggers, Cody Corrall, Kate Park, Alyssa Stringer",
    "category": "AI",
    "originalContent": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "titleJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと",
    "summaryJa": "この記事は、ChatGPTの製品アップデートとリリースに関する年表です。最新の情報から始まり、今年一年を通して更新されています。",
    "explanationJa": "この記事では、AIチャットボットChatGPTの最新情報や、これまでのアップデートの歴史をまとめています。",
    "translationJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと\n\n以下は、ChatGPTの製品アップデートとリリースに関する年表です。最新の情報から始まり、今年一年を通して更新していきます。",
    "insightJa": "ChatGPTのようなAI技術は、日々のコミュニケーションや情報収集の方法を大きく変える可能性があります。ビジネスにおいては、顧客対応の効率化や新たなサービス創出に役立つと考えられます。",
    "recommendedBooks": [
      "ChatGPT 入門",
      "AIチャットボット 活用",
      "自然言語処理 最新動向"
    ],
    "tags": [
      "ChatGPT",
      "AI",
      "チャットボット",
      "自然言語処理",
      "製品アップデート"
    ]
  },
  {
    "id": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "title": "I quit all my AI fitness plans, and I feel free",
    "source": "rss",
    "url": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "summary": "AI sure does use a lot of words to say very little.\t\n\nThis is Optimizer, a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. Optimizer arrives in our subscribers' inboxes at 10AM ET. Opt in for Optimizer here.\nThis time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt amazing. Then life happened. \nA year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T15:00:00.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Over the shoulder shot of someone reading a lengthy AI insight from the Runna app\" data-caption=\"AI sure does use a lot of words to say very little.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAI sure does use a lot of words to say very little.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>This is </em><a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a><em>, a weekly newsletter sent every Friday from Verge senior reviewer</em> <a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a><em> that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. </em>Optimizer<em> arrives in our subscribers' inboxes at 10AM ET. Opt in for </em>Optimizer <em><a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</em></p>\n<p class=\"has-drop-cap has-text-align-none\">This time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt <em>amazing.</em> Then life happened. </p>\n<p class=\"has-text-align-none\">A year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIフィットネスプランをやめたら、解放された気分",
    "summaryJa": "筆者はAIフィットネスプランを利用していたが、情報の多さに辟易し、全て解約。結果、プレッシャーから解放され、自由を感じている。",
    "explanationJa": "AIフィットネスプランをやめた筆者が、精神的な自由を得られたという記事です。",
    "translationJa": "これは、The Vergeのシニアレビューアー、ヴィクトリア・ソンから毎週金曜日に配信される週刊ニュースレター「Optimizer」です。Optimizerでは、あなたの人生を変えると豪語する最新の携帯電話、スマートウォッチ、アプリ、その他のガジェットを分析し、議論します。Optimizerは、東部時間午前10時に購読者の受信箱に届きます。Optimizerの購読は<a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">こちら</a>から。\n\n去年の今頃、私は4マイルのランニングタイムを16分短縮し、週に3〜4回ウェイトリフティングを行い、6ヶ月間の継続的なトレーニングの後、10ポンド減量しました。気分は最高でした。その後、人生に色々なことが起こりました。\n\n1年後、私は3ヶ月以上5K以上のランニングをしていません。ストレスで10ポンド戻ってしまい、…\n\n<a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">The Vergeで記事全文を読む</a>",
    "insightJa": "AIフィットネスは便利ですが、情報過多やプレッシャーを感じる場合もあります。自分に合った方法を見つけることが、健康的な生活を送る上で大切です。",
    "recommendedBooks": [
      "フィットネス アプリ 比較",
      "AI コーチング 健康",
      "運動 習慣 継続"
    ],
    "tags": [
      "AI Fitness",
      "Fitness App",
      "Mental Health",
      "Exercise",
      "Runna"
    ]
  },
  {
    "id": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "title": "How to vibe-write a country hit",
    "source": "rss",
    "url": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "summary": "You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"I Run\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.\nOn this episode of The Vergecast, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent Switched on Pop podcast. Charlie takes us th …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T14:23:18.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/VRG_VST_1212_Site.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"<a href=\"https://www.digitalmusicnews.com/2025/11/24/havens-i-run-ai-song-explained/\">I Run</a>\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.</p>\n<p class=\"has-text-align-none\">On <a href=\"https://link.chtbl.com/vergecast\">this episode of <em>The Vergecast</em></a>, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent <em>Switched on Pop </em>podcast. Charlie takes us th …</p>\n<p><a href=\"https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIでカントリーヒット曲を作る方法",
    "summaryJa": "AIツール、特にSunoが音楽制作、特にカントリー音楽の中心地ナッシュビルで大きな役割を果たしています。TikTokなどでAI生成楽曲を耳にする機会が増加。",
    "explanationJa": "AIを活用してカントリー音楽のヒット曲を作る手法が注目されています。音楽制作の新しい可能性が広がりますね。",
    "translationJa": "おそらくご存知ないかもしれませんが、ほとんど、あるいは完全にAIによって作られた曲に出会ったことがあるはずです。ここ数週間TikTokをスクロールしているなら、おそらく「I Run」を何度か耳にしたことがあるでしょう。しかし、ソーシャルや音楽プラットフォーム上では、数えきれないほどの楽曲が作られています。一般的なAIツール、特にSunoは、音楽制作プロセスにおいて大きな部分を占めるようになっています。そして、それはカントリー音楽の本拠地、ナッシュビルにおいて最も顕著です。\n\nこのエピソードの「The Vergecast」では、NilayとDavidが、音楽ジャーナリストであり教授であり、優れたポッドキャスト「Switched on Pop」の共同ホストでもあるチャーリー・ハーディングを迎えます。チャーリーが私たちを…\n\nThe Vergeで記事全文を読む。",
    "insightJa": "AI音楽の普及により、誰でも手軽に音楽制作を楽しめるようになるかもしれません。音楽業界のビジネスモデルや著作権に関する議論がより活発になるでしょう。",
    "recommendedBooks": [
      "AI音楽生成",
      "音楽とAI",
      "カントリー音楽 歴史"
    ],
    "tags": [
      "AI Music",
      "Country Music",
      "Suno",
      "人工知能",
      "音楽制作"
    ]
  },
  {
    "id": "43pZxbBPbS0s7iDFEyijjR",
    "title": "Ai2's new Olmo 3.1 extends reinforcement learning training for stronger reasoning benchmarks",
    "source": "rss",
    "url": "https://venturebeat.com/ai/ai2s-new-olmo-3-1-extends-reinforcement-learning-training-for-stronger",
    "summary": "The Allen Institute for AI (Ai2) recently released what it calls its most powerful family of models yet, Olmo 3. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.\nThe new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. \nAi2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. \nOlmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. \nAi2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. \n“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a blog post. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”\n\nTo get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.\nOlmo 3.1 Instruct 32B is \"optimized for chat, tool use, & multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a post on X. \nFor now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. \nBetter performance on benchmarks\nThe Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. \nOlmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. \nOlmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.\n“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. \n\nAi2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.\nCommitment to transparency and open source \nAi2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. \nOrganizations could add to the model’s data mix and retrain it to also learn from what’s been added.  \nThis has long been a commitment for Ai2, which also offers a tool called OlmoTrace that tracks how LLM outputs match its training data.  \n\n“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said.",
    "publishedAt": "Fri, 12 Dec 2025 05:00:00 GMT",
    "author": "",
    "category": "AI",
    "originalContent": "<p>The Allen Institute for AI (Ai2) recently released what it calls its most powerful <a href=\"https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning\"><u>family of models yet, Olmo 3</u></a>. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.</p><p>The new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. </p><p>Ai2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. </p><p>Olmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. </p><p>Ai2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. </p><p>“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a <a href=\"https://allenai.org/blog/olmo3\"><u>blog post</u></a>. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”</p><div></div><p>To get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.</p><p>Olmo 3.1 Instruct 32B is &quot;optimized for chat, tool use, &amp; multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a <a href=\"https://x.com/allen_ai/status/1999528338365247539\"><u>post on X</u></a>. </p><p>For now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. </p><h2>Better performance on benchmarks</h2><p>The Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. </p><p>Olmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. </p><p>Olmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.</p><p>“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. </p><div></div><p>Ai2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.</p><h2>Commitment to transparency and open source </h2><p>Ai2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. </p><p>Organizations could add to the model’s data mix and retrain it to also learn from what’s been added.  </p><p>This has long been a commitment for Ai2, which also offers a <a href=\"https://venturebeat.com/ai/whats-inside-the-llm-ai2-olmotrace-will-trace-the-source\"><u>tool called OlmoTrace</u></a> that tracks how LLM outputs match its training data.  </p><div></div><p>“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said. </p><p>\n\n\n\n\n\n</p>",
    "titleJa": "Ai2の新しいOlmo 3.1、強固な推論ベンチマークに向けて強化学習トレーニングを拡張",
    "summaryJa": "Allen Institute for AI(Ai2)は、Olmo 3.1をリリース。効率、透明性、制御に焦点を当て、特にThink 32BとInstruct 32Bを強化。ベンチマークテストで優れた性能を示し、オープンソースへの取り組みを強調。",
    "explanationJa": "AI2が、より性能の高いAIモデル「Olmo 3.1」を発表しました。数学や推論能力が向上し、ビジネスでの活用が期待されます。",
    "translationJa": "アレン人工知能研究所（Ai2）は最近、これまでで最も強力なモデルのファミリーであるOlmo 3を発表しました。しかし、同社はモデルの反復を続け、強化学習（RL）の実行を拡大し、Olmo 3.1を作成しました。\n\n新しいOlmo 3.1モデルは、企業向けの効率、透明性、および制御に焦点を当てています。\n\nAi2は、Olmo 2の3つのバージョンのうち2つを更新しました。高度な研究向けに最適化されたフラッグシップモデルであるOlmo 3.1 Think 32Bと、指示に従うこと、マルチターンの対話、およびツール使用のために設計されたOlmo 3.1 Instruct 32Bです。\n\nOlmo 3には、プログラミング、理解、および数学用の3番目のバージョンであるOlmo 3-Baseがあります。これは、継続的な微調整にも適しています。\n\nAi2は、Olmo 3 Think 32BをOlmo 3.1にアップグレードするために、研究者たちが最高のRL実行をより長いトレーニングスケジュールで拡張したと述べました。\n\n「オリジナルのOlmo 3のリリース後、Olmo 3 32B ThinkのRLトレーニング実行を再開し、Dolci-Think-RLデータセットで追加のエポックを使用して224個のGPUでさらに21日間トレーニングしました」と、Ai2はブログ投稿で述べています。「これにより、Olmo 3.1 32B Thinkが生まれ、数学、推論、および指示に従うベンチマーク全体で大幅な改善をもたらします。AIMEで5ポイント以上、ZebraLogicで4ポイント以上、IFEvalで4ポイント以上、IFBenchで20ポイント以上の改善に加え、コーディングと複雑なマルチステップタスクでより強力なパフォーマンスを発揮します。」\n\nOlmo 3.1 Instructに到達するために、Ai2の研究者たちは、より小さいInstructサイズである7Bの背後にあるレシピをより大きなモデルに適用したと述べました。\n\nOlmo 3.1 Instruct 32Bは、「チャット、ツールの使用、およびマルチターンの対話に最適化されており、Olmo 3 Instruct 7Bのパフォーマンスが大幅に向上した兄弟モデルであり、実際のアプリケーションに対応できます」とAi2はXへの投稿で述べています。\n\n今のところ、新しいチェックポイントはAi2 PlaygroundまたはHugging Faceで利用可能であり、APIアクセスは近日中に提供される予定です。\n\nベンチマークでのより良いパフォーマンス\n\nOlmo 3.1モデルは、ベンチマークテストで優れたパフォーマンスを発揮し、予想どおりOlmo 3モデルを打ち負かしました。\n\nOlmo 3.1 Thinkは、AIME 2025ベンチマークでQwen 3 32Bモデルを上回り、Gemma 27Bに近いパフォーマンスを発揮しました。\n\nOlmo 3.1 Instructは、そのオープンソースの仲間に対して強力なパフォーマンスを発揮し、MathベンチマークでGemma 3のようなモデルさえ打ち負かしました。\n\n「Olmo 3.1 32B Instructに関しては、チャット、ツールの使用、およびマルチターンの対話のために構築された、より大規模な指示調整済みモデルです。Olmo 3.1 32B Instructは、現在までに最も有能な完全にオープンなチャットモデルであり、私たちの評価では、最も強力な完全にオープンな32Bスケールの指示モデルです」と同社は述べています。\n\nAi2はまた、数学とコーディングのためにRL-Zero 7Bモデルをアップグレードしました。同社はXで、両方のモデルがより長く、より安定したトレーニング実行から恩恵を受けたと述べています。\n\n透明性とオープンソースへのコミットメント\n\nAi2は以前VentureBeatに、企業や研究室にモデルに入力されたデータとトレーニングのより多くの制御と理解を提供するために、Olmo 3モデルのファミリーを設計したと語りました。\n\n組織はモデルのデータミックスに追加し、それを再トレーニングして、追加されたものからも学習させることができます。\n\nこれは、Ai2にとって長年のコミットメントであり、LLM出力がそのトレーニングデータとどのように一致するかを追跡するOlmoTraceと呼ばれるツールも提供しています。\n\n「Olmo 3.1 Think 32BとOlmo 3.1 Instruct 32Bを合わせると、オープン性とパフォーマンスが共に進歩できることを示しています。同じモデルフローを拡張することで、データ、コード、およびトレーニングの決定に関するエンドツーエンドの透明性を維持しながら、機能を向上させ続けています」とAi2は述べています。",
    "insightJa": "今回のAIモデルの進化は、企業の業務効率化や研究開発の加速に貢献するでしょう。特に、オープンソースである点が、より多くの企業や研究機関での利用を促進し、AI技術の発展を加速させる可能性があります。",
    "recommendedBooks": [
      "大規模言語モデル",
      "強化学習 実践",
      "AI オープンソース"
    ],
    "tags": [
      "AI",
      "LLM",
      "Reinforcement Learning",
      "Open Source",
      "Olmo 3.1"
    ]
  },
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "title": "Trump signs AI executive order pushing to ban state laws",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "summary": "President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t\n\nOn Thursday evening, with White House AI and crypto czar David Sacks looking over his shoulder, Donald Trump signed an executive order aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order can't by itself unilaterally override state AI laws, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.\nIt specifically calls out Colorado's recently passed consumer protection law, making the claim that \"banning 'algorithmic discri …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T01:18:46.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks in the Oval Office\" data-caption=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/gettyimages-2251458899.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tPresident Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">On Thursday evening, with White House AI and crypto czar David Sacks <a href=\"https://www.youtube.com/live/rYDbVjXu5os?si=TUpA0_o7ORLU9jZh&amp;t=737\">looking over his shoulder</a>, Donald Trump <a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/\">signed an executive order</a> aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order <a href=\"https://www.theverge.com/column/829938/leaked-ai-executive-order-analysis\">can't by itself unilaterally override state AI laws</a>, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.</p>\n<p class=\"has-text-align-none\">It specifically calls out Colorado's <a href=\"https://leg.colorado.gov/bills/sb24-205\">recently passed consumer protection law</a>, making the claim that \"banning 'algorithmic discri …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "トランプ大統領、AI規制に関する大統領令に署名、州法禁止を推進",
    "summaryJa": "トランプ大統領がAI規制に関する大統領令に署名。州法の影響を減らし、連邦政府が異議を唱える可能性のある州法の制定を抑制する狙い。コロラド州の消費者保護法を名指し。",
    "explanationJa": "トランプ大統領がAI規制で州の法律よりも連邦政府の権限を強める大統領令に署名しました。",
    "translationJa": "ドナルド・トランプ大統領は木曜日の夕方、ホワイトハウスのAIおよび暗号資産担当官であるデイビッド・サックス氏が後ろで見守る中、人工知能（AI）の規制に関して連邦政府が一方的な権限を獲得することを目的とした大統領令に署名しました。この命令自体では、州のAI法を一方的に覆すことはできませんが、連邦政府機関に対し、州法の影響を低減または排除するための措置を講じ、連邦政府が異議を唱える可能性のある法律を州が制定することを抑制し、他のプログラムに対する重要な資金提供を危険にさらすことを阻止するよう指示しています。\n\nこの命令は、コロラド州で最近可決された消費者保護法を具体的に取り上げ、「アルゴリズムによる差別禁止…」という主張をしています。\n\n詳細はThe Vergeの記事をご覧ください。",
    "insightJa": "今回のAI規制に関する大統領令は、ビジネスにおけるAIの利用方法や、個人情報の保護に大きな影響を与える可能性があります。企業は、今後の法規制の動向を注視し、適切な対応を検討する必要があるでしょう。",
    "recommendedBooks": [
      "AI 法規制",
      "人工知能 ガバナンス",
      "AI リスクマネジメント"
    ],
    "tags": [
      "AI regulation",
      "Trump",
      "executive order",
      "artificial intelligence",
      "連邦法"
    ]
  },
  {
    "id": "https://techcrunch.com/?p=3075457",
    "title": "Google launched its deepest AI research agent yet — on the same day OpenAI dropped GPT-5.2",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/",
    "summary": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "publishedAt": "Fri, 12 Dec 2025 00:18:56 +0000",
    "author": "Julie Bort",
    "category": "AI",
    "originalContent": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "titleJa": "Googleが過去最高のAI研究エージェントを発表 - OpenAIがGPT-5.2を公開した同日に",
    "summaryJa": "GoogleはGemini 3 Proを基盤とするDeep Researchツールを開発者向けに公開し、アプリへの組み込みを可能にしました。OpenAIのGPT-5.2公開と同日の発表です。",
    "explanationJa": "Googleの高度なAI研究ツールが利用可能になり、様々なアプリへの応用が期待されます。",
    "translationJa": "Googleは、Gemini 3 Proを基盤とするDeep Researchツールを開発者が自身のアプリに組み込めるようにしました。これは初めてのことです。",
    "insightJa": "この技術により、アプリ開発者は高度なAI機能を容易に組み込むことができ、より賢く便利なアプリケーションが生まれることが期待されます。ビジネスにおいては、業務効率化や新しい顧客体験の提供に繋がる可能性があります。",
    "recommendedBooks": [
      "AIアプリケーション開発",
      "ジェネレーティブAI",
      "Gemini API"
    ],
    "tags": [
      "Google",
      "Gemini",
      "AI",
      "Deep Learning",
      "OpenAI"
    ]
  },
  {
    "id": "7iBvnTz8OK7lcxexlxh4OW",
    "title": "Google’s new framework helps AI agents spend their compute and tool budget more wisely",
    "source": "rss",
    "url": "https://venturebeat.com/ai/googles-new-framework-helps-ai-agents-spend-their-compute-and-tool-budget",
    "summary": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.\nAs AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.\nFor enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.\nThe challenge of scaling tool use\nTraditional test-time scaling focuses on letting models \"think\" longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.\nThis introduces significant operational overhead for businesses. \"Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,\" Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. \"Tool calls themselves introduce additional API costs.\"\nThe researchers found that simply granting agents more test-time resources does not guarantee better performance. \"In a deep research task, if the agent has no sense of budget, it often goes down blindly,\" Wang and Liu explained. \"It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.\"\nOptimizing resources with Budget Tracker\nTo evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called \"Budget Tracker.\" This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.\nThe team hypothesized that \"providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.\"\nBudget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)\nIn Google's implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.\nTo test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.\nThey tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as Gemini 2.5 Pro, Gemini 2.5 Flash, and Claude Sonnet 4. The experiments show that this simple plug-in improves performance across various budget constraints.\n\"Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,\" the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.\nBATS: A comprehensive framework for budget-aware scaling\nTo further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent's behavior as it formulates its response.\nBATS uses multiple modules to orchestrate the agent's actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to \"dig deeper\" into a promising lead or \"pivot\" to alternative paths based on resource availability.\nGiven an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.\nThe iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.\nThe researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.\nBATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.\nAccording to the authors, this efficiency makes previously expensive workflows viable. \"This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,\" they said.\nAs enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.\n\"We believe the relationship between reasoning and economics will become inseparable,\" Wang and Liu said. \"In the future, [models] must reason about value.\"",
    "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
    "author": "bendee983@gmail.com (Ben Dickson)",
    "category": "AI",
    "originalContent": "<p>In a <a href=\"https://arxiv.org/abs/2511.17006\"><u>new paper</u></a> that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple &quot;Budget Tracker&quot; and a more comprehensive framework called &quot;Budget Aware Test-time Scaling.&quot; These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.</p><p>As AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.</p><p>For enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.</p><h2>The challenge of scaling tool use</h2><p>Traditional <a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>test-time scaling</u></a> focuses on letting models &quot;think&quot; longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.</p><p>This introduces significant operational overhead for businesses. &quot;Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,&quot; Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. &quot;Tool calls themselves introduce additional API costs.&quot;</p><p>The researchers found that simply granting agents more test-time resources does not guarantee better performance. &quot;In a deep research task, if the agent has no sense of budget, it often goes down blindly,&quot; Wang and Liu explained. &quot;It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.&quot;</p><h2>Optimizing resources with Budget Tracker</h2><p>To evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called &quot;Budget Tracker.&quot; This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.</p><p>The team hypothesized that &quot;providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.&quot;</p><p>Budget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)</p><p>In Google&#x27;s implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.</p><p>To test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.</p><p>They tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as <a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>, Gemini 2.5 Flash, and <a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>. The experiments show that this simple plug-in improves performance across various budget constraints.</p><p>&quot;Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,&quot; the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.</p><h2>BATS: A comprehensive framework for budget-aware scaling</h2><p>To further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent&#x27;s behavior as it formulates its response.</p><p>BATS uses multiple modules to orchestrate the agent&#x27;s actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to &quot;dig deeper&quot; into a promising lead or &quot;pivot&quot; to alternative paths based on resource availability.</p><p>Given an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.</p><p>The iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.</p><p>The researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.</p><p>BATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.</p><p>According to the authors, this efficiency makes previously expensive workflows viable. &quot;This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,&quot; they said.</p><p>As enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.</p><p>&quot;We believe the relationship between reasoning and economics will become inseparable,&quot; Wang and Liu said. &quot;In the future, [models] must reason about value.&quot;</p><p>\n</p>",
    "titleJa": "Google の新フレームワークがAIエージェントの計算リソースとツール利用をより賢く管理",
    "summaryJa": "Googleの研究者が、LLMエージェントがツールと計算リソースを効率的に利用できるフレームワークを開発。コストとレイテンシーを制御します。",
    "explanationJa": "Googleが、AIエージェントが予算内で効率的にツールを使えるようにする新しい技術を開発しました。",
    "translationJa": "<p>大規模言語モデル（LLM）エージェントにおけるツール利用を研究した<a href=\"https://arxiv.org/abs/2511.17006\"><u>新しい論文</u></a>で、GoogleとUCサンタバーバラの研究者たちは、エージェントがツールと計算リソースの予算をより効率的に利用できるようにするフレームワークを開発しました。研究者たちは、単純な「バジェットトラッカー」と、より包括的なフレームワークである「予算認識型テスト時スケーリング（Budget Aware Test-time Scaling）」という2つの新しい技術を紹介しています。これらの技術により、エージェントは残りの推論とツール利用の許容量を明確に認識できます。</p><p>AIエージェントが現実世界で作業するためにツール呼び出しに依存するにつれて、テスト時スケーリングは、より賢いモデルというよりも、コストとレイテンシーの制御に関わるようになっています。</p><p>企業リーダーや開発者にとって、予算認識型スケーリング技術は、予測不可能なコストや計算リソースの支出に対する収益逓減に直面することなく、効果的なAIエージェントを導入するための実用的な道筋を提供します。</p><h2>ツール利用のスケーリングの課題</h2><p>従来の<a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>テスト時スケーリング</u></a>は、モデルがより長く「考える」ことに焦点を当てています。しかし、Webブラウジングのようなエージェント的なタスクでは、ツール呼び出しの回数が探索の深さと幅を直接決定します。</p><p>これは企業にとって重大な運用上のオーバーヘッドをもたらします。「Webページの閲覧のようなツール呼び出しは、より多くのトークン消費につながり、コンテキストの長さを増やし、追加の時間レイテンシーをもたらします」と、論文の共著者であるZifeng WangとTengxiao LiuはVentureBeatに語りました。「ツール呼び出し自体が追加のAPIコストをもたらします。」</p><p>研究者たちは、エージェントに多くのテスト時リソースを与えるだけでは、パフォーマンスの向上は保証されないことを発見しました。「深い研究タスクでは、エージェントが予算を意識していない場合、しばしば盲目的に突き進みます」とWangとLiuは説明しました。「ある程度関連性のある手がかりを見つけると、それに10回または20回のツール呼び出しを費やして掘り下げますが、その道全体が行き止まりだったことに気づくだけです。」</p><h2>バジェットトラッカーによるリソースの最適化</h2><p>ツール利用の予算をどのように最適化できるかを評価するために、研究者たちは最初に「バジェットトラッカー」と呼ばれる軽量なアプローチを試しました。このモジュールは、エージェントにリソースの可用性に関する継続的なシグナルを提供するプラグインとして機能し、予算を意識したツール利用を可能にします。</p><p>研究チームは、「明示的な予算シグナルを提供することで、モデルは追加のトレーニングを必要とせずにリソースの制約を内面化し、戦略を適応させることができる」と仮説を立てました。</p><p>バジェットトラッカーは、プロンプトレベルでのみ動作するため、実装が簡単です。（論文には、バジェットトラッカーに使用されるプロンプトの詳細がすべて記載されており、実装が容易になっています。）</p><p>Googleの実装では、トラッカーは予算体制とそれに対応するツールの使用に関する推奨事項を記述した簡単なポリシーガイドラインを提供します。応答プロセスの各ステップで、バジェットトラッカーはエージェントにリソースの消費量と残りの予算を明確に認識させ、その後の推論ステップを更新されたリソース状態に基づいて条件付けることを可能にします。</p><p>これをテストするために、研究者たちは、モデルが反復的に出力を洗練するシーケンシャルスケーリングと、複数の独立した実行を実施して集約するパラレルスケーリングという2つのパラダイムで実験を行いました。彼らは、ReActスタイルのループに従って検索および参照ツールを備えた検索エージェントで実験を行いました。ReAct（Reasoning + Acting）は、モデルが内部思考と外部行動を交互に行う一般的な方法です。真のコストパフォーマンスのスケーリング傾向を追跡するために、内部トークン消費と外部ツールインタラクションの両方のコストを共同で考慮する統一コストメトリックを開発しました。</p><p>彼らは、<a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>、Gemini 2.5 Flash、および<a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>などのモデルを使用して、BrowseCompやHLE-Searchなどの外部検索を必要とする3つの情報検索QAデータセットでバジェットトラッカーをテストしました。実験結果は、この単純なプラグインがさまざまな予算制約下でパフォーマンスを向上させることを示しています。</p><p>「バジェットトラッカーを追加すると、検索呼び出しが40.4％減少し、参照呼び出しが19.9％減少し、全体的なコストが…31.3％削減され、同等の精度が得られます」と著者らはVentureBeatに語りました。最後に、バジェットトラッカーは予算が増加するにつれてスケーリングを続けましたが、プレーンReActは特定のしきい値を超えると停滞しました。</p><h2>BATS：予算認識型スケーリングのための包括的なフレームワーク</h2><p>ツール利用のリソース最適化をさらに改善するために、研究者たちは、与えられた予算の下でエージェントのパフォーマンスを最大化するように設計されたフレームワークである予算認識型テスト時スケーリング（BATS）を導入しました。BATSは、残りのリソースの継続的なシグナルを維持し、この情報を使用して、応答を策定する際にエージェントの動作を動的に適応させます。</p><p>BATSは、複数のモジュールを使用してエージェントのアクションを調整します。計画モジュールは、ステップごとの努力を現在の予算に合わせて調整し、検証モジュールは、有望な手がかりを「より深く掘り下げる」か、リソースの可用性に基づいて代替パスに「ピボット」するかを決定します。</p><p>情報検索の質問とツール呼び出しの予算が与えられると、BATSは最初に計画モジュールを使用して構造化されたアクションプランを策定し、どのツールを呼び出すかを決定します。ツールが呼び出されると、その応答が推論シーケンスに追加され、新しい証拠とともにコンテキストが提供されます。エージェントが候補の回答を提案すると、検証モジュールがそれを検証し、現在のシーケンスを続行するか、残りの予算で新しい試行を開始するかを決定します。</p><p>予算化されたリソースが使い果たされると、反復プロセスは終了し、その時点でLLMとしての審査員が検証されたすべての回答の中から最適な回答を選択します。実行全体を通して、バジェットトラッカーはすべての反復でリソースの使用量と残りの予算の両方を継続的に更新します。</p><p>研究者たちは、標準のReActやさまざまなトレーニングベースのエージェントを含むベースラインに対して、BrowseComp、BrowseComp-ZH、およびHLE-SearchベンチマークでBATSをテストしました。彼らの実験は、BATSが競合する方法よりも少ないツール呼び出しを使用し、全体的なコストを低く抑えながら、より高いパフォーマンスを達成することを示しています。Gemini 2.5 Proをバックボーンとして使用すると、BATSはBrowseCompで24.6％の精度を達成しましたが、標準のReActでは12.6％、HLE-Searchでは27.0％、ReActでは20.5％でした。</p><p>BATSは、予算制約下での有効性を向上させるだけでなく、より優れたコストパフォーマンスのトレードオフももたらします。たとえば、BrowseCompデータセットでは、BATSは約23セントのコストでより高い精度を達成しましたが、同様の結果を達成するには、パラレルスケーリングのベースラインでは50セント以上が必要でした。</p><p>著者らによると、この効率により、以前は高価だったワークフローが実現可能になります。「これにより、複雑なコードベースのメンテナンス、デューデリジェンス調査、競争環境調査、コンプライアンス監査、および複数ステップのドキュメント分析など、長期的なデータ集約型のエンタープライズアプリケーションが利用可能になります」と彼らは述べています。</p><p>企業が独自のリソースを管理するエージェントを導入しようとするにつれて、コストと精度をバランスさせる能力が重要な設計要件になります。</p><p>「推論と経済の関係は切り離せなくなると思います」とWangとLiuは述べています。「将来的には、[モデル]は価値について推論する必要があります。」</p>",
    "insightJa": "この技術により、企業はAIエージェントの運用コストを削減しつつ、複雑なタスクをより効率的に実行できるようになります。これにより、今までコスト面で難しかったAIのビジネス活用が広がる可能性があります。",
    "recommendedBooks": [
      "AIエージェント",
      "大規模言語モデル 実践",
      "AI プロダクト開発"
    ],
    "tags": [
      "LLM",
      "AI Agent",
      "Budget Aware Scaling",
      "Tool Use",
      "Google"
    ]
  },
  {
    "id": "6h3LTzDwRwKFT22aRVaumY",
    "title": "GPT-5.2 first impressions: a powerful update, especially for business tasks and workflows",
    "source": "rss",
    "url": "https://venturebeat.com/ai/gpt-5-2-first-impressions-a-powerful-update-especially-for-business-tasks",
    "summary": "OpenAI has officially released GPT-5.2, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming \"incremental\" update for casual conversationalists.\nFollowing early access periods and today's broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. \nHere is a roundup of the first reactions to OpenAI’s latest flagship model.\n\"AI as a serious analyst\"\nThe strongest praise for GPT-5.2 centers on its ability to handle \"hard problems\" that require extended thinking time.\nMatt Shumer, CEO of HyperWriteAI, did not mince words in his review, calling GPT-5.2 Pro \"the best model in the world.\" \nShumer highlighted the model's tenacity, noting that \"it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.\"\nThis sentiment was echoed by Allie K. Miller, an AI entrepreneur and former AWS executive. Miller described the model as a step toward \"AI as a serious analyst\" rather than a \"friendly companion.\"\n\"The thinking and problem-solving feel noticeably stronger,\" Miller wrote on X. \"It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.\"\nEnterprise gains: Box reports distinct performance jumps\nFor the enterprise sector, the update appears to be even more significant. \nAaron Levie, CEO of Box, revealed on X that his company has been testing GPT-5.2 in early access. Levie reported that the model performs \"7 points better than GPT-5.1\" on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.\n\"The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,\" Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.\nRutuja Rajwade, a Senior Product Marketing Manager at Box, expanded on this in a company blog post, citing specific latency improvements. \n\"Complex extraction\" tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. \nRajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.\nA \"serious leap\" for coding and simulation\nDevelopers are finding GPT-5.2 particularly potent for \"one-shot\" generation of complex code structures.\nPietro Schirano, CEO of magicpathai, shared a video of the model building a full 3D graphics engine in a single file with interactive controls. \"It’s a serious leap forward in complex reasoning, math, coding, and simulations,\" Schirano posted. \"The pace of progress is unreal.\"\n\nSimilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, demonstrated the model's ability to create a visually complex shader—an infinite neo-gothic city in a stormy ocean—via a single prompt.\nThe Agentic Era: Long-running autonomy\nPerhaps the most functional shift is the model's ability to stay on task for hours without losing the thread.\nDan Shipper, CEO of thoughtful AI testing newsletter Every, reported that the model successfully performed a profit and loss (P&L) analysis that required it to work autonomously for two hours. \"It did a P&L analysis where it worked for 2 hours and gave me great results,\" Shipper wrote.\nHowever, Shipper also noted that for day-to-day tasks, the update feels \"mostly incremental.\" \nIn an article for Every, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is \"less resourceful\" than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user's location from email data.\nThe downsides: Speed and Rigidity\nDespite the reasoning capabilities, the \"feel\" of the model has drawn critique.\nShumer highlighted a significant \"speed penalty\" when using the model's Thinking mode. \"In my experience the Thinking mode is very slow for most questions,\" Shumer wrote in his deep-dive review. \"I almost never use Instant.\"\nAllie Miller also pointed out issues with the model's default behavior. \"The downside is tone and format,\" she noted. \"The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.\"\nThe Verdict\nThe early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: \"For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.\"\nHowever, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. \"My favorite model remains Claude Opus 4.5,\" Miller admitted, \"but my complex ChatGPT work will get a nice incremental boost.\"",
    "publishedAt": "Thu, 11 Dec 2025 23:26:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>OpenAI has officially <a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">released GPT-5.2</a>, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming &quot;incremental&quot; update for casual conversationalists.</p><p>Following early access periods and today&#x27;s broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. </p><p>Here is a roundup of the first reactions to OpenAI’s latest flagship model.</p><h3><b>&quot;AI as a serious analyst&quot;</b></h3><p>The strongest praise for GPT-5.2 centers on its ability to handle &quot;hard problems&quot; that require extended thinking time.</p><p>Matt Shumer, CEO of HyperWriteAI, did not mince words in <a href=\"https://shumer.dev/gpt52review\">his review</a>, calling GPT-5.2 Pro &quot;the best model in the world.&quot; </p><p>Shumer highlighted the model&#x27;s tenacity, noting that &quot;it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.&quot;</p><p>This sentiment was<a href=\"https://x.com/alliekmiller/status/1999189893910790427\"> echoed by Allie K. Miller</a>, an AI entrepreneur and former AWS executive. Miller described the model as a step toward &quot;AI as a serious analyst&quot; rather than a &quot;friendly companion.&quot;</p><p>&quot;The thinking and problem-solving feel noticeably stronger,&quot; Miller wrote on X. &quot;It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.&quot;</p><h3><b>Enterprise gains: Box reports distinct performance jumps</b></h3><p>For the enterprise sector, the update appears to be even more significant. </p><p><a href=\"https://x.com/levie/status/1999191612321391058\">Aaron Levie, CEO of Box, revealed on X</a> that his company has been testing GPT-5.2 in early access. Levie reported that the model performs &quot;7 points better than GPT-5.1&quot; on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.</p><p>&quot;The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,&quot; Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.</p><p>Rutuja Rajwade, a Senior Product Marketing Manager at Box, <a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">expanded on this in a company blog post</a>, citing specific latency improvements. </p><p>&quot;Complex extraction&quot; tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. </p><p>Rajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.</p><h3><b>A &quot;serious leap&quot; for coding and simulation</b></h3><p>Developers are finding GPT-5.2 particularly potent for &quot;one-shot&quot; generation of complex code structures.</p><p>Pietro Schirano, CEO of magicpathai, <a href=\"https://x.com/skirano/status/1999182295685644366\">shared a video </a>of the model building a full 3D graphics engine in a single file with interactive controls. &quot;It’s a serious leap forward in complex reasoning, math, coding, and simulations,&quot; Schirano posted. &quot;The pace of progress is unreal.&quot;</p><div></div><p>S<!-- -->imilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, <a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">demonstrated the model&#x27;s ability to create a visually complex shader</a>—an infinite neo-gothic city in a stormy ocean—via a single prompt.</p><h3><b>The Agentic Era: Long-running autonomy</b></h3><p>Perhaps the most functional shift is the model&#x27;s ability to stay on task for hours without losing the thread.</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">Dan Shipper, CEO of thoughtful AI testing newsletter Every</a>, reported that the model successfully performed a profit and loss (P&amp;L) analysis that required it to work autonomously for two hours. &quot;It did a P&amp;L analysis where it worked for 2 hours and gave me great results,&quot; Shipper wrote.</p><p>However, Shipper also noted that for day-to-day tasks, the update feels &quot;mostly incremental.&quot; </p><p>In <a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">an article for Every</a>, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is &quot;less resourceful&quot; than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user&#x27;s location from email data.</p><h3><b>The downsides: Speed and Rigidity</b></h3><p>Despite the reasoning capabilities, the &quot;feel&quot; of the model has drawn critique.</p><p>Shumer highlighted a significant &quot;speed penalty&quot; when using the model&#x27;s Thinking mode. &quot;In my experience the Thinking mode is very slow for most questions,&quot; Shumer wrote in his deep-dive review. &quot;I almost never use Instant.&quot;</p><p>Allie Miller also pointed out issues with the model&#x27;s default behavior. &quot;The downside is tone and format,&quot; she noted. &quot;The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.&quot;</p><h3><b>The Verdict</b></h3><p>The early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: &quot;For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.&quot;</p><p>However, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. &quot;My favorite model remains Claude Opus 4.5,&quot; Miller admitted, &quot;but my complex ChatGPT work will get a nice incremental boost.&quot;</p>",
    "titleJa": "GPT-5.2 初期印象：ビジネス用途とワークフローに特化した強力なアップデート",
    "summaryJa": "GPT-5.2は高度な推論とコーディングに優れる一方、カジュアルな会話用途では進歩が限定的。企業ではパフォーマンス向上が見られ、開発者からはコーディング能力が評価されている。",
    "explanationJa": "GPT-5.2は、特にビジネスや専門的なタスクにおいて、非常に強力な性能を発揮するAIモデルと言えるでしょう。",
    "translationJa": "<p>OpenAIは正式に<a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">GPT-5.2をリリース</a>しました。初期テスターからの反応（OpenAIは一般公開の数日前、場合によっては数週間前にモデルを配布していました）は、二つの側面を描き出しています。それは、深く自律的な推論とコーディングにおいて飛躍的な進歩である一方で、カジュアルな会話をする人々にとっては「漸進的な」アップデートにとどまる可能性があるということです。</p><p>初期アクセス期間とその後の広範な展開を受け、経営幹部、開発者、アナリストはX（旧Twitter）や企業のブログで最初のテスト結果を共有しています。</p><p>OpenAIの最新フラッグシップモデルに対する最初の反応をまとめました。</p><h3><b>「真剣なアナリストとしてのAI」</b></h3><p>GPT-5.2に対する最も強い称賛は、長い思考時間を必要とする「難しい問題」を処理する能力に集中しています。</p><p>HyperWriteAIのCEOであるMatt Shumerは、<a href=\"https://shumer.dev/gpt52review\">彼のレビュー</a>で率直に、GPT-5.2 Proを「世界最高のモデル」と呼んでいます。</p><p>Shumerはモデルの粘り強さを強調し、「難しい問題について**1時間以上**考えます。そして、他のモデルでは対応できないタスクをこなします」と述べています。</p><p>この感情は、AI起業家であり元AWS幹部である<a href=\"https://x.com/alliekmiller/status/1999189893910790427\">Allie K. Millerによっても同様に示されています</a>。Millerは、このモデルを「友好的な仲間」というよりは「真剣なアナリストとしてのAI」への一歩と表現しました。</p><p>「思考力と問題解決力は明らかに強力になっていると感じます」とMillerはXに書いています。「私がこれまで見てきたものよりもはるかに深い説明をしてくれます。ある時点で、タスクの途中で独自のOCRを改善するコードを文字通り書いていました。」</p><h3><b>企業のメリット：Boxは明確なパフォーマンスの向上を報告</b></h3><p>企業セクターにとって、このアップデートはさらに重要なものになるようです。</p><p><a href=\"https://x.com/levie/status/1999191612321391058\">BoxのCEOであるAaron Levieは、Xで</a>、彼の会社がGPT-5.2を早期アクセスでテストしていることを明らかにしました。Levieは、このモデルが、金融サービスやライフサイエンスにおける現実世界の知識労働を近似する拡張された推論テストで「GPT-5.1よりも7ポイント優れている」と報告しました。</p><p>「このモデルは、GPT-5.1やGPT-5よりもはるかに高速にタスクの大部分を実行しました」とLevieは述べ、Box AIがGPT-5.2の統合を間もなく展開することを発表しました。</p><p>BoxのシニアプロダクトマーケティングマネージャーであるRutuja Rajwadeは、<a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">企業のブログ記事</a>でこれをさらに詳しく説明し、具体的なレイテンシの改善を挙げています。</p><p>「複雑な抽出」タスクは、GPT-5では46秒かかっていたのが、GPT-5.2ではわずか12秒に短縮されました。</p><p>Rajwadeはまた、メディアおよびエンターテインメント分野における推論能力の向上も指摘し、GPT-5.1の76％の精度から新しいモデルでは81％に上昇しています。</p><h3><b>コーディングとシミュレーションにおける「重大な飛躍」</b></h3><p>開発者は、GPT-5.2が複雑なコード構造の「ワンショット」生成に特に強力であると考えています。</p><p>magicpathaiのCEOであるPietro Schiranoは、<a href=\"https://x.com/skirano/status/1999182295685644366\">インタラクティブなコントロールを備えた完全な3Dグラフィックスエンジンを1つのファイルで構築する</a>モデルのビデオを共有しました。「複雑な推論、数学、コーディング、シミュレーションにおいて重大な飛躍です」とSchiranoは投稿しました。「進歩のペースは非現実的です。」</p><div></div><p>同様に、ペンシルベニア大学ウォートンスクールの教授であり、長年のLLMおよびAIのパワーユーザーおよびライターであるEthan Mollickは、<a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">モデルが単一のプロンプトを介して視覚的に複雑なシェーダー、嵐の海に浮かぶ無限のネオゴシック都市を作成する能力</a>を実証しました。</p><h3><b>エージェントの時代：長時間の自律性</b></h3><p>おそらく最も機能的な変化は、モデルが糸口を見失うことなく何時間もタスクを実行し続ける能力です。</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">思慮深いAIテストニュースレターEveryのCEOであるDan Shipper</a>は、モデルが2時間自律的に作業する必要のある損益（P＆L）分析を正常に実行したと報告しました。「2時間作業して素晴らしい結果をもたらすP＆L分析を行いました」とShipperは書いています。</p><p>ただし、Shipperは、日々のタスクでは、アップデートは「ほとんど漸進的」に感じられるとも指摘しています。</p><p><a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">Everyの記事</a>で、Katie Parrottは、GPT-5.2は指示の追跡に優れているものの、電子メールデータからユーザーの場所を推測するなど、特定のコンテキストではClaude Opus 4.5のような競合他社よりも「資源が少ない」と書いています。</p><h3><b>短所：速度と柔軟性の欠如</b></h3><p>推論能力にもかかわらず、モデルの「感触」には批判が集まっています。</p><p>Shumerは、モデルのThinkingモードを使用する際の大きな「速度の低下」を強調しました。「私の経験では、Thinkingモードはほとんどの質問に対して非常に遅いです」とShumerは彼の詳細なレビューで書いています。「私はほとんどInstantを使用しません。」</p><p>Allie Millerはまた、モデルのデフォルトの動作に関する問題も指摘しました。「短所は口調と形式です」と彼女は述べました。「デフォルトの声は少し硬く感じられ、長さ/マークダウンの動作は極端です。簡単な質問が58個の箇条書きと番号付きのポイントに変わりました。」</p><h3><b>結論</b></h3><p>初期の反応は、GPT-5.2がカジュアルなチャットではなく、パワーユーザー、開発者、エンタープライズエージェント向けに最適化されたツールであることを示唆しています。Shumerが彼のレビューで要約したように、「深い調査、複雑な推論、および慎重な思考から恩恵を受けるタスクにとって、GPT-5.2 Proは現在利用可能な最良のオプションです。」</p><p>ただし、クリエイティブライティングや迅速で流動的な回答を求めるユーザーにとって、Claude Opus 4.5のようなモデルは依然として強力な競合他社です。「私のお気に入りのモデルはClaude Opus 4.5のままです」とMillerは認めました。「しかし、私の複雑なChatGPTの作業は、素晴らしい漸進的な後押しを受けるでしょう。」</p>",
    "insightJa": "GPT-5.2の登場により、企業の業務効率化や高度な専門分野でのAI活用がさらに進むことが期待されます。一方で、日常的な用途では他のモデルも依然として有効であり、目的に応じた使い分けが重要になるでしょう。",
    "recommendedBooks": [
      "GPT-5.2 解説",
      "大規模言語モデル 活用",
      "AI ビジネス応用"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "Large Language Model",
      "AI for Business",
      "Coding"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.10957v1",
    "title": "SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10957v1",
    "summary": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "publishedAt": "2025-12-11T18:59:56Z",
    "author": "Yukai Shi",
    "category": "AI",
    "originalContent": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "titleJa": "SceneMaker：分離型デ・オクルージョンと姿勢推定モデルによるオープンセット3Dシーン生成",
    "summaryJa": "本研究ではSceneMakerという分離型3Dシーン生成フレームワークを提案。既存手法の課題を克服するため、デ・オクルージョンモデルを分離し、姿勢推定モデルを統合。オープンセット環境での性能を向上。",
    "explanationJa": "SceneMakerは、隠れた部分を予測し、物体の正確な位置を特定することで、様々な3Dシーンを生成する技術です。",
    "translationJa": "本研究では、SceneMakerと呼ばれる分離型3Dシーン生成フレームワークを提案します。既存の手法では、十分なオープンセットのデ・オクルージョンと姿勢推定の事前知識が不足しているため、深刻なオクルージョンやオープンセット環境下で高品質な形状と正確な姿勢を同時に生成することが困難です。これらの課題に対処するため、まず、デ・オクルージョンモデルを3Dオブジェクト生成から分離し、画像データセットと収集されたデ・オクルージョンデータセットを活用して、より多様なオープンセットのオクルージョンパターンに対応できるように強化します。次に、自己注意と交差注意の両方に対してグローバルメカニズムとローカルメカニズムを統合した、統一された姿勢推定モデルを提案し、精度を向上させます。さらに、姿勢推定モデルの汎化性能を拡張するために、オープンセット3Dシーンデータセットを構築します。広範な実験により、屋内シーンとオープンセットシーンの両方において、提案する分離型フレームワークの優位性が示されています。コードとデータセットは、https://idea-research.github.io/SceneMaker/ で公開されています。",
    "insightJa": "この技術は、ゲームや映画制作における3D環境の自動生成、ロボット工学における環境認識の向上、そして商品の配置シミュレーションなどに役立つ可能性があります。よりリアルなバーチャル体験や効率的な業務支援に繋がることが期待されます。",
    "recommendedBooks": [
      "3Dグラフィックス 理論",
      "コンピュータビジョン 実践",
      "機械学習 3Dデータ"
    ],
    "tags": [
      "3D Scene Generation",
      "De-occlusion",
      "Pose Estimation",
      "Open-set Learning",
      "SceneMaker"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.10952v1",
    "title": "Hierarchical Dataset Selection for High-Quality Data Sharing",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10952v1",
    "summary": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Xiaona Zhou",
    "category": "AI",
    "originalContent": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "titleJa": "高品質なデータ共有のための階層型データセット選択",
    "summaryJa": "機械学習の成功は高品質な学習データに依存。DaSHは、データセットとグループレベルで有用性をモデル化し、リソース制約下でデータセットを選択、性能を向上させます。",
    "explanationJa": "DaSHは、効率的にデータセットを選び、機械学習の精度を向上させる技術です。",
    "translationJa": "現代の機械学習の成功は、高品質な学習データへのアクセスにかかっています。多くの現実世界のシナリオ、例えば、公共リポジトリからのデータ取得や、機関間のデータ共有においては、データは自然に離散的なデータセットとして構成され、関連性、品質、有用性が異なります。したがって、有用なデータセットを探すためにどのリポジトリまたは機関を検索するか、およびモデルの学習にどのデータセットを組み込むかを選択することは、非常に重要な決定ですが、既存のほとんどの方法は個々のサンプルを選択し、すべてのデータを同じように関連性があるとみなし、データセットとそのソース間の違いを無視しています。本研究では、データセット選択のタスクを形式化します。これは、リソースの制約下で、下流のパフォーマンスを向上させるために、大規模で異質なプールからデータセット全体を選択するものです。我々は、Dataset Selection via Hierarchies (DaSH)という、データセットとグループ（例えば、コレクション、機関）レベルの両方で有用性をモデル化するデータセット選択手法を提案します。これにより、限られた観測からの効率的な一般化が可能になります。2つの公開ベンチマーク（Digit-FiveとDomainNet）において、DaSHは、最先端のデータ選択ベースラインを最大26.2％上回る精度を達成しており、同時に必要な探索ステップも大幅に削減しています。アブレーション実験により、DaSHは低リソース環境や関連データセットの不足に対して堅牢であり、実用的なマルチソース学習ワークフローにおけるスケーラブルで適応的なデータセット選択に適していることが示されています。",
    "insightJa": "この技術により、企業はより効率的に機械学習モデルを開発できるようになり、顧客サービスの向上や、より正確な市場予測が可能になることが期待されます。また、研究機関間でのデータ共有が促進され、医療や環境問題など、様々な分野での進歩に貢献する可能性があります。",
    "recommendedBooks": [
      "データサイエンス 入門",
      "機械学習 実践",
      "データ共有 ガイドライン"
    ],
    "tags": [
      "machine learning",
      "dataset selection",
      "data quality",
      "DaSH",
      "階層型データセット選択"
    ]
  },
  {
    "id": "http://arxiv.org/abs/2512.10949v1",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10949v1",
    "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "publishedAt": "2025-12-11T18:59:52Z",
    "author": "Yiwen Tang",
    "category": "AI",
    "originalContent": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "titleJa": "テキストからの3D生成における強化学習の準備はできているか？段階的な調査",
    "summaryJa": "本研究では、テキストから3Dモデルを生成する際に強化学習(RL)を適用する初の体系的調査を実施。報酬設計、RLアルゴリズム、ベンチマーク、階層的RLパラダイムを検討し、RL強化モデルAR3D-R1を開発。",
    "explanationJa": "テキストから3Dモデルを生成する技術に、強化学習という新しい方法を試す研究が行われ、より良い3Dモデルが作れるようになるかもしれません。",
    "translationJa": "強化学習（RL）は、大規模言語モデルやマルチモーダルモデルでその有効性が以前に証明されており、最近では2D画像生成を強化するためにも成功裏に拡張されています。しかし、3Dオブジェクトのより高い空間的複雑さのため、3D生成にRLを適用することは、ほとんど未開拓のままです。3Dオブジェクトは、グローバルに一貫した形状と、きめ細かいローカルテクスチャを必要とします。このため、3D生成は報酬設計とRLアルゴリズムに著しく影響を受けやすくなっています。これらの課題に対処するため、我々はテキストから3Dの自己回帰生成に対するRLの最初の体系的な研究をいくつかの側面から実施します。(1)報酬設計：報酬の次元とモデルの選択を評価し、人間の好みとの整合性が重要であること、および一般的なマルチモーダルモデルが3D属性に対してロバストな信号を提供することを示します。(2)RLアルゴリズム：GRPOのバリアントを研究し、トークンレベルの最適化の有効性を強調し、さらにトレーニングデータと反復回数のスケーリングを調査します。(3)テキストから3Dのベンチマーク：既存のベンチマークは3D生成モデルにおける暗黙的な推論能力を測定できないため、MME-3DRを導入します。(4)高度なRLパラダイム：3D生成の自然な階層構造に動機づけられ、グローバルからローカルへの階層的な3D生成を専用の報酬アンサンブルを通じて最適化するHi-GRPOを提案します。これらの洞察に基づいて、粗い形状からテクスチャの改良まで専門とする、最初のRL強化テキストから3DモデルであるAR3D-R1を開発しました。この研究が、3D生成のためのRL駆動型推論への洞察を提供することを願っています。コードは https://github.com/Ivan-Tang-3D/3DGen-R1 で公開されています。",
    "insightJa": "テキストから3Dモデルを生成する技術が進化することで、エンターテイメント業界や製品デザインなど、様々な分野でより手軽に3Dモデルを作成できるようになる可能性があります。例えば、ゲーム開発者はプログラミングだけで高品質な3Dモデルを生成し、より迅速な開発が可能になるかもしれません。",
    "recommendedBooks": [
      "3Dモデリング 入門",
      "強化学習 理論と実践",
      "AI デザイン"
    ],
    "tags": [
      "Reinforcement Learning",
      "Text-to-3D",
      "3D Generation",
      "Reward Design",
      "AR3D-R1"
    ]
  },
  {
    "id": "5AH2xqcQJzMolV09W5VM43",
    "title": "OpenAI's GPT-5.2 is here: what enterprises need to know",
    "source": "rss",
    "url": "https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know",
    "summary": "The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, GPT-5.2.\nIt comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival Google’s Gemini 3 LLM seized the top spot on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.\nOpenAI describes GPT-5.2 as its \"most capable model series yet for professional knowledge work,\" aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.\n\"It’s our most advanced frontier model and the strongest yet in the market for professional use,\" Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. \"We designed 5.2 to unlock even more economic value for people. It's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.\"\nGPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.\nThe model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes \"Reasoning token support,\" confirming the underlying architecture uses the chain-of-thought processing popularized by the \"o1\" series.\nThe 'Code Red' Reality Check\nThe release arrives following The Information's report of an emergency \"Code Red\" directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the \"quality gap\" exposed by Gemini 3. The Verge similarly reported on the timing of GPT-5.2's release ahead of the official announcement. \nDuring the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.\n\"It is important to note this has been in the works for many, many months,\" Simo told reporters. She clarified that while the \"Code Red\" helped focus the company, it wasn't the sole driver of the timeline. \n\"We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that's not the reason it's coming out this week in particular.\"\nMax Schwarzer, lead of OpenAI's post-training team, echoed this sentiment to dispel the idea of a panic launch. \"We've been planning for this release since a very long time ago... this specific week we talked about many months ago.\"\nA spokesperson from OpenAI further clarified that the \"Code Red\" call applied to ChatGPT as a product, not solely underlying model development or the release of new models.\nUnder the Hood: Instant, Thinking, and Pro\nOpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of \"reasoning\" models with user demand for speed:\n\nGPT-5.2 Instant: Optimized for speed and daily tasks like writing, translation, and information seeking.\n\nGPT-5.2 Thinking: Designed for \"complex, structured work\" and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.\n\nGPT-5.2 Pro: The new heavyweight champion. OpenAI describes this as its \"smartest and most trustworthy option,\" delivering the highest accuracy for difficult questions where quality outweighs latency.\n\nFor developers, the models are available immediately in the application programming interface (API) as gpt-5.2, gpt-5.2-chat-latest (Instant), and gpt-5.2-pro.\nThe Numbers: Beating the Benchmarks\nThe GPT-5.2 release includes leading metrics across most domains — specifically those that target the \"professional knowledge work\" gap where competitors have recently gained ground.\nOpenAI highlighted a new benchmark called GDPval, which measures performance on \"well-specified knowledge work tasks\" across 44 occupations. \n\"GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,\" Simo said.\nIn the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. \nHe emphasized that this benchmark is \"more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.\"Other key benchmark results include:\n\nGPQA Diamond (Science): GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).\n\nFrontierMath: On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.\n\nARC-AGI-1: GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring 90.5%\n\nThe Price of Intelligence\nPerformance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of \"thinking\" mode. They're also on the upper-end of API costs for the industry.  \n\nGPT-5.2 Thinking: Priced at $1.75 per 1 million input tokens and $14 per 1 million output tokens.\n\nGPT-5.2 Pro: The costs jump significantly to $21 per 1 million input tokens and $168 per 1 million output tokens.\n\nGPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.\nThe high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.\nOpenAI argues that despite the higher per-token cost, the model’s \"greater token efficiency\" and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.\nHere's how it compares to the current API costs for other competing models across the LLM field:\n\n\nModel\n\nInput (/1M)\n\nOutput (/1M)\n\nTotal Cost\n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nQwen 3 Plus\n\n$0.40\n\n$1.20\n\n$1.60\n\nAlibaba Cloud\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen-Max\n\n$1.60\n\n$6.40\n\n$8.00\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nClaude Opus 4.5\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nImage Generation: Nothing New Yet...But 'More to Come'\nDuring the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google's Gemini 3 Image aka Nano Banana Pro. \nUnfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI's integrated DALL-E 3 and gpt-4o native image generation models.\n\"On image Gen, nothing to announce today, but more to come,\" Simo said. She acknowledged the popularity of the feature, adding, \"We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.\" \nAidan Clark, OpenAI's lead of training, also declined to comment on visual generation specifics, stating simply, \"I can't really speak to image Gen myself.\" \nThe 'Mega-Agent' Era\nBeyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of \"long-running agents\" capable of executing multi-step workflows without human hand-holding.\"\nBox found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,\" Simo said. \nShe also noted that Notion reported the model \"outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.\"Schwarzer added that coding startups like Augment Code found the model \"delivered substantially stronger deep code capabilities than any prior model,\" which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. \nOpenAI's release blog post shows an example where \"a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.\"\nThe outcome? \"GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.\"\nA new evaluation called ScreenSpot-Pro, which tests a model's ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.\nScience and Reliability\nOpenAI leaders also stressed the model's utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. \nAidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.\n\"They tested it by asking it to generate the most important unanswered questions about the immune system,\" Clark said. \"That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.\n\"Reliability was another key focus. Schwarzer claimed the new model \"hallucinates substantially less than GPT-5.1,\" noting that on a set of de-identified queries, \"responses contained errors 38% less often.\"\nThe 'Vibe' Shift\nInterestingly, OpenAI acknowledged that not every user might immediately prefer the new models. \nWhen asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that \"models change a little bit every time.\n\"Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,\" Schwarzer said. He also noted that for some enterprise customers who have \"really fine-tuned a prompt for a specific model,\" there might be \"small regressions,\" necessitating access to the older versions.\nSafety, 'Adult Mode,' and Future Roadmap\nAddressing safety concerns, Simo confirmed that the company is preparing to roll out an \"Adult Mode\" in the first quarter of next year, following the implementation of a new age prediction system.\n\"We're in the process of improving that,\" Simo said regarding the age prediction technology. \n\"We want to do that ahead of launching adult mode.\"Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename \"Project Garlic,\" targeting a flagship release in early 2026. \nWhile executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.\n\"If you look at historical trends, compute has increased about 3x every year for the last three years,\" she explained. \"Revenue has also increased at the same pace... creating this virtuous cycle.\"\nClark added that efficiency is improving rapidly: \"The model we're releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it\" compared to models from a year ago.\nGPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.",
    "publishedAt": "Thu, 11 Dec 2025 18:16:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, <a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>.</p><p>It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival <a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">Google’s Gemini 3 LLM seized the top spot</a> on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.</p><p>OpenAI describes GPT-5.2 as its &quot;most capable model series yet for professional knowledge work,&quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.</p><p>&quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &quot;We designed 5.2 to unlock even more economic value for people. It&#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&quot;</p><p>GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.</p><p>The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &quot;Reasoning token support,&quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &quot;o1&quot; series.</p><h3><b>The &#x27;Code Red&#x27; Reality Check</b></h3><p>The release arrives following<i> </i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\"><i>The Information</i>&#x27;s report</a> of an emergency &quot;Code Red&quot; directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the &quot;quality gap&quot; exposed by Gemini 3.<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i> The Verge</i></a> similarly reported on the timing of GPT-5.2&#x27;s release ahead of the official announcement. </p><p>During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.</p><p>&quot;It is important to note this has been in the works for many, many months,&quot; Simo told reporters. She clarified that while the &quot;Code Red&quot; helped focus the company, it wasn&#x27;t the sole driver of the timeline. </p><p>&quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&#x27;s not the reason it&#x27;s coming out this week in particular.&quot;</p><p>Max Schwarzer, lead of OpenAI&#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &quot;We&#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&quot;</p><p>A spokesperson from OpenAI further clarified that the &quot;Code Red&quot; call applied to ChatGPT as a product, not solely underlying model development or the release of new models.</p><h3><b>Under the Hood: Instant, Thinking, and Pro</b></h3><p>OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &quot;reasoning&quot; models with user demand for speed:</p><ul><li><p><b>GPT-5.2 Instant:</b> Optimized for speed and daily tasks like writing, translation, and information seeking.</p></li><li><p><b>GPT-5.2 Thinking:</b> Designed for &quot;complex, structured work&quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.</p></li><li><p><b>GPT-5.2 Pro:</b> The new heavyweight champion. OpenAI describes this as its &quot;smartest and most trustworthy option,&quot; delivering the highest accuracy for difficult questions where quality outweighs latency.</p></li></ul><p>For developers, the models are available immediately in the application programming interface (API) as <code>gpt-5.2</code>, <code>gpt-5.2-chat-latest</code> (Instant), and <code>gpt-5.2-pro</code>.</p><h3><b>The Numbers: Beating the Benchmarks</b></h3><p>The GPT-5.2 release includes leading metrics across most domains — specifically those that target the &quot;professional knowledge work&quot; gap where competitors have recently gained ground.</p><p>OpenAI highlighted a new benchmark called GDPval, which measures performance on &quot;well-specified knowledge work tasks&quot; across 44 occupations. </p><p>&quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&quot; Simo said.</p><p>In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. </p><p>He emphasized that this benchmark is &quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&quot;Other key benchmark results include:</p><ul><li><p><b>GPQA Diamond (Science):</b> GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).</p></li><li><p><b>FrontierMath:</b> On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.</p></li><li><p><b>ARC-AGI-1:</b> GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring <b>90.5%</b></p></li></ul><h3><b>The Price of Intelligence</b></h3><p>Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &quot;thinking&quot; mode. They&#x27;re also on the upper-end of API costs for the industry.  </p><ul><li><p><b>GPT-5.2 Thinking:</b> Priced at <b>$1.75</b> per 1 million input tokens and <b>$14</b> per 1 million output tokens.</p></li><li><p><b>GPT-5.2 Pro:</b> The costs jump significantly to <b>$21</b> per 1 million input tokens and <b>$168</b> per 1 million output tokens.</p></li></ul><p>GPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.</p><p>The high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.</p><p>OpenAI argues that despite the higher per-token cost, the model’s &quot;greater token efficiency&quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.</p><p>Here&#x27;s how it compares to the current API costs for other competing models across the LLM field:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1M)</b></p></td><td><p><b>Output (/1M)</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>Image Generation: Nothing New Yet...But &#x27;More to Come&#x27;</b></h3><p>During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&#x27;s Gemini 3 Image aka Nano Banana Pro. </p><p>Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&#x27;s integrated DALL-E 3 and gpt-4o native image generation models.</p><p>&quot;On image Gen, nothing to announce today, but more to come,&quot; Simo said. She acknowledged the popularity of the feature, adding, &quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&quot; </p><p>Aidan Clark, OpenAI&#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &quot;I can&#x27;t really speak to image Gen myself.&quot; </p><h3><b>The &#x27;Mega-Agent&#x27; Era</b></h3><p>Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &quot;long-running agents&quot; capable of executing multi-step workflows without human hand-holding.&quot;</p><p>Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&quot; Simo said. </p><p>She also noted that Notion reported the model &quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&quot;Schwarzer added that coding startups like Augment Code found the model &quot;delivered substantially stronger deep code capabilities than any prior model,&quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. </p><p>OpenAI&#x27;s release blog post shows an example where &quot;a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.&quot;</p><p>The outcome? &quot;GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.&quot;</p><p>A new evaluation called ScreenSpot-Pro, which tests a model&#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.</p><h3><b>Science and Reliability</b></h3><p>OpenAI leaders also stressed the model&#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. </p><p>Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.</p><p>&quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&quot; Clark said. &quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.</p><p>&quot;Reliability was another key focus. Schwarzer claimed the new model &quot;hallucinates substantially less than GPT-5.1,&quot; noting that on a set of de-identified queries, &quot;responses contained errors 38% less often.&quot;</p><h3><b>The &#x27;Vibe&#x27; Shift</b></h3><p>Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. </p><p>When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &quot;models change a little bit every time.</p><p>&quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&quot; Schwarzer said. He also noted that for some enterprise customers who have &quot;really fine-tuned a prompt for a specific model,&quot; there might be &quot;small regressions,&quot; necessitating access to the older versions.</p><h3><b>Safety, &#x27;Adult Mode,&#x27; and Future Roadmap</b></h3><p>Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &quot;Adult Mode&quot; in the first quarter of next year, following the implementation of a new age prediction system.</p><p>&quot;We&#x27;re in the process of improving that,&quot; Simo said regarding the age prediction technology. </p><p>&quot;We want to do that ahead of launching adult mode.&quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &quot;Project Garlic,&quot; targeting a flagship release in early 2026. </p><p>While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.</p><p>&quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&quot; she explained. &quot;Revenue has also increased at the same pace... creating this virtuous cycle.&quot;</p><p>Clark added that efficiency is improving rapidly: &quot;The model we&#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&quot; compared to models from a year ago.</p><p>GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.</p>",
    "titleJa": "OpenAIのGPT-5.2が登場：企業が知っておくべきこと",
    "summaryJa": "OpenAIがGPT-5.2を発表。推論、コーディング、エージェント機能が向上。3つのモデルを提供し、API価格は高め。科学研究への応用や安全性も強調。",
    "explanationJa": "OpenAIの新しい高性能なAIモデルGPT-5.2が登場し、より複雑なタスクに対応できるようになりました。",
    "translationJa": "<p>噂は本当でした。OpenAIは木曜日、新しい最先端の大規模言語モデル（LLM）ファミリー、<a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>を発表しました。</p><p>ライバルの<a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">GoogleのGemini 3 LLMが主要な第三者機関のパフォーマンスリーダーボードでトップの座を獲得</a>し、先月多くの主要なベンチマークを達成して以来、激化するプレッシャーに直面しているAIのパイオニアにとって、これは重要なタイミングでの発表となります。ただし、OpenAIのリーダーたちは記者会見で、今回のリリースはGemini 3のリリースよりもずっと前から議論され、取り組まれてきたものであることを強調しました。</p><p>OpenAIはGPT-5.2を「プロフェッショナルな知識労働においてこれまでで最も有能なモデルシリーズ」と説明し、推論、コーディング、エージェントのワークフローにおける大幅な向上により、パフォーマンスの王座を取り戻すことを目指しています。</p><p>「これは当社の最先端モデルであり、プロフェッショナルな用途において市場で最も強力なものです」と、OpenAIのアプリケーション担当CEOであるFidji Simoは今日の記者会見で述べました。「5.2は、人々にとってさらに多くの経済的価値を引き出すように設計しました。スプレッドシートの作成、プレゼンテーションの構築、コードの記述、画像の認識、長いコンテキストの理解、ツールの使用、および複雑な複数ステップのプロジェクトの処理がより得意です。」</p><p>GPT-5.2は、400,000トークンという大規模なコンテキストウィンドウを備えており、一度に数百のドキュメントまたは大規模なコードリポジトリを取り込むことができます。また、最大出力トークン制限は128,000であり、広範なレポートや完全なアプリケーションを一度に生成できます。</p><p>このモデルは、2025年8月31日の知識カットオフも特徴としており、比較的新しい世界的な出来事や技術ドキュメントに遅れないようにしています。明示的に「推論トークンのサポート」を含んでおり、基盤となるアーキテクチャが「o1」シリーズで普及した連鎖的思考処理を使用していることを確認しています。</p><h3><b>「コードレッド」現実チェック</b></h3><p>今回のリリースは、<a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\"><i>The Information</i>のレポート</a>に続くもので、ChatGPTを改善するためにCEOのSam AltmanからOpenAIのスタッフへの緊急「コードレッド」指令が報告されています。これは、Gemini 3によって露呈した「品質のギャップ」を受けてリソースを動員するように設計された動きであると報告されています。<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i>The Verge</i></a>も同様に、公式発表に先立ちGPT-5.2のリリース時期について報告しました。</p><p>記者会見中、OpenAIの幹部は指令を認めましたが、このモデルがGoogleに対応するためだけに急いで作成されたという見方を否定しました。</p><p>「これは何ヶ月も前から取り組んできたものであることに注意することが重要です」とSimoは記者団に語りました。彼女は、「コードレッド」が会社を集中させるのに役立った一方で、それがタイムラインの唯一の推進力ではなかったことを明らかにしました。</p><p>「このコードレッドを発表したのは、特定の分野にリソースを投入したいということを会社に伝えるためですが...それが特に今週公開される理由ではありません。」</p><p>OpenAIのポストトレーニングチームのリーダーであるMax Schwarzerは、パニックローンチという考えを払拭するために、この感情を繰り返しました。「私たちは非常に長い間このリリースを計画してきました...この特定の週については数ヶ月前に話し合いました。」</p><p>OpenAIの広報担当者はさらに、「コードレッド」の呼び出しは、新しいモデルの基盤となるモデル開発またはリリースだけではなく、製品としてのChatGPTに適用されることを明らかにしました。</p><h3><b>内部構造：インスタント、シンキング、プロ</b></h3><p>OpenAIは、GPT-5.2のリリースをChatGPT内で3つの異なる階層に分割しています。これは、「推論」モデルの大規模な計算コストと、速度に対するユーザーの需要のバランスを取るように設計された戦略であると考えられます。</p><ul><li><p><b>GPT-5.2インスタント：</b>書き込み、翻訳、情報検索などの速度と日常的なタスクに最適化されています。</p></li><li><p><b>GPT-5.2シンキング：</b>「複雑で構造化された作業」および長期実行エージェント向けに設計されたこのモデルは、より深い推論チェーンを活用して、コーディング、数学、および複数ステップのプロジェクトを処理します。</p></li><li><p><b>GPT-5.2プロ：</b>新しいヘビーウェイトチャンピオン。OpenAIはこれを「最も賢く、最も信頼できるオプション」と説明しており、品質が遅延よりも重要な難しい質問に対して最高の精度を提供します。</p></li></ul><p>開発者向けに、これらのモデルはアプリケーションプログラミングインターフェイス（API）で<code>gpt-5.2</code>、<code>gpt-5.2-chat-latest</code>（インスタント）、および<code>gpt-5.2-pro</code>としてすぐに利用できます。</p><h3><b>数値：ベンチマークの打ち負かし</b></h3><p>GPT-5.2のリリースには、ほとんどのドメインにわたる主要な指標が含まれています。特に、競合他社が最近勢いを増している「プロフェッショナルな知識労働」のギャップをターゲットとしたものです。</p><p>OpenAIは、44の職業にわたる「適切に指定された知識労働タスク」のパフォーマンスを測定するGDPvalと呼ばれる新しいベンチマークを強調しました。</p><p>「GPT-5.2シンキングは現在、そのベンチマークで最先端であり...専門家の人間による審査によると、スプレッドシート、プレゼンテーション、ドキュメントの作成など、適切に指定されたプロフェッショナルタスクの70.9％で業界のトッププロを打ち負かすか、肩を並べています」とSimoは述べています。</p><p>コーディングの重要な分野で、OpenAIは決定的なリードを主張しています。Schwarzerは、実際のソフトウェアエンジニアリングの厳密な評価であるSWE-bench Proで、GPT-5.2シンキングが55.6％という新しい最先端のスコアを設定していると述べました。</p><p>彼は、このベンチマークは「SWE-bench Verifiedなどの以前のベンチマークよりも汚染耐性があり、挑戦的で、多様で、産業関連性が高い」ことを強調しました。その他の主要なベンチマーク結果は次のとおりです。</p><ul><li><p><b>GPQAダイヤモンド（科学）：</b>GPT-5.2プロは93.2％のスコアを獲得し、GPT-5.2シンキング（92.4％）をわずかに上回り、GPT-5.1シンキング（88.1％）を上回りました。</p></li><li><p><b>FrontierMath：</b>ティア1〜3の問題で、GPT-5.2シンキングは40.3％を解決し、前任者の31.0％から大幅に向上しました。</p></li><li><p><b>ARC-AGI-1：</b>GPT-5.2プロは、この一般的な推論ベンチマークで90％のしきい値を超えた最初のモデルであると報告されており、<b>90.5％</b>のスコアを獲得しています</p></li></ul><h3><b>知性の代償</b></h3><p>パフォーマンスにはプレミアムが付きます。ChatGPTのサブスクリプション価格は今のところ変更されていませんが、新しいフラッグシップモデルのAPIコストは以前の世代と比較して高額であり、「シンキング」モードの高い計算需要を反映しています。また、業界のAPIコストの上限にあります。</p><ul><li><p><b>GPT-5.2シンキング：</b>100万入力トークンあたり<b>$1.75</b>、100万出力トークンあたり<b>$14</b>で価格設定されています。</p></li><li><p><b>GPT-5.2プロ：</b>コストは大幅に上昇し、100万入力トークンあたり<b>$21</b>、100万出力トークンあたり<b>$168</b>になります。</p></li></ul><p>GPT-5.2シンキングは、標準のGPT-5.1（$1.25/$10）よりもAPIで40％高い価格設定であり、OpenAIが新しい推論機能を単なる効率の向上ではなく、具体的な付加価値と見なしていることを示しています。</p><p>ハイエンドのGPT-5.2プロも同じパターンに従い、以前のGPT-5プロ（$15/$120）よりも40％高くなっています。高価ですが、OpenAIの最も専門的な推論モデルであるo1-proよりも依然として低価格であり、100万入力トークンあたり150ドル、100万出力トークンあたり600ドルという驚異的な価格で、メニューで最も高価な製品のままです。</p><p>OpenAIは、トークンあたりのコストが高くても、モデルの「トークン効率の向上」と、より少ないターンでタスクを解決できる能力により、高価値のエンタープライズワークフローにとって経済的に実行可能であると主張しています。</p><p>LLM分野の他の競合モデルの現在のAPIコストと比較すると、次のようになります。</p><table><tbody><tr><td><p><b>モデル</b></p></td><td><p><b>入力（/1M）</b></p></td><td><p><b>出力（/1M）</b></p></td><td><p><b>合計コスト</b></p></td><td><p><b>ソース</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (推論)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (非推論)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>画像生成：まだ新しいものはありません...しかし「これからもっと」</b></h3><p>記者会見中、VentureBeatはOpenAIの参加者に、新しいリリースに画像生成機能の向上が含まれているかどうかを尋ね、GoogleのGemini 3 Image（別名Nano Banana Pro）のような最近の競合他社のローンチにおける同様の機能に対する興奮を指摘しました。</p><p>テキストと情報が豊富なグラフィックスや画像編集機能を再現しようとしている人にとっては残念ながら、OpenAIの幹部はGPT-5.2には、以前のGPT-5.1およびOpenAIの統合されたDALL-E 3およびgpt-4oネイティブ画像生成モデルに対する現在の画像改善はないことを明らかにしました。</p><p>「画像生成に関しては、今日発表するものはありませんが、これからもっとあります」とSimoは述べました。彼女は、この機能の人気を認め、「これは人々が愛する非常に重要なユースケースであり、私たちが市場に導入したものであり、間違いなくこれからもっとあります」と付け加えました。</p><p>OpenAIのトレーニング責任者であるAidan Clarkも、ビジュアル生成の詳細についてコメントすることを控え、「私は画像生成についてあまり話せません」と述べました。</p><h3><b>「メガエージェント」時代</b></h3><p>OpenAIは、生のスコアを超えて、GPT-5.2を人間の介入なしに複数ステップのワークフローを実行できる新世代の「長期実行エージェント」のエンジンとして位置付けています。</p><p>Boxは、5.2が長く複雑なドキュメントから情報を約40％速く抽出できることを発見し、ライフサイエンスとヘルスケアの推論精度が40％向上したことも確認しました」とSimoは述べています。</p><p>彼女はまた、Notionがモデルが「あらゆる次元で5.1を上回り...実際の知識労働を定義する種類の本当にあいまいな、より長い昇順タスクに優れている」と報告していると述べました。Schwarzerは、Augment Codeなどのコーディングスタートアップが、モデルが「以前のどのモデルよりも大幅に強力な深層コード機能を提供した」ことを発見したため、新しいコードレビューエージェントを強化するために選択されたと付け加えました。視覚機能もアップグレードされています。</p><p>OpenAIのリリースブログ投稿には、「旅行者が遅延したフライト、乗り継ぎの失敗、ニューヨークでの一泊滞在、および医療上の座席要件を報告する」例が示されています。</p><p>結果は？「GPT‑5.2は、再予約、特別な支援座席、および補償というタスクチェーン全体を管理し、GPT‑5.1よりも完全な結果を提供します。」</p><p>GUIスクリーンショットを理解するモデルの能力をテストするScreenSpot-Proと呼ばれる新しい評価では、GPT-5.2シンキングが86.3％の精度を達成していますが、GPT-5.1ではわずか64.2％です。</p><h3><b>科学と信頼性</b></h3><p>OpenAIのリーダーはまた、モデルが単純なチャットボットから研究アシスタントへの会話を移行しようとして、科学研究におけるモデルの有用性を強調しました。</p><p>トレーニングチームのリーダーであるAidan Clarkは、モデルをテストした免疫学の上級研究者の例を共有しました。</p><p>「彼らは、免疫システムに関する最も重要な未解決の質問を生成するように依頼することでそれをテストしました」とClarkは述べました。「その免疫学研究者は、GPT-5.2が、以前のどのプロモデルと比較しても、より鋭い質問と、これらの質問がなぜ重要なのかについてのより強力な説明を生み出したと報告しました。</p><p>「信頼性も重要な焦点でした。Schwarzerは、新しいモデルは「GPT-5.1よりも実質的に幻覚が少ない」と主張し、匿名化された一連のクエリで「応答には38％少ないエラーが含まれていた」と述べています。</p><h3><b>「雰囲気」の変化</b></h3><p>興味深いことに、OpenAIは、すべてのユーザーが新しいモデルをすぐに好むとは限らないことを認めました。</p><p>GPT-5.1などのレガシーモデルが利用可能なままになる理由を尋ねられたとき、Schwarzerは「モデルは毎回少しずつ変化する」と認めました。</p><p>「一部のユーザーは、最新のモデルが全体的にはるかに優れていると考えていますが、以前のモデルの雰囲気を好むかもしれません」とSchwarzerは述べています。彼はまた、「特定のモデルに合わせてプロンプトを微調整した」一部のエンタープライズ顧客にとっては、「小さなリグレッション」が発生し、古いバージョンへのアクセスが必要になる可能性があると述べています。</p><h3><b>安全性、「アダルトモード」、および将来のロードマップ</b></h3><p>安全性に関する懸念に対処するため、Simoは、新しい年齢予測システムの実装後、来年の第1四半期に「アダルトモード」を展開する準備をしていることを確認しました。</p><p>「私たちはそれを改善する過程にあります」とSimoは年齢予測技術について述べています。</p><p>「アダルトモードを起動する前にそれを行いたいと思っています。」さらに先を見据えると、業界のレポートでは、OpenAIが「プロジェクトガーリック」というコードネームで、より根本的なアーキテクチャのシフトに取り組んでおり、2026年初頭にフラッグシップリリースを目標としていることが示唆されています。</p><p>幹部は記者会見中に特定の将来のロードマップについてコメントしませんでしたが、Simoは現在の軌道の経済性について楽観的なままでした。</p><p>「過去の傾向を見ると、計算量は過去3年間で毎年約3倍に増加しています」と彼女は説明しました。「収益も同じペースで増加しており...この好循環を生み出しています。」</p><p>Clarkは、効率が急速に向上していると付け加えました。「本日リリースするモデルは、1年前のモデルと比較して、ほぼ400分の1のコストと少ない計算量で、[ARC-AGI]でさらに優れたスコアを達成しています。」</p><p>GPT-5.2インスタント、シンキング、およびプロは、本日よりChatGPTで有料ユーザー（Plus、Pro、Team、およびEnterprise）に展開を開始します。同社は、安定性を維持するために段階的に展開すると述べています。</p>",
    "insightJa": "GPT-5.2の登場により、企業はより高度なAIを活用した業務効率化や意思決定が可能になります。ただし、API利用料金が高額になるため、コスト対効果を慎重に検討する必要があるでしょう。",
    "recommendedBooks": [
      "大規模言語モデル 入門",
      "AI 活用事例",
      "GPT-5.2 企業活用"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "LLM",
      "Artificial Intelligence",
      "自然言語処理"
    ]
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "title": "Stressed rats keep returning to cannabis and scientists know why",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "summary": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "publishedAt": "Thu, 11 Dec 2025 12:15:09 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "titleJa": "ストレスを感じやすいラットはカンナビスに戻り続ける：科学者がその理由を解明",
    "summaryJa": "生まれつきストレスレベルが高いラットは、カンナビスを自発的に摂取しやすいことが判明。行動実験から、ストレスホルモン、低い認知柔軟性、低いエンドカンナビノイドレベルが使用増加に関連。",
    "explanationJa": "ストレスを感じやすいラットがカンナビスを求める理由が解明され、薬物依存の初期兆候発見につながるかもしれません。",
    "translationJa": "生まれつきストレスレベルが高いラットは、カンナビスへのアクセスを与えられた場合、自発的に摂取する可能性がはるかに高いことがわかりました。行動実験の結果、ベースラインのストレスホルモンがカンナビスを求める行動の最も強い予測因子であることが示されました。認知柔軟性の低下と低いエンドカンナビノイドレベルも、使用の増加に寄与しました。これらの結果は、薬物乱用に対する脆弱性の可能性のある早期指標を示唆しています。",
    "insightJa": "この研究は、ストレス管理の重要性を示唆しています。ストレスを軽減する方法を学ぶことは、薬物依存のリスクを減らすだけでなく、仕事や人間関係など、日常生活の質を向上させることにもつながるでしょう。",
    "recommendedBooks": [
      "ストレスマネジメント",
      "薬物依存",
      "脳科学 ストレス"
    ],
    "tags": [
      "cannabis",
      "stress",
      "rats",
      "drug addiction",
      "エンドカンナビノイド"
    ]
  },
  {
    "id": "7nAN91YGj5oC8TMc2YBtjK",
    "title": "Marble enters the race to bring AI to tax work, armed with $9 million and a free research tool",
    "source": "rss",
    "url": "https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a",
    "summary": "Marble, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.\nThe round, led by Susa Ventures with participation from MXV Capital and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.\n\"When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,\" said Bhavin Shah, Marble's chief executive officer, in an exclusive interview with VentureBeat. \"Accounting generates $250 billion in fee-based billing in the US every year. There's a tremendous opportunity to increase efficiency and improve margins for accounting firms.\"\nThe company has launched a free AI-powered tax research tool on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.\nMarble's backers share Shah's conviction about the market. \"Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,\" Chad Byers, general partner at Susa Ventures, told VentureBeat. \"We've known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.\"\nThe accounting industry lost 340,000 workers in four years — and replacements aren't coming\nMarble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.\nThe accounting profession has shed roughly 340,000 workers since 2019, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to AICPA data, and 2022 saw the lowest number of exam takers in 17 years.\nThe exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately 75% of all licensed CPAs reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.\n“Fewer CPAs are getting certified year over year,\" Shah said. \"The industry is compressing at the same time that there's more work to be done and the tax code is getting more complicated.\"\nThe National Pipeline Advisory Group, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the 150-hour education requirement for CPA licensure as a significant barrier to entry. A separate survey by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.\nRecent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.\nWhy AI transformed law and software development but left accounting behind\nDespite the profession's challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. Harvey and Legora have raised hundreds of millions to bring AI to legal work. Cursor and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.\nGeordie Konrad, Marble's executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI's capabilities.\n“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,\" Konrad said. \" That requires a bit more of a two-step analysis to see why it's a big opportunity.\"\nThe technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.\n\"If you want to put AI through its paces and ask how far it's come in replicating cognitive functions, this is an unbelievable playground to work in,\" Konrad said.\nA dramatic shift: AI adoption among tax and finance teams doubles in one year\nRecent data suggests the accounting profession's stance toward AI is shifting rapidly.\nA 2025 survey from Hanover Research and Avalara found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from Thomson Reuters Institute found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.\nLarge accounting firms have invested heavily in AI infrastructure. Deloitte has developed generative AI capabilities within its audit platform. BDO announced a $1B investment in AI over the next five years. EY launched an AI platform combining technology with strategy, transactions, and tax services. PwC estimates a complete AI-driven audit solution will launch by 2026.\nBut adoption at smaller firms remains uneven. According to Thomson Reuters research, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.\nMarble's founders believe the hesitance stems not from technophobia but from a lack of compelling options.\n“Firms want to embrace AI,\" Shah said. “They just haven't seen great software and tooling made for them. That's part of the opportunity — to work with them and build something they're excited to use on a day-to-day basis.”\nCan artificial intelligence rescue accounting's billable-hour business model?\nAI's arrival in accounting raises questions about the profession's billing structure.\nAccounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?\nMarble's founders argue the opposite. The chronic staffing shortage has already constrained firms' ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.\n\"Everyone in the industry agrees that an enormous amount of advisory work simply isn't getting done,\" Konrad said. \"Customers want it. Firms want to do it because it's high-margin, great work. But nobody gets to it.\"\nThe 2025 AICPA National Management of an Accounting Practice Survey supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.\nThe survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.\nAccountants won't adopt AI tools they can't trust with sensitive client data\nFor AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.\nAccording to Avalara's survey, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.\nMarble has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.\n\"Security is at the core of what we are building,\" Shah said. \"Every employee knows that security is critical. It's a part of our onboarding and something that we consider in everything we do.\"\nFrom number crunchers to strategic advisors: How AI could reshape accounting careers\nMarble's founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. \nThey draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.\n\"If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you're a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that's just a lot more fun to operate in,\" Konrad said.\nThe shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.\n\"Not only does the work become more enjoyable because of what you can focus on, but that's also what your clients are going to value more from you,\" Shah said.\nThe competitive landscape: Marble faces well-funded rivals and legacy giants\nMarble enters a market with formidable incumbents and well-funded competitors. BlueJ, a global tax research platform, has raised over $100 million. Thomson Reuters, CCH, and Intuit have deep customer relationships built over decades.\nBut the founders see opportunity in the transition moment.\n\"AI has changed what’s possible in the industry,\" Shah said. \"We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?\"\"\nThe decision to offer a free research tool reflects Marble's go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.\n\"It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don't know how to integrate it into their workflow,\" Shah said.\nThe $250 billion question: Can a startup transform how America does its taxes?\nMarble's roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.\nThe founders frame success not in terms of disruption but rebalancing. Today's tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble's bet is that AI can flip that equation.\n\"Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,\" Konrad said. \"How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?\"\nWhether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.\nBut the founders are betting that the industry's demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.\n\"AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,\" Shah said.\nThe accounting profession, it seems, is about to find out which side of that equation it lands on.",
    "publishedAt": "Thu, 11 Dec 2025 14:00:00 GMT",
    "author": "michael.nunez@venturebeat.com (Michael Nuñez)",
    "category": "AI",
    "originalContent": "<p><a href=\"http://marble.ai/\">Marble</a>, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.</p><p>The round, led by <a href=\"https://www.susaventures.com/\">Susa Ventures</a> with participation from <a href=\"https://mxv.vc/\">MXV Capital</a> and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.</p><p>&quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&quot; said Bhavin Shah, Marble&#x27;s chief executive officer, in an exclusive interview with VentureBeat. &quot;Accounting generates $250 billion in fee-based billing in the US every year. There&#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&quot;</p><p>The company has launched a <a href=\"https://marble.ai/\">free AI-powered tax research tool</a> on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.</p><p>Marble&#x27;s backers share Shah&#x27;s conviction about the market. &quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &quot;We&#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&quot;</p><h2><b>The accounting industry lost 340,000 workers in four years — and replacements aren&#x27;t coming</b></h2><p>Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.</p><p>The accounting profession has <a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">shed roughly 340,000 workers since 2019</a>, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to <a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPA data</a>, and 2022 saw the lowest number of exam takers in 17 years.</p><p>The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately <a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">75% of all licensed CPAs</a> reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.</p><p>“Fewer CPAs are getting certified year over year,&quot; Shah said. &quot;The industry is compressing at the same time that there&#x27;s more work to be done and the tax code is getting more complicated.&quot;</p><p>The <a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the <a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150-hour education requirement</a> for CPA licensure as a significant barrier to entry. A separate <a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">survey</a> by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.</p><p>Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.</p><h2><b>Why AI transformed law and software development but left accounting behind</b></h2><p>Despite the profession&#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. <a href=\"https://www.harvey.ai/\">Harvey</a> and <a href=\"https://legora.com/\">Legora</a> have raised hundreds of millions to bring AI to legal work. <a href=\"https://cursor.com/agents\">Cursor</a> and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.</p><p>Geordie Konrad, Marble&#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&#x27;s capabilities.</p><p>“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&quot; Konrad said. &quot; That requires a bit more of a two-step analysis to see why it&#x27;s a big opportunity.&quot;</p><p>The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.</p><p>&quot;If you want to put AI through its paces and ask how far it&#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&quot; Konrad said.</p><h2><b>A dramatic shift: AI adoption among tax and finance teams doubles in one year</b></h2><p>Recent data suggests the accounting profession&#x27;s stance toward AI is shifting rapidly.</p><p>A 2025 survey from <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a> found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from <a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a> found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.</p><p>Large accounting firms have invested heavily in AI infrastructure. <a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a> has developed generative AI capabilities within its audit platform. <a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a> announced a $1B investment in AI over the next five years. <a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a> launched an AI platform combining technology with strategy, transactions, and tax services. <a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a> estimates a complete AI-driven audit solution will launch by 2026.</p><p>But adoption at smaller firms remains uneven. According to <a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reuters research</a>, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.</p><p>Marble&#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.</p><p>“Firms want to embrace AI,&quot; Shah said. “They just haven&#x27;t seen great software and tooling made for them. That&#x27;s part of the opportunity — to work with them and build something they&#x27;re excited to use on a day-to-day basis.”</p><h2><b>Can artificial intelligence rescue accounting&#x27;s billable-hour business model?</b></h2><p>AI&#x27;s arrival in accounting raises questions about the profession&#x27;s billing structure.</p><p>Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?</p><p>Marble&#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.</p><p>&quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&#x27;t getting done,&quot; Konrad said. &quot;Customers want it. Firms want to do it because it&#x27;s high-margin, great work. But nobody gets to it.&quot;</p><p>The <a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a> supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.</p><p>The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.</p><h2><b>Accountants won&#x27;t adopt AI tools they can&#x27;t trust with sensitive client data</b></h2><p>For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.</p><p>According to <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalara&#x27;s survey</a>, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.</p><p><a href=\"https://marble.ai/\">Marble</a> has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.</p><p>&quot;Security is at the core of what we are building,&quot; Shah said. &quot;Every employee knows that security is critical. It&#x27;s a part of our onboarding and something that we consider in everything we do.&quot;</p><h2><b>From number crunchers to strategic advisors: How AI could reshape accounting careers</b></h2><p>Marble&#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. </p><p>They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.</p><p>&quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&#x27;s just a lot more fun to operate in,&quot; Konrad said.</p><p>The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.</p><p>&quot;Not only does the work become more enjoyable because of what you can focus on, but that&#x27;s also what your clients are going to value more from you,&quot; Shah said.</p><h2><b>The competitive landscape: Marble faces well-funded rivals and legacy giants</b></h2><p><b></b><a href=\"http://marble.ai/\">Marble</a> enters a market with formidable incumbents and well-funded competitors. <a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>, a global tax research platform, has raised over $100 million. <a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>, <a href=\"https://www.cch.com/\">CCH</a>, and <a href=\"https://www.intuit.com/\">Intuit</a> have deep customer relationships built over decades.</p><p>But the founders see opportunity in the transition moment.</p><p>&quot;AI has changed what’s possible in the industry,&quot; Shah said. &quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&quot;&quot;</p><p>The decision to offer a free research tool reflects Marble&#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.</p><p>&quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&#x27;t know how to integrate it into their workflow,&quot; Shah said.</p><h2><b>The $250 billion question: Can a startup transform how America does its taxes?</b></h2><p>Marble&#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.</p><p>The founders frame success not in terms of disruption but rebalancing. Today&#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&#x27;s bet is that AI can flip that equation.</p><p>&quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&quot; Konrad said. &quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&quot;</p><p>Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.</p><p>But the founders are betting that the industry&#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.</p><p>&quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&quot; Shah said.</p><p>The accounting profession, it seems, is about to find out which side of that equation it lands on.</p>",
    "titleJa": "Marble、900万ドルの資金調達と無料の研究ツールで、AIによる税務業務への参入を目指す",
    "summaryJa": "会計業界の人手不足と規制の複雑化に対応するため、税務専門家向けAIエージェントを開発するMarbleが900万ドルのシード資金を調達。無料のAI税務調査ツールも公開。",
    "explanationJa": "Marble社はAIを活用して税務業務を効率化するサービスを提供し、税理士の方々の仕事をサポートします。",
    "translationJa": "<p><a href=\"http://marble.ai/\">Marble</a>は、税務専門家向けの人工知能エージェントを構築するスタートアップであり、会計業界が深刻な人手不足と増大する規制の複雑さに苦慮している中で、900万ドルのシード資金を調達しました。</p><p>Susa Venturesが主導し、MXV CapitalとKonrad Capitalが参加したこのラウンドにより、Marbleは、法律やソフトウェア開発などの他の知識産業に比べてAIの導入が大幅に遅れている市場で競争する態勢を整えました。</p><p>Marbleの最高経営責任者であるBhavin Shahは、VentureBeatとの独占インタビューで、「経済状況を分析し、AIがビジネスの運営方法をどのように変革するかを自問した結果、知識産業、特に時間料金ベースのサービスモデルを持つ企業に焦点を当てました。会計は米国で年間2,500億ドルの料金ベースの請求を生み出しています。会計事務所の効率を高め、利益率を向上させる大きな機会があります」と述べています。</p><p>同社は、複雑な政府税務データを、専門家がアクセス可能な引用付きの回答に変換する<a href=\"https://marble.ai/\">無料のAI搭載税務調査ツール</a>をウェブサイトで公開しました。Marbleは、コンプライアンスのシナリオを分析し、最終的には税務申告ワークフローの一部を自動化できるAIエージェントに拡張する予定です。</p><p>Marbleの出資者は、Shahの市場に対する確信を共有しています。「Marbleは、会計システムを根本から再考しています。会計は、専門サービスにおいて最大規模であり、最も見過ごされている市場の1つです」と、Susa VenturesのゼネラルパートナーであるChad Byersは、VentureBeatに語りました。「私たちは、Susaポートフォリオのエグゼクティブとしての彼の時代からBhavinを知っており、彼がいかに鋭敏で実行力があるかを直接見てきました。彼とGeordieは、業務の深さと製品の本能の完璧な組み合わせを、変化が長い間待たれていた分野にもたらしています。そして、彼らは私たちと同じように大きな機会を見ています。」</p><h2><b>会計業界は4年間で34万人の労働者を失い、補充は進んでいない</b></h2><p>Marbleは、専門会計の経済学を根本的に変えた構造的な力によって形作られた市場に参入します。</p><p>会計業界は<a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">2019年以降、約34万人の労働者を削減</a>しており、これは17％の減少であり、企業はクライアントの需要を満たすために奮闘しています。公認会計士試験の初回受験者数は、<a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPAのデータ</a>によると、2016年から2021年の間に33％減少し、2022年は過去17年間で最も少ない受験者数となりました。</p><p>この流出は、ベビーブーマーが一斉に退職する中で起こっています。米国公認会計士協会は、<a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">すべての公認会計士の約75％</a>が2019年までに定年退職年齢に達したと推定しており、業界が対応に苦労している人口統計上の崖を作り出しています。</p><p>「年々、公認会計士の認定を受ける人が減っています」とShahは述べています。「より多くの作業が必要とされ、税法がより複雑になっていると同時に、業界は縮小しています。」</p><p>AICPAによって2023年7月に設立されたマルチステークホルダー組織である<a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>は、CPAライセンスの<a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150時間の教育要件</a>を参入への大きな障壁として特定したレポートを発表しました。Center for Audit Qualityによる別の<a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">調査</a>では、会計を専攻しないことを選択した経営学専攻の57％が、追加の単位時間を抑止力として挙げています。</p><p>最近の法改正は、その緊急性を反映しています。オハイオ州は現在、150時間要件の代替手段を提供しており、州が入学者の減少を逆転させる可能性のある経路を試す意思があることを示しています。</p><h2><b>なぜAIは法律とソフトウェア開発を変革したが、会計を置き去りにしたのか</b></h2><p>業界の課題にもかかわらず、会計におけるAIの導入は、隣接する知識産業よりもゆっくりと進んでいます。<a href=\"https://www.harvey.ai/\">Harvey</a>と<a href=\"https://legora.com/\">Legora</a>は、法律業務にAIを導入するために数億ドルを調達しました。<a href=\"https://cursor.com/agents\">Cursor</a>やその他のコーディングアシスタントは、ソフトウェア開発を変革しました。対照的に、会計は依然としてレガシー調査プラットフォームと手作業に大きく依存しています。</p><p>Marbleのエグゼクティブチェアマンであり、レストランソフトウェア会社TouchBistroの共同創設者であるGeordie Konradは、そのギャップを、人々がAIの能力をどのように概念化するかに起因させています。</p><p>「多くの人にとって、LLMがソフトウェア開発者向けのコードを操作したり、弁護士向けの単語を操作したりすることで、意味のある作業ができることは明らかでした。会計業界では、LLMは推論エージェントとして使用されます」とKonradは述べています。「それが大きな機会である理由を理解するには、もう少し2段階の分析が必要です。」</p><p>技術的な課題は大きいです。税法は、人間が作成した最も複雑で相互接続された情報システムの1つを構成しています。それは、頻繁に重複または矛盾する、何万もの相互に関連する規則、ガイダンス文書、および管轄固有の要件です。</p><p>「AIを試して、認知機能の再現においてどこまで到達したかを尋ねたい場合は、これは作業する上で信じられないほどの遊び場です」とKonradは述べています。</p><h2><b>劇的な変化：税務および財務チームにおけるAIの導入が1年で2倍になる</b></h2><p>最近のデータは、会計業界のAIに対する姿勢が急速に変化していることを示唆しています。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a>による2025年の調査によると、現在、財務および税務チームの84％が業務でAIを多用しており、2024年の47％から増加しています。<a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a>による2025年のGenerative AI in Professional Services Reportでは、税務事務所の21％がすでに生成AIテクノロジーを使用しており、53％が採用を計画しているか、積極的に検討しています。</p><p>大手会計事務所は、AIインフラストラクチャに多額の投資を行っています。<a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a>は、監査プラットフォーム内で生成AI機能を開発しました。<a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a>は、今後5年間でAIに10億ドルを投資すると発表しました。<a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a>は、テクノロジーと戦略、トランザクション、および税務サービスを組み合わせたAIプラットフォームを立ち上げました。<a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a>は、完全なAI駆動の監査ソリューションが2026年までにリリースされると予測しています。</p><p>しかし、中小企業での導入は依然としてばらつきがあります。<a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reutersの調査</a>によると、生成AIを使用している税務事務所の回答者の52％は、業界固有のソリューションではなく、ChatGPTなどのオープンソースツールに依存しています。目的別の代替手段が登場するにつれて、このパターンは変わる可能性があります。</p><p>Marbleの創設者は、その躊躇はテクノフォビアではなく、魅力的な選択肢の欠如から生じていると考えています。</p><p>「企業はAIを受け入れたいと思っています」とShahは述べています。「彼らは自分たちのために作られた優れたソフトウェアとツールを見ていません。それが機会の一部です。彼らと協力して、彼らが日常的に使用することに興奮する何かを構築することです。」</p><h2><b>人工知能は会計の請求時間ビジネスモデルを救うことができるか？</b></h2><p>会計へのAIの登場は、業界の請求構造に関する疑問を提起します。</p><p>会計事務所は伝統的に、従業員の給与コストの数倍でクライアントにスタッフ時間を請求することで利益を生み出してきました。コンプライアンス作業を行うジュニアアソシエイトは、重要な収益源を表しています。AIがその作業を自動化できる場合、企業が依存するビジネスモデルを弱体化させるでしょうか？</p><p>Marbleの創設者は反対の主張をしています。慢性的な人員不足は、企業が利用可能な収益を獲得する能力をすでに制限しています。クライアントが積極的に望む、利益率の高いサービスであるアドバイザリーおよびコンサルティング作業は、実務者がコンプライアンスのタスクに埋もれているため、未完了のままになります。</p><p>「業界の誰もが、膨大な量のアドバイザリー作業が単に行われていないことに同意しています」とKonradは述べています。「顧客はそれを望んでいます。企業は、それが高マージンで優れた作業であるため、それを行いたいと思っています。しかし、誰もそれにたどり着けません。」</p><p><a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a>は、この見解を支持しています。企業は、前年比でクライアント料金が6.7％増加したと報告しており、監査、保証、税務サービス、およびクライアント会計アドバイザリーが増加しています。パートナー1人あたりの純利益は、2022会計年度から2024会計年度にかけて11.9％増加し、252,663ドルに達しました。</p><p>調査では、AIの採用への関心が高まっていることもわかりましたが、ほとんどの企業はまだ正式な予算を割り当てたり、構造化されたトレーニングプログラムを開発したりしていません。調査は、継続的な採用がサービスの拡大を支援し、継続的な成長を促進する可能性があることを示唆しています。</p><h2><b>会計士は機密性の高い顧客データで信頼できないAIツールを採用しない</b></h2><p>AIが会計で成功するためには、データセキュリティの高い基準を満たす必要があります。会計事務所は、経済において最も機密性の高い財務情報の一部を扱います。実務者は、コンプライアンスまたは機密保持のリスクを生み出すツールを採用することはできません。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalaraの調査</a>によると、回答者の63％が、税務および財務機能の自動化に対する最大の障壁として、データセキュリティとプライバシーの懸念を挙げています。この懸念は、最初の選択から実装、継続的な使用まで、採用ライフサイクル全体にわたって持続します。</p><p><a href=\"https://marble.ai/\">Marble</a>は、セキュリティを基本的な優先事項にしています。同社は、製品をリリースする前にソフトウェアコンプライアンスの認証を取得し、データプライバシーが初日から運用文化に組み込まれていると主張しています。</p><p>「セキュリティは、私たちが構築しているものの中心にあります」とShahは述べています。「すべての従業員が、セキュリティが重要であることを知っています。それは私たちのオンボーディングの一部であり、私たちが行うすべてのことを考慮するものです。」</p><h2><b>数字の計算機から戦略アドバイザーへ：AIは会計のキャリアをどのように再構築できるか</b></h2><p>Marbleの創設者は、AIが会計の仕事を奪うだけだという見方を否定しています。彼らは代わりに、AIが会計の仕事をより戦略的にし、反復的な実行による特徴付けを少なくすると提案しています。</p><p>彼らは、コンピュータ支援設計が骨の折れる手動製図に取って代わった建築との類似点を描いています。建築家は消えませんでした。彼らは、機械的な複製ではなく、創造的な設計により多くの時間を費やすことができるツールを手に入れました。</p><p>「ジュニアまたは中堅の会計士であることから、時間集約的で創造性の低い作業の一部を取り除き、それをあなたが創造的でアイデアを統合し、多くのタスクをAIアシスタントプラットフォームソリューションに委任できる専門家である役割に置き換えると、最終的には、業界は運営するのがはるかに楽しくなります」とKonradは述べています。</p><p>この変化は、クライアントの成果も改善する可能性があります。会計士がコンプライアンスに費やす時間を減らすと、クライアントが価値を置く戦略的なアドバイザリー作業により多くの投資をすることができます。</p><p>「何に集中できるかによって仕事がより楽しくなるだけでなく、クライアントはあなたからより多くの価値を得るでしょう」とShahは述べています。</p><h2><b>競争環境：Marbleは資金豊富なライバルとレガシー大手に直面している</b></h2><p><a href=\"http://marble.ai/\">Marble</a>は、手ごわい既存企業と資金豊富な競合他社がいる市場に参入します。グローバルな税務調査プラットフォームである<a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>は、1億ドル以上を調達しました。<a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>、<a href=\"https://www.cch.com/\">CCH</a>、および<a href=\"https://www.intuit.com/\">Intuit</a>は、数十年にわたって構築された深い顧客関係を持っています。</p><p>しかし、創設者は移行の瞬間に機会を見出しています。</p><p>「AIは業界で何が可能かを変えました」とShahは述べています。「私たちは、業界の一部のテクノロジープレーヤーと協力し、統合する予定であり、AIを搭載した新製品で他のプレーヤーと競争します。場合によっては、物事を行うための既存のテクノロジーソリューションを忘れ、タスク自体に戻ります。私たちは完全に新しい技術的能力を持っています。人間と協力してそのタスクを達成するものを白いキャンバスからどのように設計しますか？」</p><p>無料の調査ツールを提供するという決定は、Marbleの市場参入哲学を反映しています。料金なしで実務者がアクセスできるようにすることで、同社は信頼を構築し、能力を実証することを目指しています。</p><p>「AIの使用方法を心配している人や、AIの採用方法を疑問視している人に、目的に合わせて構築された本当に魅力的な製品を公開することができます。ワークフローに統合する方法がわからない場合、費用がかかりすぎるものを購入することを考える必要はありません」とShahは述べています。</p><h2><b>2,500億ドルの質問：スタートアップ企業はアメリカの税金の処理方法を変えることができるか？</b></h2><p>Marbleのロードマップは調査を超えて広がっています。同社は、複雑な税務シナリオを分析し、コンプライアンスの問題を特定し、最終的にはコンプライアンスワークフローの重要な部分を自動化できるAIエージェントを開発する予定です。すべて、実務者の制御を維持しながら。</p><p>創設者は、成功を破壊ではなく、リバランスの観点から捉えています。今日の税務業務はコンプライアンスに大きく偏っており、クライアントが切望する、より高いマージンを生み出す戦略的なアドバイザリーサービスは、永遠に未完了のままになっています。Marbleの賭けは、AIがその方程式を反転させることができるということです。</p><p>「誰もが、コンプライアンスがより簡単に完了し、戦略と計画について話し合う時間を費やすことを望んでいます」とKonradは述べています。「コンプライアンス対戦略と計画のブレンドを、戦略と計画を最初に、コンプライアンスが劇的に簡素化されたものにするにはどうすればよいでしょうか？」</p><p>Marbleがそのビジョンを実行できるかどうかはまだわかりません。同社は、根強い競合他社、歴史的に技術的な変化に抵抗してきた業界、およびリスクの高い財務業務向けのAIシステムを構築することの固有の予測不可能性に直面しています。</p><p>しかし、創設者は、業界の人口構成の変化が、以前のテクノロジーの波ではできなかった方法で採用を加速させると考えています。毎年業界に入る会計士が減少し、クライアントの需要が増大するだけであれば、企業は残りのスタッフがより多くのことをできるようにするツールを採用することに意欲を高める可能性があります。</p><p>「AIはすべての業界を変えるでしょう。ビジネスモデルを支援する方法もあれば、ビジネスモデルに挑戦する方法もあります。AIは最終的に会計事務所のビジネスをより良く、より収益性が高くすると同時に、エンドクライアントはより良いサービスをより良い価格で得られると信じています」とShahは述べています。</p><p>会計業界は、その方程式のどちら側に着地するかを知ろうとしているようです。</p>",
    "insightJa": "会計業界におけるAI導入は、税理士の業務効率化だけでなく、クライアントへのより高度な戦略的アドバイス提供を可能にする可能性を秘めています。中小企業にとっても、AIツール導入が競争力強化の鍵となるでしょう。",
    "recommendedBooks": [
      "会計 AI",
      "税務 DX",
      "AI 税理士"
    ],
    "tags": [
      "AI",
      "Accounting",
      "Tax",
      "Artificial Intelligence",
      "Automation"
    ]
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "title": "New research reveals how everyday cues secretly shape your habits",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "summary": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "publishedAt": "Wed, 10 Dec 2025 22:41:05 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "titleJa": "日常の合図がどのように潜在的に習慣を形成するのかを解明する新たな研究",
    "summaryJa": "脳タンパク質KCC2の変動が、報酬と合図の結びつきを変化させ、習慣形成を促進。ドーパミン神経が活発化し、中毒行動に類似したメカニズムで学習が強化。",
    "explanationJa": "日常の何気ない合図が、脳内の特定のタンパク質の変化を通して、私たちの習慣を強く形成している可能性があるのです。",
    "translationJa": "研究者らは、KCC2と呼ばれる脳タンパク質のレベルの変化が、合図が報酬と結びつく方法を再構築し、時には予想以上に迅速かつ強力に習慣を形成させることを発見しました。このタンパク質が低下すると、ドーパミンニューロンの発火がより強くなり、中毒行動が定着する様子と似た方法で、新しい関連付けが強化されます。ラットを使った研究では、短時間の同期したニューラル活動のバーストでさえ、報酬学習を増幅させることが示されており、朝のルーチンワークのような日常的なきっかけが、なぜ強い欲求を引き起こすのかについての洞察が得られました。",
    "insightJa": "この研究から、習慣形成を意識的にコントロールするためには、KCC2に影響を与える要素、例えば睡眠や食事、運動などを見直すことが重要かもしれません。また、マーケティング戦略において、消費者の特定の行動と快楽を結びつけるような合図を効果的に活用できる可能性があります。",
    "recommendedBooks": [
      "習慣形成",
      "脳科学",
      "行動経済学"
    ],
    "tags": [
      "habit formation",
      "KCC2",
      "dopamine",
      "reward learning",
      "neuroscience"
    ]
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "title": "Blood tests reveal obesity rapidly accelerates Alzheimer’s progression",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "summary": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "publishedAt": "Wed, 10 Dec 2025 12:23:51 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "titleJa": "血液検査で肥満がアルツハイマー病の進行を加速することが判明",
    "summaryJa": "肥満は、従来考えられていたよりもはるかに急速にアルツハイマー病関連の血中バイオマーカーの上昇を加速させます。画像データと血漿データの分析から、肥満者は神経変性とアミロイド蓄積に関連するタンパク質の増加が速いことが示されました。",
    "explanationJa": "血液検査によって、肥満がアルツハイマー病の進行を早める可能性が高いことがわかりました。",
    "translationJa": "肥満は、従来認識されていたよりもはるかに急速に、アルツハイマー病関連の血中バイオマーカーの上昇を加速させます。長期的な画像データと血漿データの分析により、肥満の人は神経変性とアミロイド蓄積に関連するタンパク質の増加が非常に速いことが示されました。驚くべきことに、血液検査はPETスキャンよりも早くこれらの変化を検出しました。この結果は、肥満がアルツハイマー病の進行における主要な、かつ修正可能な要因であることを示唆しています。",
    "insightJa": "この研究結果は、健康的な体重を維持することが、アルツハイマー病のリスク低減に重要であることを示しています。日々の食生活や運動習慣を見直すことで、将来の健康リスクを軽減できる可能性があります。",
    "recommendedBooks": [
      "アルツハイマー病 予防",
      "肥満 健康リスク",
      "脳の健康 食事"
    ],
    "tags": [
      "Alzheimer's",
      "Obesity",
      "Biomarker",
      "Neurodegeneration",
      "血液検査"
    ]
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "title": "Rising temperatures are slowing early childhood development",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "summary": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "publishedAt": "Wed, 10 Dec 2025 00:59:03 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "titleJa": "気温上昇が幼児の発達を遅らせる",
    "summaryJa": "研究により、異常な高温が幼児の発達を阻害する可能性が示されました。特に読み書きや算数の基礎能力の発達に影響が出やすく、経済的に困難な状況にある子供ほど影響を受けやすいことがわかりました。",
    "explanationJa": "気温の上昇は、子供たちが学校に通う前から学習に影響を与える可能性があることがわかりました。",
    "translationJa": "研究者らは、異常に高い気温が幼児の発達を妨げる可能性があることを発見しました。高温の環境で暮らす子供たちは、特に読み書きや基礎的な算数のスキルにおいて、重要な学習の節目に到達しにくい傾向がありました。経済的な困難や限られた資源に直面している子供たちは、最も大きな打撃を受けました。この研究は、気候変動が子供たちが就学年齢に達するずっと前から、その学習をどのように形作る可能性があるかを強調しています。",
    "insightJa": "この研究は、地球温暖化が子どもたちの教育機会に不平等を生み出す可能性を示唆しています。企業は、地域社会への貢献として、気候変動対策と教育支援の両面から、この問題に取り組む必要性が高まるでしょう。",
    "recommendedBooks": [
      "幼児教育 環境",
      "気候変動 子ども",
      "発達心理学 入門"
    ],
    "tags": [
      "child development",
      "climate change",
      "early childhood education",
      "temperature",
      "幼児教育"
    ]
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "title": "Scientists reveal a tiny brain chip that streams thoughts in real time",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "summary": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "publishedAt": "Tue, 09 Dec 2025 23:54:39 EST",
    "author": "",
    "category": "Science",
    "originalContent": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "titleJa": "科学者らが思考をリアルタイムで伝送する超小型脳チップを発表",
    "summaryJa": "BISCは脳とコンピュータを繋ぐ超薄型インプラント。数万の電極を搭載し、AIモデルで運動、知覚、意図を解読。てんかん、麻痺、失明治療を変革する可能性。",
    "explanationJa": "BISCという脳チップを使うと、思考をリアルタイムでコンピュータに伝えることができるようになるそうです。",
    "translationJa": "BISCは、脳とコンピュータ間に高帯域幅の無線リンクを構築する超薄型神経インプラントです。その小型シングルチップ設計は、数万もの電極を搭載し、運動、知覚、および意図を解読するための高度なAIモデルをサポートします。初期の臨床研究では、頭蓋骨の小さな開口部から挿入でき、詳細な神経活動を捉えながら安定性を維持できることが示されています。この技術は、てんかん、麻痺、および失明の治療を大きく変える可能性があります。",
    "insightJa": "この技術が進歩すれば、脳波による機器操作や、コミュニケーションが困難な方の意思伝達を支援できるかもしれません。医療分野だけでなく、エンターテインメントや教育分野にも大きな影響を与える可能性があります。",
    "recommendedBooks": [
      "脳科学 入門",
      "ニューロテクノロジー",
      "ブレイン・マシン・インターフェース"
    ],
    "tags": [
      "Brain-computer interface",
      "Neural implant",
      "AI",
      "脳科学",
      "BMI"
    ]
  }
]