[
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "title": "Parents call for New York governor to sign landmark AI safety bill",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "summary": "A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill that would require developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.\nThe bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul reportedly proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the changes made to California's  …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T22:16:09.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STK485_STK414_AI_SAFETY_B.webp?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill <a href=\"https://legislation.nysenate.gov/pdf/bills/2025/S6953B\">that would require</a> developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.</p>\n<p class=\"has-text-align-none\">The bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul <a href=\"https://www.transformernews.ai/p/new-york-governor-hochul-raise-act-sb-53\">reportedly</a> proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the <a href=\"https://www.theverge.com/ai-artificial-intelligence/787918/sb-53-the-landmark-ai-transparency-bill-is-now-law-in-california\">changes made to California's  …</a></p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "保護者らがニューヨーク州知事に画期的なAI安全法案の署名を求める",
    "summaryJa": "150人以上の保護者が、AI開発企業に安全計画の作成と安全事故の報告を義務付けるRAISE法案への署名をホークル知事に要請。知事は法案の修正を提案し、テック企業に有利になる可能性がある。",
    "explanationJa": "保護者の方々が、AIの安全性を高めるための法案に署名するよう、ニューヨーク州知事に働きかけています。",
    "translationJa": "150人以上の保護者グループが金曜日、ニューヨーク州知事のキャシー・ホークルに書簡を送り、責任あるAIの安全性と教育（RAISE）法を修正なしで署名するよう促しました。RAISE法は、Meta、OpenAI、Deepseek、Googleなどの大規模AIモデルの開発者に対し、安全計画の作成と安全事故の報告に関する透明性規則の遵守を義務付ける注目の法案です。\n\nこの法案は6月、ニューヨーク州上院と下院の両方で可決されました。しかし今週、ホークルはRAISE法をほぼ全面的に書き換え、テック企業にとってより有利なものにする修正案を提案したと報じられています。これは、カリフォルニア州で行われた…と同様のものです。\n\nThe Vergeで記事全文を読む。",
    "insightJa": "AIの安全性に関する法規制は、今後ますます重要になってくるでしょう。企業だけでなく、私たち一人ひとりがAIの恩恵を安全に享受できるよう、注視していく必要がありそうです。",
    "recommendedBooks": [
      "AI倫理",
      "AIリスクマネジメント",
      "AIと法規制"
    ],
    "tags": [
      "AI safety",
      "RAISE Act",
      "Kathy Hochul",
      "AI regulation",
      "人工知能 安全性"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%20safety%2CRAISE%20Act&sig=840"
  },
  {
    "id": "https://techcrunch.com/?p=3075418",
    "title": "OK, what’s going on with LinkedIn’s algo?",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/ok-whats-going-on-with-linkedins-algo/",
    "summary": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "publishedAt": "Fri, 12 Dec 2025 19:38:16 +0000",
    "author": "Dominic-Madori Davis",
    "category": "AI",
    "originalContent": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "titleJa": "LinkedInのアルゴリズムに何が？",
    "summaryJa": "女性たちがLinkedInの新しいアルゴリズムが性差別的かどうか実験し、証明したと考えた。しかし、専門家によると、もっと複雑な要因が絡んでいる。",
    "explanationJa": "LinkedInのアルゴリズムについて、性差別疑惑を含め、専門家の間でより複雑な議論がなされています。",
    "translationJa": "女性たちがLinkedInの新しいアルゴリズムが性差別的かどうかを検証する実験を行い、それを証明したと考えました。しかし、専門家は、より複雑な要因が関与していると指摘しています。",
    "insightJa": "もしLinkedInのアルゴリズムに偏りがある場合、採用活動やキャリア形成に影響が出る可能性があります。アルゴリズムの透明性と公平性を確保することが重要です。",
    "recommendedBooks": [
      "アルゴリズム バイアス",
      "AI 公平性",
      "LinkedIn マーケティング"
    ],
    "tags": [
      "LinkedIn",
      "algorithm",
      "bias",
      "sexism",
      "AI"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?LinkedIn%2Calgorithm&sig=790"
  },
  {
    "id": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "title": "Google Translate brings real-time speech translations to any headphones",
    "source": "rss",
    "url": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "summary": "Google Translate's latest update brings live speech translations, originally available only on the Pixel Buds, to any headphones you want, with support for over 70 languages. It's rolling out today in beta and just requires a compatible Android phone with the Translate app (unlike Apple's similar feature, which requires AirPods). \nIt's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T18:11:14.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/google-translate-text-update-12-12-25.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google Translate's latest update brings live speech translations, originally available only <a href=\"https://www.theverge.com/2017/11/16/16659314/google-pixel-buds-review-bluetooth-headphones\">on the Pixel Buds</a>, to any headphones you want, with support for over 70 languages. It's <a href=\"https://blog.google/products/search/gemini-capabilities-translation-upgrades/\">rolling out today in beta</a> and just requires a compatible Android phone with the Translate app (unlike <a href=\"https://www.theverge.com/news/629506/apple-airpods-live-translation-ios-19\">Apple's similar feature</a>, which requires AirPods). </p>\n<p class=\"has-text-align-none\">It's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …</p>\n<p><a href=\"https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "Google翻訳、あらゆるヘッドホンでリアルタイム音声翻訳が可能に",
    "summaryJa": "Google翻訳の最新アップデートで、Pixel Buds限定だったリアルタイム音声翻訳が、70以上の言語に対応し、あらゆるヘッドホンで利用可能になります。テキスト翻訳も改善。",
    "explanationJa": "Google翻訳が進化し、どんなヘッドホンでもリアルタイムで外国語の会話が楽しめるようになります。",
    "translationJa": "Google翻訳の最新アップデートにより、これまでPixel Budsでのみ利用可能だったリアルタイム音声翻訳機能が、70以上の言語をサポートし、お好みのヘッドホンで使用できるようになります。本日ベータ版として公開され、Translateアプリがインストールされた対応Androidスマートフォンがあれば利用できます（Appleの同様の機能のように、AirPodsは必要ありません）。\n\nこれは、Google翻訳に追加されるいくつかの新機能の一つであり、テキスト翻訳も改善されています。Geminiを使用することで、Translateは、イディオムやスラングなど、文字通りの意味とは異なるフレーズをより正確に翻訳できるようになります。たとえば、「stealing my …」という表現などです。\n\n詳細はThe Vergeの記事をご覧ください。",
    "insightJa": "この機能により、海外旅行やビジネスシーンでのコミュニケーションが格段にスムーズになります。言語の壁を感じることなく、より多くの人々と交流できるようになるでしょう。",
    "recommendedBooks": [
      "翻訳技術",
      "多言語コミュニケーション",
      "Google 翻訳 活用"
    ],
    "tags": [
      "Google Translate",
      "リアルタイム翻訳",
      "音声翻訳",
      "多言語対応",
      "AI translation"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Google%20Translate%2C%E3%83%AA%E3%82%A2%E3%83%AB%E3%82%BF%E3%82%A4%E3%83%A0%E7%BF%BB%E8%A8%B3&sig=514"
  },
  {
    "id": "https://techcrunch.com/?p=3075611",
    "title": "Trump’s AI executive order promises ‘one rulebook’ — startups may get legal limbo instead",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/trumps-ai-executive-order-promises-one-rulebook-startups-may-get-legal-limbo-instead/",
    "summary": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "publishedAt": "Fri, 12 Dec 2025 17:07:22 +0000",
    "author": "Rebecca Bellan",
    "category": "AI",
    "originalContent": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "titleJa": "トランプ大統領のAI大統領令、「単一規則」を約束するも、スタートアップは法的空白に陥る可能性",
    "summaryJa": "トランプ大統領が州法を対象としたAI大統領令に署名し、全国単一規則を約束。しかし、連邦規則の議論中に法廷闘争を引き起こし、スタートアップの不確実性を長引かせる可能性があると批判されています。",
    "explanationJa": "トランプ大統領のAIに関する大統領令は、スタートアップにとって、法的状況が不安定になる可能性がありそうです。",
    "translationJa": "トランプ大統領は、州法を対象とし、全国的な単一規則を約束するAIに関する大統領令に署名しました。批評家は、この大統領令が法廷闘争を引き起こし、議会が連邦規則を議論する間、スタートアップ企業の不確実性を長引かせる可能性があると警告しています。",
    "insightJa": "この大統領令によって、AI関連のビジネスを展開する企業は、今後、州ごとの規制ではなく、連邦政府の動向に注視する必要が出てきます。特にスタートアップ企業は、法的リスクを考慮した上で事業戦略を立てる必要性が高まるかもしれません。",
    "recommendedBooks": [
      "AI 法規制",
      "スタートアップ 法務",
      "人工知能 リスク"
    ],
    "tags": [
      "AI",
      "executive order",
      "legal limbo",
      "startup",
      "regulation"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%2Cexecutive%20order&sig=785"
  },
  {
    "id": "https://techcrunch.com/?p=3075551",
    "title": "Google Translate now lets you hear real-time translations in your headphones",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/google-translate-now-lets-you-hear-real-time-translations-in-your-headphones/",
    "summary": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "publishedAt": "Fri, 12 Dec 2025 17:00:00 +0000",
    "author": "Aisha Malik",
    "category": "AI",
    "originalContent": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "titleJa": "Google翻訳がヘッドホンでリアルタイム翻訳を提供開始",
    "summaryJa": "Google翻訳が、話者の口調や強調、抑揚をそのままにリアルタイムで翻訳するヘッドホン機能を発表。会話の理解を助け、誰が話しているかを識別しやすくします。",
    "explanationJa": "Google翻訳の新しいヘッドホン機能で、より自然な会話のリアルタイム翻訳が可能になりました。",
    "translationJa": "リアルタイムのヘッドホン翻訳体験では、各話者の口調、強調、および抑揚がそのまま維持されるため、会話を理解しやすく、誰が何を発言しているかを区別しやすくなります。",
    "insightJa": "この技術により、言語の壁を超えたスムーズなコミュニケーションが可能になり、国際的なビジネスや旅行がより容易になるでしょう。異文化理解の促進にも貢献すると期待されます。",
    "recommendedBooks": [
      "機械翻訳",
      "多言語コミュニケーション",
      "異文化コミュニケーション"
    ],
    "tags": [
      "Google Translate",
      "Real-time Translation",
      "Headphones",
      "Machine Translation",
      "AI"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Google%20Translate%2CReal-time%20Translation&sig=788"
  },
  {
    "id": "https://techcrunch.com/?p=2607630",
    "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/chatgpt-everything-to-know-about-the-ai-chatbot/",
    "summary": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "publishedAt": "Fri, 12 Dec 2025 16:01:00 +0000",
    "author": "Kyle Wiggers, Cody Corrall, Kate Park, Alyssa Stringer",
    "category": "AI",
    "originalContent": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "titleJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと",
    "summaryJa": "この記事では、ChatGPTの製品アップデートとリリースに関するタイムラインを、最新情報から順に紹介しています。今年一年間の更新を追っています。",
    "explanationJa": "この記事は、AIチャットボットChatGPTのアップデート情報を時系列でまとめたものです。",
    "translationJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと\n\n以下は、ChatGPTの製品アップデートとリリースに関するタイムラインです。最新のものから始まり、今年一年を通して更新しています。",
    "insightJa": "ChatGPTのようなAI技術は、顧客対応やコンテンツ作成など、様々な業務を効率化する可能性を秘めています。ビジネスだけでなく、日々の情報収集や学習方法にも大きな影響を与えるでしょう。",
    "recommendedBooks": [
      "ChatGPT 入門",
      "自然言語処理",
      "AI チャットボット"
    ],
    "tags": [
      "ChatGPT",
      "AI",
      "Chatbot",
      "Artificial Intelligence",
      "自然言語処理"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?ChatGPT%2CAI&sig=786"
  },
  {
    "id": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "title": "I quit all my AI fitness plans, and I feel free",
    "source": "rss",
    "url": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "summary": "AI sure does use a lot of words to say very little.\t\n\nThis is Optimizer, a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. Optimizer arrives in our subscribers' inboxes at 10AM ET. Opt in for Optimizer here.\nThis time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt amazing. Then life happened. \nA year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T15:00:00.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Over the shoulder shot of someone reading a lengthy AI insight from the Runna app\" data-caption=\"AI sure does use a lot of words to say very little.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAI sure does use a lot of words to say very little.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>This is </em><a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a><em>, a weekly newsletter sent every Friday from Verge senior reviewer</em> <a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a><em> that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. </em>Optimizer<em> arrives in our subscribers' inboxes at 10AM ET. Opt in for </em>Optimizer <em><a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</em></p>\n<p class=\"has-drop-cap has-text-align-none\">This time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt <em>amazing.</em> Then life happened. </p>\n<p class=\"has-text-align-none\">A year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIフィットネスプランをやめたら、心が軽くなった",
    "summaryJa": "筆者はAIフィットネスプランを利用していたが、情報過多や生活の変化により断念。AIからの解放で精神的な余裕を得たと述べています。",
    "explanationJa": "AIフィットネスプランをやめたことで、より自由な気持ちで運動に取り組めるようになったという記事です。",
    "translationJa": "<figure>\n\n<img alt=\"RunnaアプリからのAIインサイトを読んでいる人の肩越しの写真\" data-caption=\"AIは、ほとんど何も言っていないのに、実に多くの言葉を使いますね。\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAIは、ほとんど何も言っていないのに、実に多くの言葉を使いますね。\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>こちらは、Vergeのシニアレビュー担当者である</em> <a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a><em>が毎週金曜日に配信する週刊ニュースレター</em><a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a><em>です。Optimizerでは、あなたの人生を変えると豪語する最新の携帯電話、スマートウォッチ、アプリ、その他のガジェットを分析し、議論します。</em>Optimizer<em>は、東部時間午前10時に購読者の受信箱に届きます。</em>Optimizer<em>の購読は<a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">こちら</a>から。</em></p>\n<p class=\"has-drop-cap has-text-align-none\">去年の今頃、私は4マイルのランニングタイムを16分短縮し、週に3〜4回ウェイトリフティングを行い、6ヶ月間の継続的なトレーニングの結果、10ポンド減量しました。気分は<em>最高</em>でした。しかし、その後、色々なことが起こりました。</p>\n<p class=\"has-text-align-none\">1年後、私は3ヶ月間5K以上走っておらず、ストレスで10ポンド戻ってしまい、…に悩まされています…</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">The Vergeで記事全文を読む。</a></p>",
    "insightJa": "AIフィットネスプランは便利ですが、全ての人に合うわけではありません。自分の生活スタイルや目標に合わせて、最適な方法を選ぶことが大切です。時にはAIから離れて、自分の体と心と向き合う時間も必要かもしれません。",
    "recommendedBooks": [
      "フィットネス AI",
      "AI コーチング",
      "運動 習慣化"
    ],
    "tags": [
      "AI fitness",
      "Wellness",
      "Fitness app",
      "Runna",
      "健康"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%20fitness%2CWellness&sig=490"
  },
  {
    "id": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "title": "How to vibe-write a country hit",
    "source": "rss",
    "url": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "summary": "You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"I Run\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.\nOn this episode of The Vergecast, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent Switched on Pop podcast. Charlie takes us th …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T14:23:18.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/VRG_VST_1212_Site.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"<a href=\"https://www.digitalmusicnews.com/2025/11/24/havens-i-run-ai-song-explained/\">I Run</a>\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.</p>\n<p class=\"has-text-align-none\">On <a href=\"https://link.chtbl.com/vergecast\">this episode of <em>The Vergecast</em></a>, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent <em>Switched on Pop </em>podcast. Charlie takes us th …</p>\n<p><a href=\"https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIでカントリーヒット曲を作る方法",
    "summaryJa": "AIツール、特にSunoが音楽制作に大きな影響を与えており、それはカントリー音楽の本場ナッシュビルで顕著です。ポッドキャストでは、AI音楽の現状が議論されています。",
    "explanationJa": "AIが音楽制作、特にカントリー音楽の世界で存在感を増しているというお話です。",
    "translationJa": "ご存じないかもしれませんが、AIによって大部分または完全に作られた曲に、ほぼ確実に触れたことがあるでしょう。ここ数週間TikTokをスクロールしているなら、おそらく「I Run」を何度か耳にしたことがあるでしょう。しかし、ソーシャルおよび音楽プラットフォームで広まっている楽曲は数え切れません。一般的なAIツール、特にSunoは、音楽制作プロセスにおいて大きな役割を果たすようになっています。そして、それはカントリー音楽の本場、ナッシュビルにおいて、より顕著です。\n\nこのThe Vergecastのエピソードでは、音楽ジャーナリストであり、人気ポッドキャスト「Switched on Pop」の共同ホストでもあるチャーリー・ハーディング氏を迎え、ニレイとデイビッドが話を伺います。\n\n詳細はThe Vergeで。",
    "insightJa": "AIによる音楽制作は、アマチュアが気軽に音楽を作成できる可能性を広げます。ビジネスにおいては、著作権の問題や、AIが生成した音楽のクオリティコントロールなどが重要になってくるでしょう。",
    "recommendedBooks": [
      "AI音楽制作",
      "音楽生成AI",
      "AI作曲"
    ],
    "tags": [
      "AI music",
      "Country music",
      "Suno",
      "Nashville",
      "音楽生成AI"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%20music%2CCountry%20music&sig=682"
  },
  {
    "id": "43pZxbBPbS0s7iDFEyijjR",
    "title": "Ai2's new Olmo 3.1 extends reinforcement learning training for stronger reasoning benchmarks",
    "source": "rss",
    "url": "https://venturebeat.com/ai/ai2s-new-olmo-3-1-extends-reinforcement-learning-training-for-stronger",
    "summary": "The Allen Institute for AI (Ai2) recently released what it calls its most powerful family of models yet, Olmo 3. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.\nThe new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. \nAi2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. \nOlmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. \nAi2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. \n“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a blog post. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”\n\nTo get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.\nOlmo 3.1 Instruct 32B is \"optimized for chat, tool use, & multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a post on X. \nFor now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. \nBetter performance on benchmarks\nThe Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. \nOlmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. \nOlmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.\n“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. \n\nAi2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.\nCommitment to transparency and open source \nAi2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. \nOrganizations could add to the model’s data mix and retrain it to also learn from what’s been added.  \nThis has long been a commitment for Ai2, which also offers a tool called OlmoTrace that tracks how LLM outputs match its training data.  \n\n“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said.",
    "publishedAt": "Fri, 12 Dec 2025 05:00:00 GMT",
    "author": "",
    "category": "AI",
    "originalContent": "<p>The Allen Institute for AI (Ai2) recently released what it calls its most powerful <a href=\"https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning\"><u>family of models yet, Olmo 3</u></a>. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.</p><p>The new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. </p><p>Ai2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. </p><p>Olmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. </p><p>Ai2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. </p><p>“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a <a href=\"https://allenai.org/blog/olmo3\"><u>blog post</u></a>. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”</p><div></div><p>To get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.</p><p>Olmo 3.1 Instruct 32B is &quot;optimized for chat, tool use, &amp; multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a <a href=\"https://x.com/allen_ai/status/1999528338365247539\"><u>post on X</u></a>. </p><p>For now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. </p><h2>Better performance on benchmarks</h2><p>The Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. </p><p>Olmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. </p><p>Olmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.</p><p>“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. </p><div></div><p>Ai2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.</p><h2>Commitment to transparency and open source </h2><p>Ai2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. </p><p>Organizations could add to the model’s data mix and retrain it to also learn from what’s been added.  </p><p>This has long been a commitment for Ai2, which also offers a <a href=\"https://venturebeat.com/ai/whats-inside-the-llm-ai2-olmotrace-will-trace-the-source\"><u>tool called OlmoTrace</u></a> that tracks how LLM outputs match its training data.  </p><div></div><p>“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said. </p><p>\n\n\n\n\n\n</p>",
    "titleJa": "Ai2の新しいOlmo 3.1、強化学習のトレーニングを拡張し、より強力な推論ベンチマークを実現",
    "summaryJa": "Allen Institute for AI (Ai2) は、Olmo 3.1をリリース。効率性、透明性、制御に焦点を当て、推論、数学、コーディング性能が向上。APIアクセスも予定。",
    "explanationJa": "AI2が新しいAIモデルOlmo 3.1を発表しました。推論や数学の能力が向上し、より実用的なモデルになっています。",
    "translationJa": "アレン人工知能研究所（Ai2）は最近、これまでで最も強力なモデル群であるOlmo 3を発表しました。しかし、同社はモデルの改良を続け、強化学習（RL）の実行を拡張して、Olmo 3.1を作成しました。\n\n新しいOlmo 3.1モデルは、企業向けの効率、透明性、および制御に焦点を当てています。\n\nAi2は、Olmo 2の3つのバージョンのうち2つをアップデートしました。高度な研究向けに最適化されたフラッグシップモデルであるOlmo 3.1 Think 32Bと、指示に従うこと、複数ターンの対話、およびツール使用のために設計されたOlmo 3.1 Instruct 32Bです。\n\nOlmo 3には、プログラミング、理解、および数学のための第3のバージョンであるOlmo 3-Baseがあります。これは、継続的なファインチューニングにも適しています。\n\nAi2は、Olmo 3 Think 32BをOlmo 3.1にアップグレードするために、研究者たちが最高のRL実行をより長いトレーニングスケジュールで拡張したと述べました。\n\n「元のOlmo 3のリリース後、Dolci-Think-RLデータセット上で追加のエポックを使用して224個のGPUでさらに21日間トレーニングし、Olmo 3 32B ThinkのRLトレーニング実行を再開しました」と、Ai2はブログ投稿で述べています。「これにより、Olmo 3.1 32B Thinkが実現し、数学、推論、および指示に従うことのベンチマークで大幅な向上をもたらします。AIMEで5ポイント以上、ZebraLogicで4ポイント以上、IFEvalで4ポイント以上、IFBenchで20ポイント以上の改善が見られ、コーディングと複雑な多段階タスクでもより強力なパフォーマンスを発揮します。」\n\nOlmo 3.1 Instructを実現するために、Ai2はより小さいInstructサイズである7Bの背後にあるレシピをより大きなモデルに適用したと述べました。\n\nOlmo 3.1 Instruct 32Bは、「チャット、ツール使用、および複数ターンの対話に最適化されており、Olmo 3 Instruct 7Bのパフォーマンスが大幅に向上した兄弟モデルであり、実際のアプリケーションに対応できます」とAi2はXへの投稿で述べています。\n\n今のところ、新しいチェックポイントはAi2 PlaygroundまたはHugging Faceで入手可能であり、APIアクセスは近日中に提供される予定です。\n\nベンチマークでのより良いパフォーマンス\n\nOlmo 3.1モデルは、ベンチマークテストで優れたパフォーマンスを発揮し、予想どおりOlmo 3モデルを上回りました。\n\nOlmo 3.1 Thinkは、AIME 2025ベンチマークでQwen 3 32Bモデルを上回り、Gemma 27Bに近いパフォーマンスを発揮しました。\n\nOlmo 3.1 Instructは、オープンソースの競合他社に対して強力なパフォーマンスを発揮し、MathベンチマークではGemma 3のようなモデルにも打ち勝ちました。\n\n「Olmo 3.1 32B Instructに関しては、チャット、ツール使用、および複数ターンの対話用に構築された、より大規模な指示調整モデルです。Olmo 3.1 32B Instructは、現在までに最も有能な完全にオープンなチャットモデルであり、当社の評価では、最も強力な完全にオープンな32Bスケールの指示モデルです」と同社は述べています。\n\nAi2はまた、数学とコーディングのためにRL-Zero 7Bモデルをアップグレードしました。同社はXで、両方のモデルがより長く、より安定したトレーニング実行の恩恵を受けたと述べました。\n\n透明性とオープンソースへのコミットメント\n\nAi2は以前、VentureBeatに対し、企業や研究室に、モデルに入力されたデータとトレーニングに対するより多くの制御と理解を提供するために、Olmo 3モデル群を設計したと語りました。\n\n組織は、モデルのデータミックスに追加し、それを再トレーニングして、追加されたものからも学習できます。\n\nこれは、Ai2にとって長年のコミットメントであり、LLMの出力がトレーニングデータにどのように一致するかを追跡するOlmoTraceというツールも提供しています。\n\n「Olmo 3.1 Think 32BとOlmo 3.1 Instruct 32Bは、オープン性とパフォーマンスが共に進歩できることを示しています。同じモデルフローを拡張することで、データ、コード、およびトレーニングの決定に関するエンドツーエンドの透明性を維持しながら、機能を向上させ続けます」とAi2は述べています。",
    "insightJa": "Olmo 3.1の登場により、企業はAIモデルの透明性と制御性を高めながら、高度な推論能力を利用できるようになります。これにより、より信頼性の高いAI活用が進み、業務効率化や新たなビジネスチャンスの創出に繋がる可能性があります。",
    "recommendedBooks": [
      "大規模言語モデル",
      "強化学習 実践",
      "オープンソースAI"
    ],
    "tags": [
      "AI2",
      "Olmo 3.1",
      "Reinforcement Learning",
      "LLM",
      "Open Source AI"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI2%2COlmo%203.1&sig=900"
  },
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "title": "Trump signs AI executive order pushing to ban state laws",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "summary": "President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t\n\nOn Thursday evening, with White House AI and crypto czar David Sacks looking over his shoulder, Donald Trump signed an executive order aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order can't by itself unilaterally override state AI laws, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.\nIt specifically calls out Colorado's recently passed consumer protection law, making the claim that \"banning 'algorithmic discri …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T01:18:46.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks in the Oval Office\" data-caption=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/gettyimages-2251458899.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tPresident Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">On Thursday evening, with White House AI and crypto czar David Sacks <a href=\"https://www.youtube.com/live/rYDbVjXu5os?si=TUpA0_o7ORLU9jZh&amp;t=737\">looking over his shoulder</a>, Donald Trump <a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/\">signed an executive order</a> aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order <a href=\"https://www.theverge.com/column/829938/leaked-ai-executive-order-analysis\">can't by itself unilaterally override state AI laws</a>, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.</p>\n<p class=\"has-text-align-none\">It specifically calls out Colorado's <a href=\"https://leg.colorado.gov/bills/sb24-205\">recently passed consumer protection law</a>, making the claim that \"banning 'algorithmic discri …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "トランプ大統領、AI規制に関する大統領令に署名、州法の禁止を推進",
    "summaryJa": "トランプ大統領が、AI規制に関する連邦政府の単独権限掌握を目指す大統領令に署名。コロラド州の消費者保護法を名指しし、州法の影響力削減を指示。",
    "explanationJa": "トランプ大統領は、AI規制で連邦政府がより強い権限を持つようにする大統領令に署名しました。",
    "translationJa": "ドナルド・トランプ大統領は木曜日の夜、ホワイトハウスのAIおよび暗号資産担当顧問であるデイビッド・サックス氏が見守る中、人工知能（AI）の規制に関する連邦政府の単独権限掌握を目指す大統領令に署名しました。この大統領令自体は、州のAI法を一方的に覆すことはできませんが、連邦政府機関に対し、州法の影響力を削減または排除するための措置を講じ、連邦政府が異議を唱える可能性のある法律や、他のプログラムへの重要な資金提供を危険にさらす可能性のある法律を州が制定することを阻止するよう指示しています。\n\nこの大統領令は特に、コロラド州で最近可決された消費者保護法を名指しし、「アルゴリズムによる差別的…」との主張を展開しています。\n\n詳細はThe Vergeの記事をご覧ください: [https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws]",
    "insightJa": "この大統領令により、AI技術の発展や利用方法が大きく変化する可能性があります。企業は、今後の規制動向を注視し、柔軟に対応できる体制を整える必要がありそうです。また、個人のデータ保護やプライバシーに関する意識もさらに高まるかもしれません。",
    "recommendedBooks": [
      "人工知能 法規制",
      "AI政策",
      "アメリカ 政治"
    ],
    "tags": [
      "AI regulation",
      "Executive Order",
      "Trump",
      "Artificial Intelligence",
      "連邦政府"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%20regulation%2CExecutive%20Order&sig=929"
  },
  {
    "id": "https://techcrunch.com/?p=3075457",
    "title": "Google launched its deepest AI research agent yet — on the same day OpenAI dropped GPT-5.2",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/",
    "summary": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "publishedAt": "Fri, 12 Dec 2025 00:18:56 +0000",
    "author": "Julie Bort",
    "category": "AI",
    "originalContent": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "titleJa": "Google、過去最高のAI研究エージェントを発表―OpenAIがGPT-5.2を公開した同日に",
    "summaryJa": "GoogleはGemini 3 Proを基盤としたDeep Researchツールを開発者向けに公開。これにより、自身のアプリに組み込み可能になりました。",
    "explanationJa": "Googleの最新AI研究ツールが利用可能になり、様々なアプリで高度なAI機能が使えるようになります。",
    "translationJa": "Googleは、Gemini 3 Proを基盤としたDeep Researchツールを開発者が自身のアプリケーションに組み込めるようにしました。これは初の試みです。",
    "insightJa": "このツールによって、より高度なAI機能を組み込んだアプリケーションが開発され、日々の業務効率化や新しいサービスの創出が期待されます。ビジネスにおいては、競争優位性を築くための重要な要素となるでしょう。",
    "recommendedBooks": [
      "AI 開発",
      "Gemini AI",
      "大規模言語モデル"
    ],
    "tags": [
      "Google",
      "Gemini 3 Pro",
      "AI",
      "Deep Research",
      "OpenAI"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Google%2CGemini%203%20Pro&sig=793"
  },
  {
    "id": "7iBvnTz8OK7lcxexlxh4OW",
    "title": "Google’s new framework helps AI agents spend their compute and tool budget more wisely",
    "source": "rss",
    "url": "https://venturebeat.com/ai/googles-new-framework-helps-ai-agents-spend-their-compute-and-tool-budget",
    "summary": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.\nAs AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.\nFor enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.\nThe challenge of scaling tool use\nTraditional test-time scaling focuses on letting models \"think\" longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.\nThis introduces significant operational overhead for businesses. \"Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,\" Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. \"Tool calls themselves introduce additional API costs.\"\nThe researchers found that simply granting agents more test-time resources does not guarantee better performance. \"In a deep research task, if the agent has no sense of budget, it often goes down blindly,\" Wang and Liu explained. \"It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.\"\nOptimizing resources with Budget Tracker\nTo evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called \"Budget Tracker.\" This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.\nThe team hypothesized that \"providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.\"\nBudget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)\nIn Google's implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.\nTo test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.\nThey tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as Gemini 2.5 Pro, Gemini 2.5 Flash, and Claude Sonnet 4. The experiments show that this simple plug-in improves performance across various budget constraints.\n\"Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,\" the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.\nBATS: A comprehensive framework for budget-aware scaling\nTo further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent's behavior as it formulates its response.\nBATS uses multiple modules to orchestrate the agent's actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to \"dig deeper\" into a promising lead or \"pivot\" to alternative paths based on resource availability.\nGiven an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.\nThe iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.\nThe researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.\nBATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.\nAccording to the authors, this efficiency makes previously expensive workflows viable. \"This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,\" they said.\nAs enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.\n\"We believe the relationship between reasoning and economics will become inseparable,\" Wang and Liu said. \"In the future, [models] must reason about value.\"",
    "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
    "author": "bendee983@gmail.com (Ben Dickson)",
    "category": "AI",
    "originalContent": "<p>In a <a href=\"https://arxiv.org/abs/2511.17006\"><u>new paper</u></a> that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple &quot;Budget Tracker&quot; and a more comprehensive framework called &quot;Budget Aware Test-time Scaling.&quot; These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.</p><p>As AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.</p><p>For enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.</p><h2>The challenge of scaling tool use</h2><p>Traditional <a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>test-time scaling</u></a> focuses on letting models &quot;think&quot; longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.</p><p>This introduces significant operational overhead for businesses. &quot;Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,&quot; Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. &quot;Tool calls themselves introduce additional API costs.&quot;</p><p>The researchers found that simply granting agents more test-time resources does not guarantee better performance. &quot;In a deep research task, if the agent has no sense of budget, it often goes down blindly,&quot; Wang and Liu explained. &quot;It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.&quot;</p><h2>Optimizing resources with Budget Tracker</h2><p>To evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called &quot;Budget Tracker.&quot; This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.</p><p>The team hypothesized that &quot;providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.&quot;</p><p>Budget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)</p><p>In Google&#x27;s implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.</p><p>To test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.</p><p>They tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as <a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>, Gemini 2.5 Flash, and <a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>. The experiments show that this simple plug-in improves performance across various budget constraints.</p><p>&quot;Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,&quot; the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.</p><h2>BATS: A comprehensive framework for budget-aware scaling</h2><p>To further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent&#x27;s behavior as it formulates its response.</p><p>BATS uses multiple modules to orchestrate the agent&#x27;s actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to &quot;dig deeper&quot; into a promising lead or &quot;pivot&quot; to alternative paths based on resource availability.</p><p>Given an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.</p><p>The iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.</p><p>The researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.</p><p>BATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.</p><p>According to the authors, this efficiency makes previously expensive workflows viable. &quot;This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,&quot; they said.</p><p>As enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.</p><p>&quot;We believe the relationship between reasoning and economics will become inseparable,&quot; Wang and Liu said. &quot;In the future, [models] must reason about value.&quot;</p><p>\n</p>",
    "titleJa": "Googleの新しいフレームワーク、AIエージェントが計算リソースとツール予算をより賢く利用できるように",
    "summaryJa": "Googleの研究者が、LLMエージェントのツール利用効率を向上させるフレームワークを開発。Budget TrackerとBATSという2つの技術により、コストとパフォーマンスのバランスを最適化。",
    "explanationJa": "GoogleがAIエージェントのツール利用を効率化する新しい技術を発表し、より賢くリソースを使えるようになりました。",
    "translationJa": "<p>大規模言語モデル（LLM）エージェントにおけるツール利用を研究した<a href=\"https://arxiv.org/abs/2511.17006\"><u>新しい論文</u></a>において、Googleとカリフォルニア大学サンタバーバラ校の研究者たちは、エージェントがツールと計算リソースの予算をより効率的に利用できるようにするフレームワークを開発しました。研究者たちは、シンプルな「Budget Tracker」と、より包括的なフレームワークである「Budget Aware Test-time Scaling（BATS）」という2つの新しい技術を導入しました。これらの技術により、エージェントは残りの推論とツール利用の許容量を明確に認識できます。</p><p>AIエージェントが現実世界で機能するためにツール呼び出しに依存するにつれて、テスト時のスケーリングは、より賢いモデルというよりも、コストとレイテンシの制御が重要になってきています。</p><p>企業リーダーや開発者にとって、予算を意識したスケーリング技術は、予測不可能なコストや計算リソースの消費に見合う効果が得られないという問題に直面することなく、効果的なAIエージェントを導入するための現実的な道を提供します。</p><h2>ツール利用のスケーリングの課題</h2><p>従来の<a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>テスト時のスケーリング</u></a>は、モデルがより長く「考える」ことを重視しています。しかし、ウェブブラウジングのようなエージェント的なタスクでは、ツール呼び出しの回数が探索の深さと広さを直接決定します。</p><p>これは企業にとって重大な運用上のオーバーヘッドをもたらします。「ウェブページの閲覧などのツール呼び出しは、より多くのトークン消費につながり、コンテキスト長を増加させ、追加の遅延を引き起こします」と、論文の共著者であるZifeng WangとTengxiao LiuはVentureBeatに語っています。「ツール呼び出し自体が追加のAPIコストを発生させます。」</p><p>研究者たちは、エージェントにテスト時のリソースをより多く与えるだけでは、パフォーマンスの向上は保証されないことを発見しました。「深い調査タスクでは、エージェントが予算を意識していない場合、しばしば盲目的に突き進んでしまいます」とWangとLiuは説明しました。「やや関連性のある手がかりを見つけると、それに10回または20回のツール呼び出しを費やして深く掘り下げ、最終的にそのパス全体が行き止まりだったことに気づきます。」</p><h2>Budget Trackerによるリソースの最適化</h2><p>ツール利用の予算をどのように最適化できるかを評価するために、研究者たちはまず「Budget Tracker」と呼ばれる軽量なアプローチを試しました。このモジュールはプラグインとして機能し、エージェントにリソースの利用可能性に関する継続的なシグナルを提供し、予算を意識したツール利用を可能にします。</p><p>研究チームは、「明示的な予算シグナルを提供することで、モデルはリソースの制約を内面化し、追加のトレーニングなしで戦略を適応させることができる」と仮説を立てました。</p><p>Budget Trackerはプロンプトレベルでのみ動作するため、実装が容易です。（論文にはBudget Trackerに使用されるプロンプトの詳細が記載されており、実装が容易になっています。）</p><p>Googleの実装では、トラッカーは予算体制とそれに対応するツールの使用に関する推奨事項を説明する簡単なポリシーガイドラインを提供します。応答プロセスの各ステップで、Budget Trackerはエージェントにリソースの消費量と残りの予算を明確に認識させ、その後の推論ステップを更新されたリソース状態に基づいて調整できるようにします。</p><p>これをテストするために、研究者たちは、モデルが反復的に出力を洗練するシーケンシャルスケーリングと、複数の独立した実行を実施して集計するパラレルスケーリングという2つのパラダイムで実験を行いました。彼らは、ReActスタイルのループに従って、検索および閲覧ツールを備えた検索エージェントで実験を行いました。ReAct（Reasoning + Acting）は、モデルが内部思考と外部アクションを交互に行う一般的な手法です。真のコストパフォーマンスのスケーリング傾向を追跡するために、内部トークン消費と外部ツールインタラクションの両方のコストを総合的に考慮した統一コストメトリックを開発しました。</p><p>彼らは、<a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>、Gemini 2.5 Flash、および<a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>などのモデルを使用して、BrowseCompやHLE-Searchを含む、外部検索を必要とする3つの情報検索QAデータセットでBudget Trackerをテストしました。実験の結果、このシンプルなプラグインがさまざまな予算制約下でパフォーマンスを向上させることが示されました。</p><p>「Budget Trackerを追加すると、検索呼び出しが40.4％減少し、閲覧呼び出しが19.9％減少し、全体的なコストが31.3％削減され、同等の精度が得られます」と著者らはVentureBeatに語っています。最後に、Budget Trackerは予算が増加するにつれてスケールし続けましたが、プレーンなReActはある閾値を超えると停滞しました。</p><h2>BATS：予算を意識したスケーリングのための包括的なフレームワーク</h2><p>ツール利用のリソース最適化をさらに改善するために、研究者たちは、与えられた予算内でエージェントのパフォーマンスを最大化するように設計されたフレームワークであるBudget Aware Test-time Scaling（BATS）を導入しました。BATSは、残りのリソースの継続的なシグナルを維持し、この情報を使用して、エージェントが応答を策定する際にその動作を動的に適応させます。</p><p>BATSは、複数のモジュールを使用してエージェントのアクションを調整します。計画モジュールは、段階的な努力を現在の予算に合わせて調整し、検証モジュールは、有望な手がかりを「より深く掘り下げる」か、リソースの利用可能性に基づいて代替パスに「ピボットする」かを決定します。</p><p>情報検索の質問とツール呼び出しの予算が与えられた場合、BATSはまず計画モジュールを使用して、構造化されたアクションプランを策定し、どのツールを呼び出すかを決定します。ツールが呼び出されると、その応答が推論シーケンスに追加され、新しい証拠とともにコンテキストが提供されます。エージェントが候補の回答を提案すると、検証モジュールがそれを検証し、現在のシーケンスを続行するか、残りの予算で新しい試行を開始するかを決定します。</p><p>反復プロセスは、予算化されたリソースが使い果たされたときに終了し、その時点でLLMが審査員として機能し、検証されたすべての回答の中から最良の回答を選択します。実行全体を通して、Budget Trackerは反復ごとにリソースの使用量と残りの予算の両方を継続的に更新します。</p><p>研究者たちは、BrowseComp、BrowseComp-ZH、およびHLE-Searchベンチマークで、標準のReActやさまざまなトレーニングベースのエージェントを含むベースラインに対してBATSをテストしました。彼らの実験は、BATSが競合する手法よりも少ないツール呼び出しを使用し、全体的なコストを抑えながら、より高いパフォーマンスを達成することを示しています。Gemini 2.5 Proをバックボーンとして使用すると、BATSは標準のReActの12.6％と比較してBrowseCompで24.6％の精度を達成し、ReActの20.5％と比較してHLE-Searchで27.0％の精度を達成しました。</p><p>BATSは、予算制約下での有効性を向上させるだけでなく、より優れたコストパフォーマンスのトレードオフももたらします。たとえば、BrowseCompデータセットでは、BATSは同様の結果を達成するために50セント以上を必要としたパラレルスケーリングのベースラインと比較して、約23セントのコストでより高い精度を達成しました。</p><p>著者らによると、この効率性により、これまでコストがかかりすぎて実現できなかったワークフローが実現可能になります。「これにより、複雑なコードベースのメンテナンス、デューデリジェンス調査、競争環境調査、コンプライアンス監査、および多段階ドキュメント分析など、長期にわたるデータ集約型のエンタープライズアプリケーションが数多く可能になります」と彼らは述べています。</p><p>企業が独自のリソースを管理するエージェントを導入しようとするにつれて、コストと精度のバランスを取る能力が重要な設計要件になります。</p><p>「推論と経済学の関係は切り離せなくなると思います」とWangとLiuは述べています。「将来的には、（モデルは）価値について推論する必要があります。」</p>",
    "insightJa": "AIエージェントがコストを意識して行動することで、企業はより効率的な運用が可能になります。今後は、AIが経済的な価値を判断し、より賢くリソースを配分する時代になるでしょう。",
    "recommendedBooks": [
      "AIエージェント",
      "大規模言語モデル 実践",
      "AI プロダクト開発"
    ],
    "tags": [
      "AI Agent",
      "LLM",
      "Budget Aware Scaling",
      "Tool Use",
      "コスト最適化"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%20Agent%2CLLM&sig=23"
  },
  {
    "id": "6h3LTzDwRwKFT22aRVaumY",
    "title": "GPT-5.2 first impressions: a powerful update, especially for business tasks and workflows",
    "source": "rss",
    "url": "https://venturebeat.com/ai/gpt-5-2-first-impressions-a-powerful-update-especially-for-business-tasks",
    "summary": "OpenAI has officially released GPT-5.2, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming \"incremental\" update for casual conversationalists.\nFollowing early access periods and today's broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. \nHere is a roundup of the first reactions to OpenAI’s latest flagship model.\n\"AI as a serious analyst\"\nThe strongest praise for GPT-5.2 centers on its ability to handle \"hard problems\" that require extended thinking time.\nMatt Shumer, CEO of HyperWriteAI, did not mince words in his review, calling GPT-5.2 Pro \"the best model in the world.\" \nShumer highlighted the model's tenacity, noting that \"it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.\"\nThis sentiment was echoed by Allie K. Miller, an AI entrepreneur and former AWS executive. Miller described the model as a step toward \"AI as a serious analyst\" rather than a \"friendly companion.\"\n\"The thinking and problem-solving feel noticeably stronger,\" Miller wrote on X. \"It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.\"\nEnterprise gains: Box reports distinct performance jumps\nFor the enterprise sector, the update appears to be even more significant. \nAaron Levie, CEO of Box, revealed on X that his company has been testing GPT-5.2 in early access. Levie reported that the model performs \"7 points better than GPT-5.1\" on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.\n\"The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,\" Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.\nRutuja Rajwade, a Senior Product Marketing Manager at Box, expanded on this in a company blog post, citing specific latency improvements. \n\"Complex extraction\" tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. \nRajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.\nA \"serious leap\" for coding and simulation\nDevelopers are finding GPT-5.2 particularly potent for \"one-shot\" generation of complex code structures.\nPietro Schirano, CEO of magicpathai, shared a video of the model building a full 3D graphics engine in a single file with interactive controls. \"It’s a serious leap forward in complex reasoning, math, coding, and simulations,\" Schirano posted. \"The pace of progress is unreal.\"\n\nSimilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, demonstrated the model's ability to create a visually complex shader—an infinite neo-gothic city in a stormy ocean—via a single prompt.\nThe Agentic Era: Long-running autonomy\nPerhaps the most functional shift is the model's ability to stay on task for hours without losing the thread.\nDan Shipper, CEO of thoughtful AI testing newsletter Every, reported that the model successfully performed a profit and loss (P&L) analysis that required it to work autonomously for two hours. \"It did a P&L analysis where it worked for 2 hours and gave me great results,\" Shipper wrote.\nHowever, Shipper also noted that for day-to-day tasks, the update feels \"mostly incremental.\" \nIn an article for Every, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is \"less resourceful\" than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user's location from email data.\nThe downsides: Speed and Rigidity\nDespite the reasoning capabilities, the \"feel\" of the model has drawn critique.\nShumer highlighted a significant \"speed penalty\" when using the model's Thinking mode. \"In my experience the Thinking mode is very slow for most questions,\" Shumer wrote in his deep-dive review. \"I almost never use Instant.\"\nAllie Miller also pointed out issues with the model's default behavior. \"The downside is tone and format,\" she noted. \"The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.\"\nThe Verdict\nThe early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: \"For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.\"\nHowever, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. \"My favorite model remains Claude Opus 4.5,\" Miller admitted, \"but my complex ChatGPT work will get a nice incremental boost.\"",
    "publishedAt": "Thu, 11 Dec 2025 23:26:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>OpenAI has officially <a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">released GPT-5.2</a>, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming &quot;incremental&quot; update for casual conversationalists.</p><p>Following early access periods and today&#x27;s broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. </p><p>Here is a roundup of the first reactions to OpenAI’s latest flagship model.</p><h3><b>&quot;AI as a serious analyst&quot;</b></h3><p>The strongest praise for GPT-5.2 centers on its ability to handle &quot;hard problems&quot; that require extended thinking time.</p><p>Matt Shumer, CEO of HyperWriteAI, did not mince words in <a href=\"https://shumer.dev/gpt52review\">his review</a>, calling GPT-5.2 Pro &quot;the best model in the world.&quot; </p><p>Shumer highlighted the model&#x27;s tenacity, noting that &quot;it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.&quot;</p><p>This sentiment was<a href=\"https://x.com/alliekmiller/status/1999189893910790427\"> echoed by Allie K. Miller</a>, an AI entrepreneur and former AWS executive. Miller described the model as a step toward &quot;AI as a serious analyst&quot; rather than a &quot;friendly companion.&quot;</p><p>&quot;The thinking and problem-solving feel noticeably stronger,&quot; Miller wrote on X. &quot;It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.&quot;</p><h3><b>Enterprise gains: Box reports distinct performance jumps</b></h3><p>For the enterprise sector, the update appears to be even more significant. </p><p><a href=\"https://x.com/levie/status/1999191612321391058\">Aaron Levie, CEO of Box, revealed on X</a> that his company has been testing GPT-5.2 in early access. Levie reported that the model performs &quot;7 points better than GPT-5.1&quot; on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.</p><p>&quot;The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,&quot; Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.</p><p>Rutuja Rajwade, a Senior Product Marketing Manager at Box, <a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">expanded on this in a company blog post</a>, citing specific latency improvements. </p><p>&quot;Complex extraction&quot; tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. </p><p>Rajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.</p><h3><b>A &quot;serious leap&quot; for coding and simulation</b></h3><p>Developers are finding GPT-5.2 particularly potent for &quot;one-shot&quot; generation of complex code structures.</p><p>Pietro Schirano, CEO of magicpathai, <a href=\"https://x.com/skirano/status/1999182295685644366\">shared a video </a>of the model building a full 3D graphics engine in a single file with interactive controls. &quot;It’s a serious leap forward in complex reasoning, math, coding, and simulations,&quot; Schirano posted. &quot;The pace of progress is unreal.&quot;</p><div></div><p>S<!-- -->imilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, <a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">demonstrated the model&#x27;s ability to create a visually complex shader</a>—an infinite neo-gothic city in a stormy ocean—via a single prompt.</p><h3><b>The Agentic Era: Long-running autonomy</b></h3><p>Perhaps the most functional shift is the model&#x27;s ability to stay on task for hours without losing the thread.</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">Dan Shipper, CEO of thoughtful AI testing newsletter Every</a>, reported that the model successfully performed a profit and loss (P&amp;L) analysis that required it to work autonomously for two hours. &quot;It did a P&amp;L analysis where it worked for 2 hours and gave me great results,&quot; Shipper wrote.</p><p>However, Shipper also noted that for day-to-day tasks, the update feels &quot;mostly incremental.&quot; </p><p>In <a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">an article for Every</a>, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is &quot;less resourceful&quot; than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user&#x27;s location from email data.</p><h3><b>The downsides: Speed and Rigidity</b></h3><p>Despite the reasoning capabilities, the &quot;feel&quot; of the model has drawn critique.</p><p>Shumer highlighted a significant &quot;speed penalty&quot; when using the model&#x27;s Thinking mode. &quot;In my experience the Thinking mode is very slow for most questions,&quot; Shumer wrote in his deep-dive review. &quot;I almost never use Instant.&quot;</p><p>Allie Miller also pointed out issues with the model&#x27;s default behavior. &quot;The downside is tone and format,&quot; she noted. &quot;The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.&quot;</p><h3><b>The Verdict</b></h3><p>The early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: &quot;For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.&quot;</p><p>However, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. &quot;My favorite model remains Claude Opus 4.5,&quot; Miller admitted, &quot;but my complex ChatGPT work will get a nice incremental boost.&quot;</p>",
    "titleJa": "GPT-5.2の第一印象：特にビジネス用途とワークフローにおいて強力なアップデート",
    "summaryJa": "GPT-5.2は、深い自律的な推論とコーディング能力が向上したが、日常会話用途では控えめなアップデート。企業分野では性能向上が顕著で、開発者にも有用。",
    "explanationJa": "GPT-5.2は、ビジネスや専門的なタスクにおいて、より高度な問題解決能力を提供するAIモデルです。",
    "translationJa": "<p>OpenAIは正式に<a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">GPT-5.2をリリースしました</a>。早期テスターからの反応（OpenAIが一般公開の数日前、場合によっては数週間前にモデルを配布した人々）は、二面性のある評価を示しています。それは、深遠な自律的推論とコーディングにおいて記念碑的な飛躍である一方、日常的な会話者にとっては、潜在的に「漸進的な」アップデートに過ぎない可能性があります。</p><p>早期アクセス期間と今日のより広範な展開を受けて、経営幹部、開発者、アナリストは、X（旧Twitter）や企業のブログで最初のテスト結果を共有しています。</p><p>以下は、OpenAIの最新フラッグシップモデルに対する最初の反応のまとめです。</p><h3><b>「真剣なアナリストとしてのAI」</b></h3><p>GPT-5.2に対する最も強い称賛は、長時間の思考時間を必要とする「難しい問題」を処理する能力に集中しています。</p><p>HyperWriteAIのCEOであるMatt Shumerは、<a href=\"https://shumer.dev/gpt52review\">彼のレビュー</a>で率直に、GPT-5.2 Proを「世界最高のモデル」と呼んでいます。</p><p>Shumerは、モデルの粘り強さを強調し、「難しい問題について**1時間以上**考えます。そして、他のモデルが触れることのできないタスクをやり遂げます」と述べています。</p><p>この感情は、AI起業家で元AWS幹部の<a href=\"https://x.com/alliekmiller/status/1999189893910790427\">Allie K. Millerによっても反映されています</a>。Millerは、このモデルを「フレンドリーな仲間」ではなく、「真剣なアナリストとしてのAI」への一歩と表現しました。</p><p>「思考と問題解決が著しく強化されていると感じます」とMillerはXに書いています。「私が普段見慣れているよりもはるかに深い説明をしてくれます。ある時、タスクの途中で、自分のOCRを改善するコードを文字通り書きました。」</p><h3><b>企業向けの利点：Boxが明確なパフォーマンスの向上を報告</b></h3><p>企業セクターにとって、このアップデートはさらに重要であるようです。</p><p><a href=\"https://x.com/levie/status/1999191612321391058\">BoxのCEOであるAaron LevieはXで</a>、彼の会社がGPT-5.2を早期アクセスでテストしていることを明らかにしました。Levieは、金融サービスやライフサイエンスにおける現実世界の知識労働に近い、拡張された推論テストで、このモデルが「GPT-5.1よりも7ポイント優れている」と報告しました。</p><p>「このモデルは、GPT-5.1やGPT-5よりもはるかに高速にタスクの大部分を実行しました」とLevieは述べ、Box AIがGPT-5.2の統合を間もなく展開することを確認しました。</p><p>BoxのシニアプロダクトマーケティングマネージャーであるRutuja Rajwadeは、<a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">会社のブログ投稿で</a>、これをさらに詳しく説明し、具体的なレイテンシーの改善を挙げています。</p><p>「複雑な抽出」タスクは、GPT-5では46秒かかっていたのが、GPT-5.2ではわずか12秒に短縮されました。</p><p>Rajwadeはまた、メディアおよびエンターテインメント分野における推論能力の向上にも言及し、GPT-5.1の76％の精度から、新しいモデルでは81％に向上しました。</p><h3><b>コーディングとシミュレーションにおける「重大な飛躍」</b></h3><p>開発者は、GPT-5.2が複雑なコード構造の「ワンショット」生成に特に強力であると感じています。</p><p>magicpathaiのCEOであるPietro Schiranoは、インタラクティブなコントロールを備えた完全な3Dグラフィックスエンジンを1つのファイルで構築するモデルの<a href=\"https://x.com/skirano/status/1999182295685644366\">ビデオを共有しました</a>。「これは、複雑な推論、数学、コーディング、シミュレーションにおける重大な飛躍です」とSchiranoは投稿しました。「進歩のペースは非現実的です。」</p><div></div><p>同様に、ペンシルベニア大学ウォートンスクールの教授であり、長年のLLMおよびAIのパワーユーザーでありライターでもあるEthan Mollickは、<a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">単一のプロンプトを介して、視覚的に複雑なシェーダー（嵐の海にある無限のネオゴシック様式の都市）を作成するモデルの能力を実証しました</a>。</p><h3><b>エージェントの時代：長期的な自律性</b></h3><p>おそらく最も機能的な変化は、モデルがスレッドを失うことなく何時間もタスクを継続できる能力です。</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">思慮深いAIテストニュースレターEveryのCEOであるDan Shipper</a>は、モデルが2時間自律的に作業する必要のある損益（P＆L）分析を正常に実行したと報告しました。「2時間作業し、素晴らしい結果をもたらしてくれた損益分析を行いました」とShipperは書いています。</p><p>ただし、Shipperはまた、日々のタスクでは、このアップデートは「ほとんど漸進的」に感じると述べています。</p><p><a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">Everyの記事</a>で、Katie Parrottは、GPT-5.2は指示に従うことに優れているものの、メールデータからユーザーの所在地を推測するなど、特定のコンテキストではClaude Opus 4.5のような競合製品よりも「リソースが少ない」と書いています。</p><h3><b>短所：速度と硬直性</b></h3><p>推論能力にもかかわらず、モデルの「感触」は批判を集めています。</p><p>Shumerは、モデルのThinkingモードを使用するときの重大な「速度ペナルティ」を強調しました。「私の経験では、Thinkingモードはほとんどの質問に対して非常に遅いです」とShumerは彼の詳細なレビューで書いています。「私はほとんどInstantを使用しません。」</p><p>Allie Millerはまた、モデルのデフォルトの動作の問題を指摘しました。「短所はトーンとフォーマットです」と彼女は述べています。「デフォルトの音声は少し硬直的に感じられ、長さ/マークダウンの動作は極端です。単純な質問が58個の箇条書きと番号付きのポイントになりました。」</p><h3><b>評決</b></h3><p>早期の反応は、GPT-5.2が、カジュアルなチャットよりもパワーユーザー、開発者、およびエンタープライズエージェント向けに最適化されたツールであることを示唆しています。Shumerがレビューで要約したように、「深い研究、複雑な推論、および注意深い思考から恩恵を受けるタスクにとって、GPT-5.2 Proは現在利用可能な最良のオプションです。」</p><p>ただし、創造的な文章作成や、迅速で流動的な回答を求めるユーザーにとっては、Claude Opus 4.5のようなモデルが依然として強力な競争相手です。「私のお気に入りのモデルは依然としてClaude Opus 4.5です」とMillerは認めました。「しかし、私の複雑なChatGPTの作業は、素晴らしい漸進的な後押しを受けるでしょう。」</p>",
    "insightJa": "GPT-5.2の登場により、企業はより高度なAIを活用して業務効率を向上させることが期待されます。個人レベルでは、特定の専門分野において、より質の高いサポートを得られるようになるかもしれません。",
    "recommendedBooks": [
      "GPT-5.2 活用",
      "AI ビジネス応用",
      "大規模言語モデル 実践"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "AI",
      "LLM",
      "Business Applications"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?GPT-5.2%2COpenAI&sig=885"
  },
  {
    "id": "http://arxiv.org/abs/2512.10957v1",
    "title": "SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10957v1",
    "summary": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "publishedAt": "2025-12-11T18:59:56Z",
    "author": "Yukai Shi",
    "category": "AI",
    "originalContent": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "titleJa": "SceneMaker：分離された遮蔽除去と姿勢推定モデルを用いたオープンセット3Dシーン生成",
    "summaryJa": "本研究では、SceneMakerという分離型3Dシーン生成フレームワークを提案します。遮蔽除去モデルを分離し、姿勢推定モデルを統合することで、高品質なジオメトリと正確な姿勢を生成します。",
    "explanationJa": "SceneMakerは、3Dのシーンを生成する際に、隠れた部分をうまく処理し、物体の位置を正確に推定する新しい方法です。",
    "translationJa": "本研究では、SceneMakerという分離型3Dシーン生成フレームワークを提案します。既存の手法は、十分なオープンセットの遮蔽除去と姿勢推定の事前知識が不足しているため、厳しい遮蔽とオープンセットの設定下で、高品質なジオメトリと正確な姿勢を同時に生成することが困難です。これらの課題に対処するため、まず遮蔽除去モデルを3Dオブジェクト生成から分離し、画像データセットと収集した遮蔽除去データセットを活用することで、より多様なオープンセットの遮蔽パターンに対応できるように強化します。次に、自己注意とクロス注意の両方に対してグローバルメカニズムとローカルメカニズムを統合した、統一された姿勢推定モデルを提案し、精度を向上させます。さらに、姿勢推定モデルの汎化能力を拡張するために、オープンセット3Dシーンデータセットを構築します。包括的な実験により、屋内およびオープンセットのシーンの両方において、提案する分離型フレームワークの優位性が示されています。コードとデータセットはhttps://idea-research.github.io/SceneMaker/で公開されています。",
    "insightJa": "この技術が進むことで、ゲームやVRなどの分野で、よりリアルで自然な3D空間が実現可能になります。また、自動運転やロボット工学において、周囲の状況をより正確に把握し、安全な行動を支援することが期待されます。",
    "recommendedBooks": [
      "3Dモデリング",
      "コンピュータビジョン",
      "機械学習 実践"
    ],
    "tags": [
      "3D scene generation",
      "De-occlusion",
      "Pose estimation",
      "SceneMaker",
      "Computer Vision"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?3D%20scene%20generation%2CDe-occlusion&sig=609"
  },
  {
    "id": "http://arxiv.org/abs/2512.10952v1",
    "title": "Hierarchical Dataset Selection for High-Quality Data Sharing",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10952v1",
    "summary": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Xiaona Zhou",
    "category": "AI",
    "originalContent": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "titleJa": "高品質なデータ共有のための階層的データセット選択",
    "summaryJa": "機械学習の成功は高品質な学習データに依存。異種データセット群から、有用なものを効率的に選択する手法DaSHを提案。既存手法を大幅に上回る性能を示す。",
    "explanationJa": "DaSHという手法で、機械学習の学習データを選ぶのが簡単になり、より賢いAIが作られるようになるかもしれません。",
    "translationJa": "現代の機械学習の成功は、高品質な学習データへのアクセスに大きく依存しています。公共リポジトリからのデータ取得や機関間での共有など、多くの現実世界のシナリオにおいて、データは本質的に離散的なデータセットとして組織化され、関連性、品質、有用性が異なります。したがって、有用なデータセットを検索するためにどのリポジトリまたは機関を選択するか、そしてどのデータセットをモデルトレーニングに組み込むかは、非常に重要な決定となります。しかし、既存の方法のほとんどは個々のサンプルを選択し、すべてのデータを等しく関連性があるとみなし、データセットとそのソース間の違いを無視しています。本研究では、データセット選択というタスクを形式化します。これは、大規模で異質なプールからデータセット全体を選択し、リソースの制約下でダウンストリームのパフォーマンスを向上させるものです。私たちは、データセットレベルとグループ（例：コレクション、機関）レベルの両方で有用性をモデル化するデータセット選択手法Dataset Selection via Hierarchies (DaSH)を提案し、限られた観察からの効率的な汎化を可能にします。2つの公開ベンチマーク（Digit-FiveとDomainNet）において、DaSHは最先端のデータ選択ベースラインを最大26.2%精度で上回り、探索に必要なステップ数は大幅に少なくなっています。アブレーション実験は、DaSHが低リソース設定や関連データセットの不足に対して堅牢であることを示しており、実用的なマルチソース学習ワークフローにおけるスケーラブルで適応的なデータセット選択に適しています。",
    "insightJa": "高品質なデータセットを効率的に選択できるようになることで、AIの性能が向上し、医療診断や自動運転などの分野で、より信頼性の高いサービスが提供されるようになることが期待されます。ビジネスにおいては、より少ないコストで高度なAIを構築できる可能性が広がります。",
    "recommendedBooks": [
      "機械学習 実践",
      "データサイエンス 入門",
      "深層学習 理論"
    ],
    "tags": [
      "Machine Learning",
      "Dataset Selection",
      "Data Quality",
      "Hierarchical Learning",
      "DaSH"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Machine%20Learning%2CDataset%20Selection&sig=604"
  },
  {
    "id": "http://arxiv.org/abs/2512.10949v1",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10949v1",
    "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "publishedAt": "2025-12-11T18:59:52Z",
    "author": "Yiwen Tang",
    "category": "AI",
    "originalContent": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "titleJa": "テキストからの3D生成における強化学習の準備はできているか？段階的な調査",
    "summaryJa": "テキストから3Dモデルを生成する際に、強化学習(RL)を適用する研究。報酬設計、アルゴリズム、ベンチマーク、階層型RLなどを検討し、新たなモデルAR3D-R1を開発。",
    "explanationJa": "テキストで指示すると、3Dモデルを自動で作成できる技術が進化しています。その精度を上げるために強化学習が使われています。",
    "translationJa": "強化学習（RL）は、大規模言語モデルやマルチモーダルモデルで効果的であることがすでに証明されており、最近では2D画像生成を強化するためにうまく拡張されています。しかし、3Dオブジェクトの空間的複雑さがより高く、全体的に一貫した形状と、きめ細かい局所的なテクスチャが必要となるため、3D生成へのRLの適用は、ほとんど未開拓のままです。これにより、3D生成は報酬設計とRLアルゴリズムに著しく敏感になります。これらの課題に対処するために、我々は、テキストから3Dの自己回帰生成のためのRLに関する最初の体系的な研究を、いくつかの側面から実施します。（1）報酬設計：報酬の側面とモデルの選択を評価し、人間の好みに合わせることが重要であること、および一般的なマルチモーダルモデルが3D属性に対して堅牢なシグナルを提供することを示します。（2）RLアルゴリズム：GRPOの変種を研究し、トークンレベルの最適化の有効性を強調し、トレーニングデータと反復のスケールをさらに調査します。（3）テキストから3Dへのベンチマーク：既存のベンチマークは、3D生成モデルにおける暗黙的な推論能力を測定できないため、MME-3DRを導入します。（4）高度なRLパラダイム：3D生成の自然な階層構造に動機づけられ、専用の報酬アンサンブルを通じてグローバルからローカルへの階層的な3D生成を最適化するHi-GRPOを提案します。これらの洞察に基づいて、粗い形状からテクスチャの洗練まで、エキスパートである最初のRL強化テキストから3DモデルであるAR3D-R1を開発します。この研究が、3D生成のためのRL駆動型の推論に関する洞察を提供することを願っています。コードはhttps://github.com/Ivan-Tang-3D/3DGen-R1で公開されています。",
    "insightJa": "この技術が進歩すると、デザイナーやエンジニアでなくても、テキストで指示するだけで簡単に3Dモデルを作成できるようになります。製品開発やエンターテインメントなど、様々な分野への応用が期待されます。",
    "recommendedBooks": [
      "3Dモデリング 入門",
      "強化学習 実践",
      "AI デザイン"
    ],
    "tags": [
      "Reinforcement Learning",
      "Text-to-3D",
      "3D Generation",
      "AR3D-R1",
      "強化学習"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Reinforcement%20Learning%2CText-to-3D&sig=610"
  },
  {
    "id": "5AH2xqcQJzMolV09W5VM43",
    "title": "OpenAI's GPT-5.2 is here: what enterprises need to know",
    "source": "rss",
    "url": "https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know",
    "summary": "The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, GPT-5.2.\nIt comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival Google’s Gemini 3 LLM seized the top spot on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.\nOpenAI describes GPT-5.2 as its \"most capable model series yet for professional knowledge work,\" aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.\n\"It’s our most advanced frontier model and the strongest yet in the market for professional use,\" Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. \"We designed 5.2 to unlock even more economic value for people. It's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.\"\nGPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.\nThe model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes \"Reasoning token support,\" confirming the underlying architecture uses the chain-of-thought processing popularized by the \"o1\" series.\nThe 'Code Red' Reality Check\nThe release arrives following The Information's report of an emergency \"Code Red\" directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the \"quality gap\" exposed by Gemini 3. The Verge similarly reported on the timing of GPT-5.2's release ahead of the official announcement. \nDuring the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.\n\"It is important to note this has been in the works for many, many months,\" Simo told reporters. She clarified that while the \"Code Red\" helped focus the company, it wasn't the sole driver of the timeline. \n\"We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that's not the reason it's coming out this week in particular.\"\nMax Schwarzer, lead of OpenAI's post-training team, echoed this sentiment to dispel the idea of a panic launch. \"We've been planning for this release since a very long time ago... this specific week we talked about many months ago.\"\nA spokesperson from OpenAI further clarified that the \"Code Red\" call applied to ChatGPT as a product, not solely underlying model development or the release of new models.\nUnder the Hood: Instant, Thinking, and Pro\nOpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of \"reasoning\" models with user demand for speed:\n\nGPT-5.2 Instant: Optimized for speed and daily tasks like writing, translation, and information seeking.\n\nGPT-5.2 Thinking: Designed for \"complex, structured work\" and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.\n\nGPT-5.2 Pro: The new heavyweight champion. OpenAI describes this as its \"smartest and most trustworthy option,\" delivering the highest accuracy for difficult questions where quality outweighs latency.\n\nFor developers, the models are available immediately in the application programming interface (API) as gpt-5.2, gpt-5.2-chat-latest (Instant), and gpt-5.2-pro.\nThe Numbers: Beating the Benchmarks\nThe GPT-5.2 release includes leading metrics across most domains — specifically those that target the \"professional knowledge work\" gap where competitors have recently gained ground.\nOpenAI highlighted a new benchmark called GDPval, which measures performance on \"well-specified knowledge work tasks\" across 44 occupations. \n\"GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,\" Simo said.\nIn the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. \nHe emphasized that this benchmark is \"more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.\"Other key benchmark results include:\n\nGPQA Diamond (Science): GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).\n\nFrontierMath: On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.\n\nARC-AGI-1: GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring 90.5%\n\nThe Price of Intelligence\nPerformance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of \"thinking\" mode. They're also on the upper-end of API costs for the industry.  \n\nGPT-5.2 Thinking: Priced at $1.75 per 1 million input tokens and $14 per 1 million output tokens.\n\nGPT-5.2 Pro: The costs jump significantly to $21 per 1 million input tokens and $168 per 1 million output tokens.\n\nGPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.\nThe high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.\nOpenAI argues that despite the higher per-token cost, the model’s \"greater token efficiency\" and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.\nHere's how it compares to the current API costs for other competing models across the LLM field:\n\n\nModel\n\nInput (/1M)\n\nOutput (/1M)\n\nTotal Cost\n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nQwen 3 Plus\n\n$0.40\n\n$1.20\n\n$1.60\n\nAlibaba Cloud\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen-Max\n\n$1.60\n\n$6.40\n\n$8.00\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nClaude Opus 4.5\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nImage Generation: Nothing New Yet...But 'More to Come'\nDuring the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google's Gemini 3 Image aka Nano Banana Pro. \nUnfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI's integrated DALL-E 3 and gpt-4o native image generation models.\n\"On image Gen, nothing to announce today, but more to come,\" Simo said. She acknowledged the popularity of the feature, adding, \"We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.\" \nAidan Clark, OpenAI's lead of training, also declined to comment on visual generation specifics, stating simply, \"I can't really speak to image Gen myself.\" \nThe 'Mega-Agent' Era\nBeyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of \"long-running agents\" capable of executing multi-step workflows without human hand-holding.\"\nBox found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,\" Simo said. \nShe also noted that Notion reported the model \"outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.\"Schwarzer added that coding startups like Augment Code found the model \"delivered substantially stronger deep code capabilities than any prior model,\" which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. \nOpenAI's release blog post shows an example where \"a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.\"\nThe outcome? \"GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.\"\nA new evaluation called ScreenSpot-Pro, which tests a model's ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.\nScience and Reliability\nOpenAI leaders also stressed the model's utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. \nAidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.\n\"They tested it by asking it to generate the most important unanswered questions about the immune system,\" Clark said. \"That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.\n\"Reliability was another key focus. Schwarzer claimed the new model \"hallucinates substantially less than GPT-5.1,\" noting that on a set of de-identified queries, \"responses contained errors 38% less often.\"\nThe 'Vibe' Shift\nInterestingly, OpenAI acknowledged that not every user might immediately prefer the new models. \nWhen asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that \"models change a little bit every time.\n\"Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,\" Schwarzer said. He also noted that for some enterprise customers who have \"really fine-tuned a prompt for a specific model,\" there might be \"small regressions,\" necessitating access to the older versions.\nSafety, 'Adult Mode,' and Future Roadmap\nAddressing safety concerns, Simo confirmed that the company is preparing to roll out an \"Adult Mode\" in the first quarter of next year, following the implementation of a new age prediction system.\n\"We're in the process of improving that,\" Simo said regarding the age prediction technology. \n\"We want to do that ahead of launching adult mode.\"Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename \"Project Garlic,\" targeting a flagship release in early 2026. \nWhile executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.\n\"If you look at historical trends, compute has increased about 3x every year for the last three years,\" she explained. \"Revenue has also increased at the same pace... creating this virtuous cycle.\"\nClark added that efficiency is improving rapidly: \"The model we're releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it\" compared to models from a year ago.\nGPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.",
    "publishedAt": "Thu, 11 Dec 2025 18:16:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, <a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>.</p><p>It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival <a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">Google’s Gemini 3 LLM seized the top spot</a> on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.</p><p>OpenAI describes GPT-5.2 as its &quot;most capable model series yet for professional knowledge work,&quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.</p><p>&quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &quot;We designed 5.2 to unlock even more economic value for people. It&#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&quot;</p><p>GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.</p><p>The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &quot;Reasoning token support,&quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &quot;o1&quot; series.</p><h3><b>The &#x27;Code Red&#x27; Reality Check</b></h3><p>The release arrives following<i> </i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\"><i>The Information</i>&#x27;s report</a> of an emergency &quot;Code Red&quot; directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the &quot;quality gap&quot; exposed by Gemini 3.<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i> The Verge</i></a> similarly reported on the timing of GPT-5.2&#x27;s release ahead of the official announcement. </p><p>During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.</p><p>&quot;It is important to note this has been in the works for many, many months,&quot; Simo told reporters. She clarified that while the &quot;Code Red&quot; helped focus the company, it wasn&#x27;t the sole driver of the timeline. </p><p>&quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&#x27;s not the reason it&#x27;s coming out this week in particular.&quot;</p><p>Max Schwarzer, lead of OpenAI&#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &quot;We&#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&quot;</p><p>A spokesperson from OpenAI further clarified that the &quot;Code Red&quot; call applied to ChatGPT as a product, not solely underlying model development or the release of new models.</p><h3><b>Under the Hood: Instant, Thinking, and Pro</b></h3><p>OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &quot;reasoning&quot; models with user demand for speed:</p><ul><li><p><b>GPT-5.2 Instant:</b> Optimized for speed and daily tasks like writing, translation, and information seeking.</p></li><li><p><b>GPT-5.2 Thinking:</b> Designed for &quot;complex, structured work&quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.</p></li><li><p><b>GPT-5.2 Pro:</b> The new heavyweight champion. OpenAI describes this as its &quot;smartest and most trustworthy option,&quot; delivering the highest accuracy for difficult questions where quality outweighs latency.</p></li></ul><p>For developers, the models are available immediately in the application programming interface (API) as <code>gpt-5.2</code>, <code>gpt-5.2-chat-latest</code> (Instant), and <code>gpt-5.2-pro</code>.</p><h3><b>The Numbers: Beating the Benchmarks</b></h3><p>The GPT-5.2 release includes leading metrics across most domains — specifically those that target the &quot;professional knowledge work&quot; gap where competitors have recently gained ground.</p><p>OpenAI highlighted a new benchmark called GDPval, which measures performance on &quot;well-specified knowledge work tasks&quot; across 44 occupations. </p><p>&quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&quot; Simo said.</p><p>In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. </p><p>He emphasized that this benchmark is &quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&quot;Other key benchmark results include:</p><ul><li><p><b>GPQA Diamond (Science):</b> GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).</p></li><li><p><b>FrontierMath:</b> On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.</p></li><li><p><b>ARC-AGI-1:</b> GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring <b>90.5%</b></p></li></ul><h3><b>The Price of Intelligence</b></h3><p>Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &quot;thinking&quot; mode. They&#x27;re also on the upper-end of API costs for the industry.  </p><ul><li><p><b>GPT-5.2 Thinking:</b> Priced at <b>$1.75</b> per 1 million input tokens and <b>$14</b> per 1 million output tokens.</p></li><li><p><b>GPT-5.2 Pro:</b> The costs jump significantly to <b>$21</b> per 1 million input tokens and <b>$168</b> per 1 million output tokens.</p></li></ul><p>GPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.</p><p>The high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.</p><p>OpenAI argues that despite the higher per-token cost, the model’s &quot;greater token efficiency&quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.</p><p>Here&#x27;s how it compares to the current API costs for other competing models across the LLM field:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1M)</b></p></td><td><p><b>Output (/1M)</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>Image Generation: Nothing New Yet...But &#x27;More to Come&#x27;</b></h3><p>During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&#x27;s Gemini 3 Image aka Nano Banana Pro. </p><p>Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&#x27;s integrated DALL-E 3 and gpt-4o native image generation models.</p><p>&quot;On image Gen, nothing to announce today, but more to come,&quot; Simo said. She acknowledged the popularity of the feature, adding, &quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&quot; </p><p>Aidan Clark, OpenAI&#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &quot;I can&#x27;t really speak to image Gen myself.&quot; </p><h3><b>The &#x27;Mega-Agent&#x27; Era</b></h3><p>Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &quot;long-running agents&quot; capable of executing multi-step workflows without human hand-holding.&quot;</p><p>Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&quot; Simo said. </p><p>She also noted that Notion reported the model &quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&quot;Schwarzer added that coding startups like Augment Code found the model &quot;delivered substantially stronger deep code capabilities than any prior model,&quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. </p><p>OpenAI&#x27;s release blog post shows an example where &quot;a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.&quot;</p><p>The outcome? &quot;GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.&quot;</p><p>A new evaluation called ScreenSpot-Pro, which tests a model&#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.</p><h3><b>Science and Reliability</b></h3><p>OpenAI leaders also stressed the model&#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. </p><p>Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.</p><p>&quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&quot; Clark said. &quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.</p><p>&quot;Reliability was another key focus. Schwarzer claimed the new model &quot;hallucinates substantially less than GPT-5.1,&quot; noting that on a set of de-identified queries, &quot;responses contained errors 38% less often.&quot;</p><h3><b>The &#x27;Vibe&#x27; Shift</b></h3><p>Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. </p><p>When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &quot;models change a little bit every time.</p><p>&quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&quot; Schwarzer said. He also noted that for some enterprise customers who have &quot;really fine-tuned a prompt for a specific model,&quot; there might be &quot;small regressions,&quot; necessitating access to the older versions.</p><h3><b>Safety, &#x27;Adult Mode,&#x27; and Future Roadmap</b></h3><p>Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &quot;Adult Mode&quot; in the first quarter of next year, following the implementation of a new age prediction system.</p><p>&quot;We&#x27;re in the process of improving that,&quot; Simo said regarding the age prediction technology. </p><p>&quot;We want to do that ahead of launching adult mode.&quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &quot;Project Garlic,&quot; targeting a flagship release in early 2026. </p><p>While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.</p><p>&quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&quot; she explained. &quot;Revenue has also increased at the same pace... creating this virtuous cycle.&quot;</p><p>Clark added that efficiency is improving rapidly: &quot;The model we&#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&quot; compared to models from a year ago.</p><p>GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.</p>",
    "titleJa": "OpenAIのGPT-5.2が登場：企業が知っておくべきこと",
    "summaryJa": "OpenAIがGPT-5.2を発表。推論、コーディング、エージェントワークフローが向上。3つのティアで提供され、API価格は高め。画像生成はまだ改善なし。",
    "explanationJa": "OpenAIの最新モデルGPT-5.2は、より高度な推論やコーディングが可能になり、ビジネスでの活用が期待されます。",
    "translationJa": "<p>噂は本当でした。OpenAIは木曜日、最新のフロンティア大規模言語モデル（LLM）ファミリーである<a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>を発表しました。</p><p>ライバルの<a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">GoogleのGemini 3 LLMが主要な第三者パフォーマンスリーダーボードと多くの重要なベンチマークで先月トップの座を奪った</a>ため、AIの先駆者である同社は激しいプレッシャーに直面しており、この発表はAIの先駆者である同社にとって重要な局面を迎えています。ただし、OpenAIの幹部は記者会見で、今回のリリース時期はGemini 3のリリースよりもずっと前から議論され、準備されていたことを強調しました。</p><p>OpenAIはGPT-5.2を「プロフェッショナルな知識労働向けのこれまでで最も有能なモデルシリーズ」と説明し、推論、コーディング、エージェントワークフローの大幅な改善により、パフォーマンスの王座を取り戻すことを目指しています。</p><p>OpenAIのアプリケーション担当CEOであるフィッジ・シモ氏は、今日の記者会見で「これは当社の最も先進的なフロンティアモデルであり、プロフェッショナル用途において市場で最も強力なモデルです」と述べました。「5.2は、人々にとってより多くの経済的価値を引き出すように設計されています。スプレッドシートの作成、プレゼンテーションの作成、コードの記述、画像の認識、長いコンテキストの理解、ツールの使用、および複雑な複数ステップのプロジェクトの処理がより得意です。」</p><p>GPT-5.2は、400,000トークンという膨大なコンテキストウィンドウを備えており、一度に数百のドキュメントまたは大規模なコードリポジトリを取り込むことができます。また、最大128,000トークンの出力制限があり、大規模なレポートや完全なアプリケーションを一度に生成できます。</p><p>このモデルは、2025年8月31日の知識カットオフも備えており、比較的最近の世界的な出来事や技術文書に対応しています。また、「推論トークンのサポート」が明示的に含まれており、基盤となるアーキテクチャが「o1」シリーズで普及した連鎖的思考処理を使用していることを確認しています。</p><h3><b>「コードレッド」の現実</b></h3><p>このリリースは、<i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\">The Informationのレポート</a></i>に続き、Gemini 3によって露呈した「品質のギャップ」を受けてリソースを動員するために設計されたと伝えられる、ChatGPTを改善するためのCEOのサム・アルトマン氏からの緊急「コードレッド」指令の後に発表されました。<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i>The Verge</i></a>も同様に、公式発表に先立ってGPT-5.2のリリース時期について報じました。</p><p>記者会見中、OpenAIの幹部は指令を認めましたが、このモデルがGoogleに対抗するためだけに急いで作成されたという見方を否定しました。</p><p>シモ氏は記者団に「これは数か月前から準備されていたことに注意することが重要です」と語りました。彼女は、「コードレッド」が会社を集中させるのに役立ったが、それがタイムラインの唯一の推進力ではなかったことを明らかにしました。</p><p>「このコードレッドを発表したのは、特定分野にリソースを投入したいという意思を会社に伝えるためですが、それが今週特にリリースされる理由ではありません。」</p><p>OpenAIのポストトレーニングチームのリーダーであるマックス・シュワルツァー氏は、パニックローンチという考えを払拭するためにこの感情に同意しました。「このリリースはかなり前から計画していました... 特定の週については数か月前に話し合いました。」</p><p>OpenAIの広報担当者はさらに、「コードレッド」の呼びかけは、新しいモデルの開発やリリースだけでなく、製品としてのChatGPTに適用されることを明確にしました。</p><h3><b>内部構造：Instant、Thinking、およびPro</b></h3><p>OpenAIは、ChatGPT内でGPT-5.2リリースを3つの異なるティアに分割しています。これは、「推論」モデルの膨大な計算コストと、速度に対するユーザーの要求とのバランスを取るように設計された戦略であると考えられます。</p><ul><li><p><b>GPT-5.2 Instant：</b>執筆、翻訳、情報検索などの速度と日常タスクに最適化されています。</p></li><li><p><b>GPT-5.2 Thinking：</b>「複雑で構造化された作業」および長期実行エージェント向けに設計されており、より深い推論チェーンを活用してコーディング、数学、および複数ステップのプロジェクトを処理します。</p></li><li><p><b>GPT-5.2 Pro：</b>新しいヘビー級チャンピオン。OpenAIはこれを「最もスマートで最も信頼できるオプション」と説明しており、品質が遅延よりも重要な難しい質問に対して最高の精度を提供します。</p></li></ul><p>開発者向けに、モデルはアプリケーションプログラミングインターフェース（API）で<code>gpt-5.2</code>、<code>gpt-5.2-chat-latest</code>（Instant）、および<code>gpt-5.2-pro</code>としてすぐに利用できます。</p><h3><b>数値：ベンチマークを打ち負かす</b></h3><p>GPT-5.2リリースには、ほとんどのドメインで主要なメトリックが含まれています。特に、競合他社が最近勢いを増している「プロフェッショナルな知識労働」のギャップをターゲットにしています。</p><p>OpenAIは、44の職業にわたる「明確に指定された知識労働タスク」のパフォーマンスを測定するGDPvalと呼ばれる新しいベンチマークを強調しました。</p><p>シモ氏は、「GPT-5.2 Thinkingは現在、そのベンチマークで最先端技術となっており... スプレッドシート、プレゼンテーション、ドキュメントの作成など、専門家の人間の審査員によると、明確に指定されたプロフェッショナルタスクの70.9％でトップ業界の専門家を上回るか、タイです」と述べました。</p><p>コーディングの重要な分野で、OpenAIは決定的なリードを主張しています。シュワルツァー氏は、現実世界のソフトウェアエンジニアリングの厳格な評価であるSWE-bench Proで、GPT-5.2 Thinkingが55.6％の新しい最先端スコアを設定していると述べました。</p><p>彼は、このベンチマークが「SWE-bench Verifiedなどの以前のベンチマークよりも汚染耐性があり、挑戦的で、多様で、業界に関連性がある」ことを強調しました。その他の主要なベンチマーク結果は次のとおりです。</p><ul><li><p><b>GPQA Diamond（科学）：</b>GPT-5.2 Proは93.2％のスコアを獲得し、GPT-5.2 Thinking（92.4％）をわずかに上回り、GPT-5.1 Thinking（88.1％）を上回りました。</p></li><li><p><b>FrontierMath：</b>ティア1〜3の問題では、GPT-5.2 Thinkingは40.3％を解決しました。これは、その前任者が達成した31.0％から大幅な増加です。</p></li><li><p><b>ARC-AGI-1：</b>GPT-5.2 Proは、この一般的な推論ベンチマークで90％のしきい値を超えた最初のモデルであると報告されており、<b>90.5％</b>のスコアを獲得しています。</p></li></ul><h3><b>インテリジェンスの価格</b></h3><p>パフォーマンスにはプレミアムが付きます。ChatGPTのサブスクリプション価格は今のところ変更されていませんが、新しいフラッグシップモデルのAPIコストは、以前の世代と比較して高額であり、「思考」モードの高い計算需要を反映しています。また、業界のAPIコストの上限に達しています。</p><ul><li><p><b>GPT-5.2 Thinking：</b>100万入力トークンあたり<b>$1.75</b>、100万出力トークンあたり<b>$14</b>で価格設定されています。</p></li><li><p><b>GPT-5.2 Pro：</b>コストは大幅に上昇し、100万入力トークンあたり<b>$21</b>、100万出力トークンあたり<b>$168</b>になります。</p></li></ul><p>GPT-5.2 Thinkingは、APIで標準のGPT-5.1（$1.25 / $10）よりも40％高い価格設定されており、OpenAIは、新しい推論機能を単なる効率の向上ではなく、具体的な付加価値と見なしていることを示しています。</p><p>ハイエンドのGPT-5.2 Proも同じパターンに従い、以前のGPT-5 Pro（$15 / $120）よりも40％高価です。高価ですが、それでもOpenAIの最も専門的な推論モデルであるo1-proを下回っており、これは100万入力トークンあたり150ドル、100万出力トークンあたり600ドルという驚異的な価格でメニューで最も高価な製品のままです。</p><p>OpenAIは、トークンあたりのコストは高いものの、モデルの「トークン効率の向上」と、より少ないターンでタスクを解決できる能力により、高価値のエンタープライズワークフローにとって経済的に実行可能であると主張しています。</p><p>LLM分野の他の競合モデルの現在のAPIコストとの比較は次のとおりです。</p><table><tbody><tr><td><p><b>モデル</b></p></td><td><p><b>入力（/ 1M）</b></p></td><td><p><b>出力（/ 1M）</b></p></td><td><p><b>合計コスト</b></p></td><td><p><b>ソース</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast（推論）</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast（非推論）</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat（V3.2-Exp）</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner（V3.2-Exp）</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro（≤200K）</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro（> 200K）</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>画像生成：まだ新しいものはありません...しかし「今後さらに増える」</b></h3><p>記者会見中、VentureBeatはOpenAIの参加者に、新しいリリースにGoogleのGemini 3 Image（別名Nano Banana Pro）のような最近の競合他社のローンチにおける同様の機能に対する興奮に言及して、画像生成機能の向上が含まれているかどうかを尋ねました。</p><p>テキストと情報が豊富なグラフィックおよび画像編集機能を再現しようとしている人々にとって残念なことに、OpenAIの幹部は、GPT-5.2には、以前のGPT-5.1およびOpenAIの統合されたDALL-E 3およびgpt-4oネイティブ画像生成モデルと比較して、現在の画像の改善はないことを明らかにしました。</p><p>シモ氏は、「画像生成については、今日は何も発表することはありませんが、今後さらに増える予定です」と述べました。彼女は、この機能の人気を認め、「これは人々が愛する非常に重要なユースケースであり、当社が市場に導入したものであり、今後さらに増えることは間違いありません」と付け加えました。</p><p>OpenAIのトレーニングリーダーであるエイダン・クラーク氏も、視覚生成の具体的な内容についてコメントを控え、「画像生成についてはあまり話せません」と述べています。</p><h3><b>「メガエージェント」時代</b></h3><p>OpenAIは、生のスコアを超えて、GPT-5.2を人間の手を介さずに複数ステップのワークフローを実行できる、新世代の「長期実行エージェント」のエンジンとして位置付けています。</p><p>シモ氏は、「Boxは、5.2が長くて複雑なドキュメントから約40％高速に情報を抽出できることを発見し、ライフサイエンスと医療における推論の精度も40％向上しました」と述べています。</p><p>彼女はまた、Notionがモデルは「すべての側面で5.1を上回り... そして、それは実際の知識労働を定義する、本当に曖昧で、より長い立ち上がりタスクに優れています」と報告していると述べました。シュワルツァー氏は、Augment Codeのようなコーディングスタートアップは、モデルが「以前のどのモデルよりも大幅に強力なディープコード機能を提供した」ことを発見したため、新しいコードレビューエージェントを強化するために選択されたと付け加えました。視覚機能もアップグレードされています。</p><p>OpenAIのリリースブログ投稿は、「旅行者がフライトの遅延、乗り継ぎの遅延、ニューヨークでの一泊、および医療上の座席要件を報告する」例を示しています。</p><p>結果？「GPT‑5.2は、予約の変更、特別な支援座席、および補償というタスクチェーン全体を管理し、GPT‑5.1よりも完全な結果を提供します。」</p><p>GUIスクリーンショットを理解するモデルの能力をテストするScreenSpot-Proと呼ばれる新しい評価では、GPT-5.2 Thinkingが86.3％の精度を達成し、GPT-5.1のわずか64.2％と比較されます。</p><h3><b>科学と信頼性</b></h3><p>OpenAIのリーダーはまた、単純なチャットボットから研究助手への会話を移行しようと試み、科学研究におけるモデルの有用性を強調しました。</p><p>トレーニングチームのリーダーであるエイダン・クラーク氏は、モデルをテストした免疫学の上級研究者の例を共有しました。</p><p>クラーク氏は、「彼らは、免疫系に関する最も重要な未解決の質問を生成するようにモデルに依頼することでそれをテストしました」と述べました。「その免疫学の研究者は、GPT-5.2が、以前のどのプロモデルと比較しても、より鋭い質問と、それらの質問が重要な理由のより強力な説明を生み出したと報告しました。</p><p>「信頼性ももう1つの重要な焦点でした。シュワルツァー氏は、新しいモデルは「GPT-5.1よりも大幅に幻覚が少ない」と主張し、一連の匿名化されたクエリでは、「応答にエラーが含まれることは38％少なかった」と指摘しました。</p><h3><b>「雰囲気」の変化</b></h3><p>興味深いことに、OpenAIは、すべてのユーザーがすぐに新しいモデルを好むとは限らないことを認めました。</p><p>GPT-5.1のようなレガシーモデルが利用可能なままである理由を尋ねられたとき、シュワルツァー氏は「モデルは毎回少し変化します」と認めました。</p><p>シュワルツァー氏は、「最新のモデルが全体的にはるかに優れていると考えていますが、以前のモデルの雰囲気を好むユーザーもいるかもしれません」と述べています。また、「特定のモデルのプロンプトを非常に微調整した」一部のエンタープライズ顧客にとっては、「小さな後退」があり、古いバージョンへのアクセスが必要になる可能性があると指摘しました。</p><h3><b>安全性、「アダルトモード」、および将来のロードマップ</b></h3><p>安全性の懸念に対処するために、シモ氏は、同社が新しい年齢予測システムの実装に続いて、来年の第1四半期に「アダルトモード」を展開する準備をしていることを確認しました。</p><p>シモ氏は、年齢予測技術に関して「改善のプロセスを進めています」と述べています。</p><p>「アダルトモードを立ち上げる前にそれを行いたいと考えています。」さらに先を見据えて、業界レポートは、OpenAIがコードネーム「Project Garlic」の下で、より根本的なアーキテクチャの変更に取り組んでおり、2026年初頭にフラッグシップリリースを予定していることを示唆しています。</p><p>幹部は記者会見中に特定の将来のロードマップについてコメントしませんでしたが、シモ氏は現在の軌道の経済学について楽観的な見方を維持しました。</p><p>彼女は、「過去の傾向を見ると、過去3年間でコンピューティングは約3倍に増加しました」と説明しました。「収益も同じペースで増加しており... この好循環を生み出しています。」</p><p>クラーク氏は、効率が急速に向上していると付け加えました。「今日リリースしているモデルは、1年前のモデルと比較して、ほぼ400分の1のコストとコンピューティングで[ARC-AGI]でさらに優れたスコアを達成しています。」</p><p>GPT-5.2 Instant、Thinking、およびProは、今日から有料ユーザー（Plus、Pro、Team、およびEnterprise）にChatGPTで展開を開始します。同社は、安定性を維持するために展開は段階的になることに注意しています。</p>",
    "insightJa": "GPT-5.2の登場で、ビジネスにおけるAIの活用がさらに進むと考えられます。特に、高度な推論能力を活かした業務効率化や、顧客対応の自動化などが期待されます。一方で、APIの利用コストが高いため、費用対効果を慎重に検討する必要があります。",
    "recommendedBooks": [
      "大規模言語モデル",
      "AIによる業務改革",
      "自然言語処理 実践"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "LLM",
      "AI",
      "人工知能"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?GPT-5.2%2COpenAI&sig=742"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "title": "Stressed rats keep returning to cannabis and scientists know why",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "summary": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "publishedAt": "Thu, 11 Dec 2025 12:15:09 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "titleJa": "ストレスを感じやすいラットはカンナビスに繰り返し戻る：科学者がその理由を解明",
    "summaryJa": "ストレスが高いラットはカンナビスを自発的に摂取する傾向が強く、行動実験から、ストレスホルモン値、認知柔軟性の低さ、エンドカンナビノイドレベルの低さが関連することが判明。薬物乱用リスクの早期指標を示唆。",
    "explanationJa": "ストレスを感じやすいラットはカンナビスを使用しやすいことが研究で明らかになり、薬物依存の早期発見につながるかもしれません。",
    "translationJa": "生まれつきストレスレベルの高いラットは、カンナビスを利用できる環境に置かれた場合、自発的に摂取する傾向がはるかに高いことがわかりました。行動試験の結果、ベースラインのストレスホルモンがカンナビス探索行動の最も強力な予測因子であることが示されました。認知柔軟性の低下と低いエンドカンナビノイドレベルも、使用量の増加に寄与しました。これらの結果は、薬物乱用に対する脆弱性の可能性を示す早期指標を示唆しています。",
    "insightJa": "この研究は、ストレス管理の重要性を示唆しており、企業における従業員のメンタルヘルスケアの充実や、個人レベルでのストレス軽減策の実施が、薬物依存予防に繋がる可能性があります。ストレス耐性を高める製品やサービスの開発にもつながるかもしれません。",
    "recommendedBooks": [
      "ストレスマネジメント",
      "薬物依存 メカニズム",
      "脳科学 ストレス"
    ],
    "tags": [
      "Cannabis",
      "Stress",
      "Drug misuse",
      "ラット",
      "エンドカンナビノイド"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Cannabis%2CStress&sig=60"
  },
  {
    "id": "7nAN91YGj5oC8TMc2YBtjK",
    "title": "Marble enters the race to bring AI to tax work, armed with $9 million and a free research tool",
    "source": "rss",
    "url": "https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a",
    "summary": "Marble, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.\nThe round, led by Susa Ventures with participation from MXV Capital and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.\n\"When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,\" said Bhavin Shah, Marble's chief executive officer, in an exclusive interview with VentureBeat. \"Accounting generates $250 billion in fee-based billing in the US every year. There's a tremendous opportunity to increase efficiency and improve margins for accounting firms.\"\nThe company has launched a free AI-powered tax research tool on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.\nMarble's backers share Shah's conviction about the market. \"Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,\" Chad Byers, general partner at Susa Ventures, told VentureBeat. \"We've known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.\"\nThe accounting industry lost 340,000 workers in four years — and replacements aren't coming\nMarble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.\nThe accounting profession has shed roughly 340,000 workers since 2019, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to AICPA data, and 2022 saw the lowest number of exam takers in 17 years.\nThe exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately 75% of all licensed CPAs reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.\n“Fewer CPAs are getting certified year over year,\" Shah said. \"The industry is compressing at the same time that there's more work to be done and the tax code is getting more complicated.\"\nThe National Pipeline Advisory Group, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the 150-hour education requirement for CPA licensure as a significant barrier to entry. A separate survey by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.\nRecent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.\nWhy AI transformed law and software development but left accounting behind\nDespite the profession's challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. Harvey and Legora have raised hundreds of millions to bring AI to legal work. Cursor and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.\nGeordie Konrad, Marble's executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI's capabilities.\n“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,\" Konrad said. \" That requires a bit more of a two-step analysis to see why it's a big opportunity.\"\nThe technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.\n\"If you want to put AI through its paces and ask how far it's come in replicating cognitive functions, this is an unbelievable playground to work in,\" Konrad said.\nA dramatic shift: AI adoption among tax and finance teams doubles in one year\nRecent data suggests the accounting profession's stance toward AI is shifting rapidly.\nA 2025 survey from Hanover Research and Avalara found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from Thomson Reuters Institute found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.\nLarge accounting firms have invested heavily in AI infrastructure. Deloitte has developed generative AI capabilities within its audit platform. BDO announced a $1B investment in AI over the next five years. EY launched an AI platform combining technology with strategy, transactions, and tax services. PwC estimates a complete AI-driven audit solution will launch by 2026.\nBut adoption at smaller firms remains uneven. According to Thomson Reuters research, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.\nMarble's founders believe the hesitance stems not from technophobia but from a lack of compelling options.\n“Firms want to embrace AI,\" Shah said. “They just haven't seen great software and tooling made for them. That's part of the opportunity — to work with them and build something they're excited to use on a day-to-day basis.”\nCan artificial intelligence rescue accounting's billable-hour business model?\nAI's arrival in accounting raises questions about the profession's billing structure.\nAccounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?\nMarble's founders argue the opposite. The chronic staffing shortage has already constrained firms' ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.\n\"Everyone in the industry agrees that an enormous amount of advisory work simply isn't getting done,\" Konrad said. \"Customers want it. Firms want to do it because it's high-margin, great work. But nobody gets to it.\"\nThe 2025 AICPA National Management of an Accounting Practice Survey supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.\nThe survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.\nAccountants won't adopt AI tools they can't trust with sensitive client data\nFor AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.\nAccording to Avalara's survey, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.\nMarble has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.\n\"Security is at the core of what we are building,\" Shah said. \"Every employee knows that security is critical. It's a part of our onboarding and something that we consider in everything we do.\"\nFrom number crunchers to strategic advisors: How AI could reshape accounting careers\nMarble's founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. \nThey draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.\n\"If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you're a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that's just a lot more fun to operate in,\" Konrad said.\nThe shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.\n\"Not only does the work become more enjoyable because of what you can focus on, but that's also what your clients are going to value more from you,\" Shah said.\nThe competitive landscape: Marble faces well-funded rivals and legacy giants\nMarble enters a market with formidable incumbents and well-funded competitors. BlueJ, a global tax research platform, has raised over $100 million. Thomson Reuters, CCH, and Intuit have deep customer relationships built over decades.\nBut the founders see opportunity in the transition moment.\n\"AI has changed what’s possible in the industry,\" Shah said. \"We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?\"\"\nThe decision to offer a free research tool reflects Marble's go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.\n\"It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don't know how to integrate it into their workflow,\" Shah said.\nThe $250 billion question: Can a startup transform how America does its taxes?\nMarble's roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.\nThe founders frame success not in terms of disruption but rebalancing. Today's tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble's bet is that AI can flip that equation.\n\"Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,\" Konrad said. \"How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?\"\nWhether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.\nBut the founders are betting that the industry's demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.\n\"AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,\" Shah said.\nThe accounting profession, it seems, is about to find out which side of that equation it lands on.",
    "publishedAt": "Thu, 11 Dec 2025 14:00:00 GMT",
    "author": "michael.nunez@venturebeat.com (Michael Nuñez)",
    "category": "AI",
    "originalContent": "<p><a href=\"http://marble.ai/\">Marble</a>, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.</p><p>The round, led by <a href=\"https://www.susaventures.com/\">Susa Ventures</a> with participation from <a href=\"https://mxv.vc/\">MXV Capital</a> and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.</p><p>&quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&quot; said Bhavin Shah, Marble&#x27;s chief executive officer, in an exclusive interview with VentureBeat. &quot;Accounting generates $250 billion in fee-based billing in the US every year. There&#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&quot;</p><p>The company has launched a <a href=\"https://marble.ai/\">free AI-powered tax research tool</a> on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.</p><p>Marble&#x27;s backers share Shah&#x27;s conviction about the market. &quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &quot;We&#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&quot;</p><h2><b>The accounting industry lost 340,000 workers in four years — and replacements aren&#x27;t coming</b></h2><p>Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.</p><p>The accounting profession has <a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">shed roughly 340,000 workers since 2019</a>, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to <a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPA data</a>, and 2022 saw the lowest number of exam takers in 17 years.</p><p>The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately <a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">75% of all licensed CPAs</a> reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.</p><p>“Fewer CPAs are getting certified year over year,&quot; Shah said. &quot;The industry is compressing at the same time that there&#x27;s more work to be done and the tax code is getting more complicated.&quot;</p><p>The <a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the <a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150-hour education requirement</a> for CPA licensure as a significant barrier to entry. A separate <a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">survey</a> by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.</p><p>Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.</p><h2><b>Why AI transformed law and software development but left accounting behind</b></h2><p>Despite the profession&#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. <a href=\"https://www.harvey.ai/\">Harvey</a> and <a href=\"https://legora.com/\">Legora</a> have raised hundreds of millions to bring AI to legal work. <a href=\"https://cursor.com/agents\">Cursor</a> and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.</p><p>Geordie Konrad, Marble&#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&#x27;s capabilities.</p><p>“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&quot; Konrad said. &quot; That requires a bit more of a two-step analysis to see why it&#x27;s a big opportunity.&quot;</p><p>The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.</p><p>&quot;If you want to put AI through its paces and ask how far it&#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&quot; Konrad said.</p><h2><b>A dramatic shift: AI adoption among tax and finance teams doubles in one year</b></h2><p>Recent data suggests the accounting profession&#x27;s stance toward AI is shifting rapidly.</p><p>A 2025 survey from <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a> found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from <a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a> found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.</p><p>Large accounting firms have invested heavily in AI infrastructure. <a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a> has developed generative AI capabilities within its audit platform. <a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a> announced a $1B investment in AI over the next five years. <a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a> launched an AI platform combining technology with strategy, transactions, and tax services. <a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a> estimates a complete AI-driven audit solution will launch by 2026.</p><p>But adoption at smaller firms remains uneven. According to <a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reuters research</a>, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.</p><p>Marble&#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.</p><p>“Firms want to embrace AI,&quot; Shah said. “They just haven&#x27;t seen great software and tooling made for them. That&#x27;s part of the opportunity — to work with them and build something they&#x27;re excited to use on a day-to-day basis.”</p><h2><b>Can artificial intelligence rescue accounting&#x27;s billable-hour business model?</b></h2><p>AI&#x27;s arrival in accounting raises questions about the profession&#x27;s billing structure.</p><p>Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?</p><p>Marble&#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.</p><p>&quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&#x27;t getting done,&quot; Konrad said. &quot;Customers want it. Firms want to do it because it&#x27;s high-margin, great work. But nobody gets to it.&quot;</p><p>The <a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a> supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.</p><p>The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.</p><h2><b>Accountants won&#x27;t adopt AI tools they can&#x27;t trust with sensitive client data</b></h2><p>For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.</p><p>According to <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalara&#x27;s survey</a>, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.</p><p><a href=\"https://marble.ai/\">Marble</a> has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.</p><p>&quot;Security is at the core of what we are building,&quot; Shah said. &quot;Every employee knows that security is critical. It&#x27;s a part of our onboarding and something that we consider in everything we do.&quot;</p><h2><b>From number crunchers to strategic advisors: How AI could reshape accounting careers</b></h2><p>Marble&#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. </p><p>They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.</p><p>&quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&#x27;s just a lot more fun to operate in,&quot; Konrad said.</p><p>The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.</p><p>&quot;Not only does the work become more enjoyable because of what you can focus on, but that&#x27;s also what your clients are going to value more from you,&quot; Shah said.</p><h2><b>The competitive landscape: Marble faces well-funded rivals and legacy giants</b></h2><p><b></b><a href=\"http://marble.ai/\">Marble</a> enters a market with formidable incumbents and well-funded competitors. <a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>, a global tax research platform, has raised over $100 million. <a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>, <a href=\"https://www.cch.com/\">CCH</a>, and <a href=\"https://www.intuit.com/\">Intuit</a> have deep customer relationships built over decades.</p><p>But the founders see opportunity in the transition moment.</p><p>&quot;AI has changed what’s possible in the industry,&quot; Shah said. &quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&quot;&quot;</p><p>The decision to offer a free research tool reflects Marble&#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.</p><p>&quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&#x27;t know how to integrate it into their workflow,&quot; Shah said.</p><h2><b>The $250 billion question: Can a startup transform how America does its taxes?</b></h2><p>Marble&#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.</p><p>The founders frame success not in terms of disruption but rebalancing. Today&#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&#x27;s bet is that AI can flip that equation.</p><p>&quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&quot; Konrad said. &quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&quot;</p><p>Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.</p><p>But the founders are betting that the industry&#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.</p><p>&quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&quot; Shah said.</p><p>The accounting profession, it seems, is about to find out which side of that equation it lands on.</p>",
    "titleJa": "Marble、税務業務へのAI導入競争に参入、900万ドルの資金調達と無料の研究ツールを武器に",
    "summaryJa": "税務専門家向けのAIエージェントを開発するMarbleが900万ドルの資金を調達。会計業界の人手不足と規制の複雑化に対応。AIを活用した税務研究ツールも提供開始。",
    "explanationJa": "Marble社は、AIを使って税務業務を効率化するサービスを提供し、会計業界の課題解決を目指しています。",
    "translationJa": "<p><a href=\"http://marble.ai/\">Marble</a>は、税務専門家向けの人工知能エージェントを構築するスタートアップであり、会計業界が深刻化する人手不足と増大する規制の複雑さに苦慮する中、900万ドルのシード資金を調達しました。</p><p>Susa Venturesが主導し、MXV CapitalとKonrad Capitalが参加したこのラウンドにより、Marbleは、法律やソフトウェア開発などの他の知識産業に比べてAIの導入が大幅に遅れている市場で競争することができます。</p><p>Marbleの最高経営責任者であるBhavin Shahは、VentureBeatとの独占インタビューで、&quot;経済を検討し、AIがビジネスの運営方法をどのように変革するかを自問したとき、時間制料金ベースのサービスモデルを持つ知識産業、特に企業に焦点を当てました。&quot;と述べています。&quot;会計は米国で年間2,500億ドルの料金ベースの請求を生み出しています。会計事務所の効率を高め、利益率を向上させる絶好の機会があります。&quot;</p><p>同社は、ウェブサイトで<a href=\"https://marble.ai/\">無料のAI搭載税務研究ツール</a>を立ち上げました。これは、複雑な政府の税務データを、専門家がアクセス可能な、引用で裏付けられた回答に変換するものです。Marbleは、コンプライアンスシナリオを分析し、最終的には税務申告ワークフローの一部を自動化できるAIエージェントに拡張する予定です。</p><p>Marbleの出資者は、Shahの市場に対する確信を共有しています。Susa VenturesのジェネラルパートナーであるChad ByersはVentureBeatに、&quot;Marbleは会計システムを根本から見直しています。会計は、専門サービスにおいて最大規模であり、最も見過ごされている市場の一つです&quot;と語っています。&quot;私たちは、BhavinがSusaのポートフォリオのエグゼクティブであった頃から彼を知っており、彼がいかに鋭敏で実行力に優れているかを直接見てきました。彼とGeordieは、業務の深さと製品に対する直感を完璧に組み合わせ、変化が長らく求められている分野に貢献しています。そして、彼らは私たちと同じように大きな機会を見出しています。&quot;</p><h2><b>会計業界は4年間で34万人の労働者を失い、補充は進んでいない</b></h2><p>Marbleは、専門会計の経済を根本的に変えた構造的な力によって形作られた市場に参入します。</p><p>会計業界は<a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">2019年以来、約34万人の労働者を削減</a>しており、これは17％の減少であり、企業はクライアントの要求に応えるために奔走しています。公認会計士試験の初回受験者は、<a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPAのデータ</a>によると、2016年から2021年の間に33％減少し、2022年には過去17年間で最も少ない受験者数となりました。</p><p>この流出は、ベビーブーマー世代が一斉に退職することによって起こっています。米国公認会計士協会は、<a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">すべてのライセンスを持つCPAの約75％</a>が2019年までに定年退職年齢に達したと推定しており、業界が対応に苦労している人口統計上の崖を作り出しています。</p><p>&quot;毎年認定されるCPAの数は減っています&quot;とShahは述べています。&quot;業界は縮小しており、同時に、より多くの仕事が行われる必要があり、税法はより複雑になっています。&quot;</p><p>AICPAが2023年7月に設立したマルチステークホルダー組織である<a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>は、CPAライセンスの<a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150時間の教育要件</a>が参入に対する大きな障壁であると特定する報告書を発表しました。監査品質センターによる別の<a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">調査</a>では、会計を専攻しないことを選択したビジネス専攻の57％が、追加の単位時間を抑止力として挙げています。</p><p>最近の法改正は、その緊急性を反映しています。オハイオ州は現在、150時間要件の代替手段を提供しており、州が登録者数の減少を逆転させる可能性のある経路を試す意思があることを示しています。</p><h2><b>なぜAIは法律とソフトウェア開発を変革したが、会計を置き去りにしたのか</b></h2><p>業界の課題にもかかわらず、会計におけるAIの導入は、隣接する知識産業よりも遅れています。<a href=\"https://www.harvey.ai/\">Harvey</a>と<a href=\"https://legora.com/\">Legora</a>は、AIを法律業務に導入するために数億ドルを調達しました。<a href=\"https://cursor.com/agents\">Cursor</a>やその他のコーディングアシスタントは、ソフトウェア開発を変革しました。対照的に、会計は依然としてレガシーな研究プラットフォームと手作業に大きく依存しています。</p><p>Marbleのエグゼクティブチェアマンであり、レストランソフトウェア会社TouchBistroの共同創設者であるGeordie Konradは、そのギャップの原因を、人々がAIの能力をどのように概念化するかに帰しています。</p><p>&quot;LLMがソフトウェア開発者向けのコードを操作したり、弁護士向けの言葉を操作したりすることで、意味のある仕事ができることは、多くの人にとって明らかでした。会計業界では、LLMは推論エージェントとして使用されるでしょう&quot;とKonradは述べています。&quot;それが大きな機会である理由を理解するには、もう少し2段階の分析が必要です。&quot;</p><p>技術的な課題は相当なものです。税法は、人間が作成した最も複雑で相互接続された情報システムの1つを形成しています。それは、頻繁に重複または矛盾する、数万もの相互に関連する規則、ガイダンス文書、および管轄区域固有の要件で構成されています。</p><p>&quot;AIを試して、認知機能を再現する上でどこまで進んだかを知りたいのであれば、これは働く上で信じられないほどの遊び場です&quot;とKonradは述べています。</p><h2><b>劇的な変化：税務および財務チームにおけるAIの導入が1年で倍増</b></h2><p>最近のデータは、会計業界のAIに対する姿勢が急速に変化していることを示唆しています。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a>による2025年の調査では、財務および税務チームの84％が現在、業務でAIを多用しており、2024年の47％から増加しています。<a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a>による2025 Generative AI in Professional Services Reportでは、税務事務所の21％がすでに生成AIテクノロジーを使用しており、53％が導入を計画しているか、積極的に検討しています。</p><p>大手会計事務所は、AIインフラストラクチャに多額の投資を行っています。<a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a>は、監査プラットフォーム内で生成AI機能を開発しました。<a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a>は、今後5年間でAIに10億ドルを投資すると発表しました。<a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a>は、テクノロジーと戦略、トランザクション、税務サービスを組み合わせたAIプラットフォームを立ち上げました。<a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a>は、完全なAI駆動型監査ソリューションが2026年までにローンチされると予測しています。</p><p>しかし、中小企業での導入はまだら模様です。<a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reutersの調査</a>によると、生成AIを使用する税務事務所の回答者の52％は、業界固有のソリューションではなく、ChatGPTのようなオープンソースツールに依存しています。これは、目的に合わせた代替手段が登場するにつれて変化する可能性があります。</p><p>Marbleの創設者たちは、ためらいはテクノロジー恐怖症ではなく、魅力的な選択肢の欠如から生じていると考えています。</p><p>&quot;企業はAIを受け入れたいと思っています&quot;とShahは述べています。&quot;彼らは自分たちのために作られた素晴らしいソフトウェアやツールを見ていません。それこそが機会の一部です。彼らと協力し、彼らが日常的に使用することに興奮するようなものを作り上げることです。&quot;</p><h2><b>人工知能は会計の請求時間ビジネスモデルを救うことができるのか</b></h2><p>会計へのAIの登場は、業界の請求構造について疑問を投げかけています。</p><p>会計事務所は伝統的に、スタッフの時間に対してクライアントに請求することで利益を生み出してきました。多くの場合、従業員の報酬コストの数倍の金額で請求します。コンプライアンス業務を行うジュニアアソシエイトは、重要な収入源となります。AIがその業務を自動化できる場合、企業が依存しているビジネスモデルを弱体化させるのでしょうか。</p><p>Marbleの創設者たちは、その逆を主張しています。慢性の人手不足は、企業が利用可能な収入を獲得する能力をすでに制限しています。顧問業務やコンサルティング業務（クライアントが積極的に望んでいる、より利益率の高いサービス）は、実務者がコンプライアンス業務に埋もれているため、行われていません。</p><p>&quot;業界の誰もが、莫大な量の顧問業務が単に行われていないことに同意しています&quot;とKonradは述べています。&quot;顧客はそれを望んでいます。企業はそれが高利益で素晴らしい仕事なので、それをやりたいと思っています。しかし、誰もそれに手を付けることができません。&quot;</p><p><a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a>は、この見解を裏付けています。企業は、前年比で顧客からの純手数料が中央値で6.7％増加したと報告しており、監査、保証、税務サービス、および顧客会計顧問の成長が見られました。パートナー1人当たりの純残余は、2022会計年度から2024会計年度にかけて11.9％増加し、252,663ドルに達しました。</p><p>この調査では、AI導入への関心も高まっていることがわかりましたが、ほとんどの企業はまだ正式な予算を割り当てたり、構造化されたトレーニングプログラムを開発したりしていません。調査によると、継続的な導入はサービスの拡大と継続的な成長の促進に役立つ可能性があります。</p><h2><b>会計士は機密性の高いクライアントデータを信頼できないAIツールを採用しない</b></h2><p>AIが会計で成功するためには、データセキュリティの高い基準をクリアする必要があります。会計事務所は、経済において最も機密性の高い財務情報の一部を扱っています。実務者は、コンプライアンスまたは機密保持のリスクを生み出すツールを採用することはできません。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalaraの調査</a>によると、回答者の63％が、税務および財務機能の自動化に対する最大の障壁として、データセキュリティとプライバシーの懸念を挙げています。この懸念は、最初の選択から実装、継続的な使用まで、導入ライフサイクル全体にわたって持続します。</p><p><a href=\"https://marble.ai/\">Marble</a>は、セキュリティを基本的な優先事項としてきました。同社は、製品をリリースする前にソフトウェアコンプライアンス認証を取得し、データプライバシーが初日から運用文化に組み込まれていることを主張しています。</p><p>&quot;セキュリティは、私たちが構築しているものの核心です&quot;とShahは述べています。&quot;すべての従業員は、セキュリティが重要であることを知っています。それは私たちのオンボーディングの一部であり、私たちがすることすべてにおいて考慮することです。&quot;</p><h2><b>数字の処理から戦略的アドバイザーへ：AIは会計士のキャリアをどのように再構築できるか</b></h2><p>Marbleの創設者たちは、AIが会計の仕事を奪うだけだという見方を否定します。彼らは代わりに、AIが会計の仕事をより戦略的にし、反復的な実行を特徴としなくなるだろうと提案しています。</p><p>彼らは建築のアナロジーを引き合いに出しています。建築では、コンピューター支援設計が骨の折れる手作業による製図に取って代わりました。建築家は姿を消したわけではありません。彼らは創造的な設計により多くの時間を費やし、機械的な複製にかかる時間を減らすことができるツールを手に入れたのです。</p><p>&quot;ジュニアまたは中級会計士であることの、時間集約的で創造性の低い作業の一部を取り除き、それを創造的で、アイデアを統合し、多くのタスクをAIアシスタントプラットフォームソリューションに委任できるプロフェッショナルである役割に置き換えると、業界ははるかに楽しく運営できるようになります&quot;とKonradは述べています。</p><p>この変化は、クライアントの成果も改善する可能性があります。会計士がコンプライアンスに費やす時間が減ると、クライアントが価値を置く戦略的なアドバイザリー業務により多くの時間を費やすことができます。</p><p>&quot;何に焦点を当てることができるかによって仕事がより楽しくなるだけでなく、クライアントはあなたからより多くの価値を得るでしょう&quot;とShahは述べています。</p><h2><b>競争環境：Marbleは資金力のあるライバルとレガシーな巨人に直面する</b></h2><p><b></b><a href=\"http://marble.ai/\">Marble</a>は、手ごわい既存企業と資金力のある競合他社が存在する市場に参入します。グローバルな税務調査プラットフォームである<a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>は、1億ドル以上を調達しました。<a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>、<a href=\"https://www.cch.com/\">CCH</a>、および<a href=\"https://www.intuit.com/\">Intuit</a>は、数十年にわたって構築された深い顧客関係を持っています。</p><p>しかし、創設者たちは移行の瞬間に機会を見出しています。</p><p>&quot;AIは業界で何が可能かを変えました&quot;とShahは述べています。&quot;私たちは業界の一部のテクノロジー企業と協力し、統合し、AIを搭載した新製品で他の企業と競争します。場合によっては、物事を行うための既存のテクノロジーソリューションを忘れ、タスク自体に戻ります。私たちにはまったく新しい技術的能力があります。人間と協力してそのタスクを達成するために、白紙の状態からどのように設計しますか？&quot;&quot;</p><p>無料の研究ツールを提供するという決定は、Marbleの市場参入哲学を反映しています。有料の壁なしで実務者がアクセスできるようにすることで、同社は信頼を構築し、能力を実証することを目指しています。</p><p>&quot;AIの使い方を心配している人や、AIをどのように採用するか疑問に思っている人に、目的に合わせて作られた本当に魅力的な製品を公開することができます。ワークフローにどのように統合するかを知らないときに、費用がかかるものを購入することを考える必要はありません&quot;とShahは述べています。</p><h2><b>2,500億ドルの質問：スタートアップはアメリカの税金の処理方法を変革できるか？</b></h2><p>Marbleのロードマップは調査にとどまりません。同社は、複雑な税務シナリオを分析し、コンプライアンスの問題を特定し、最終的にはコンプライアンスワークフローの重要な部分を自動化できるAIエージェントを開発することを計画しています。これらすべてを、実務者が管理できるようにしながら行います。</p><p>創設者たちは、成功を破壊という観点ではなく、リバランスという観点で捉えています。今日の税務業務はコンプライアンスに大きく偏っており、クライアントが切望し、より高い利益を生み出す戦略的なアドバイザリーサービスは、永遠に行われていません。Marbleは、AIがその方程式を覆すことができると賭けています。</p><p>&quot;誰もが、コンプライアンスがより簡単に行われ、戦略と計画について話す時間を使うことを望んでいます&quot;とKonradは述べています。&quot;コンプライアンス対戦略と計画のブレンドを、戦略と計画を最初にし、コンプライアンスが劇的に簡素化されたものにするにはどうすればよいでしょうか？&quot;</p><p>Marbleがそのビジョンを実行できるかどうかはまだわかりません。同社は、根強い競合他社、これまで技術的な変化に抵抗してきた業界、そして高リスクの財務業務のためのAIシステムを構築することの本質的な予測不可能性に直面しています。</p><p>しかし、創設者たちは、業界の人口統計の変化が、以前のテクノロジーの波では不可能だった方法で採用を加速させると賭けています。毎年業界に参入する会計士が減少し、クライアントの要求が増大するにつれて、企業は残りのスタッフがより多くのことを行えるようにするツールを受け入れる意欲が高まる可能性があります。</p><p>&quot;AIはすべての業界を変えるでしょう。ビジネスモデルを支援する方法もあれば、ビジネスモデルに挑戦する方法もあります。AIは最終的に会計事務所のビジネスをより良く、より収益性の高いものにし、同時にエンドクライアントはより良いサービスをより良い価格で受けられるようになると信じています&quot;とShahは述べています。</p><p>会計業界は、その方程式のどちら側に落ち着くかを調べようとしているようです。</p>",
    "insightJa": "中小企業では、AI導入が進むことで業務効率化や人材不足解消につながる可能性があります。今後はAIツールを使いこなせる人材育成も重要になるでしょう。",
    "recommendedBooks": [
      "AI 税務",
      "会計 AI",
      "人工知能 会計"
    ],
    "tags": [
      "AI",
      "Accounting",
      "Tax",
      "Automation",
      "Marble"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?AI%2CAccounting&sig=729"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "title": "New research reveals how everyday cues secretly shape your habits",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "summary": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "publishedAt": "Wed, 10 Dec 2025 22:41:05 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "titleJa": "日常の合図がどのように習慣を密かに形成するのかを解明する最新研究",
    "summaryJa": "KCC2タンパク質の低下でドーパミン神経が活性化、報酬との結びつきが強まり習慣形成が加速。日常の行動が強い欲求を誘発する仕組みを解明。",
    "explanationJa": "脳内のタンパク質が、私たちが何気なく行う行動と報酬を結びつけ、習慣を強くしてしまうことがあるようです。",
    "translationJa": "研究者たちは、KCC2と呼ばれる脳タンパク質のレベルの変化が、合図が報酬と結びつく方法をどのように再構築し、時に予想以上に早く、または強力に習慣を形成させるかを明らかにしました。このタンパク質が低下すると、ドーパミンニューロンの発火がより激しくなり、中毒性のある行動が定着するのと同様の方法で、新しい関連付けが強化されます。ラットの研究では、短い、同期した神経活動のバーストでさえ報酬学習を増幅させ、朝のルーチンのような日常的なきっかけが、なぜ強い欲求を引き起こすのかについての洞察を提供しています。",
    "insightJa": "この研究は、習慣形成のメカニズムを理解することで、悪い習慣を改善したり、新しい習慣を効果的に身につけたりするための戦略を立てるのに役立つ可能性があります。企業は、顧客の習慣を理解することで、より効果的なマーケティング戦略を展開できるかもしれません。",
    "recommendedBooks": [
      "習慣の力",
      "脳科学 習慣",
      "行動経済学 実践"
    ],
    "tags": [
      "habit formation",
      "KCC2",
      "dopamine",
      "reward learning",
      "習慣形成"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?habit%20formation%2CKCC2&sig=67"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "title": "Blood tests reveal obesity rapidly accelerates Alzheimer’s progression",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "summary": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "publishedAt": "Wed, 10 Dec 2025 12:23:51 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "titleJa": "血液検査で肥満がアルツハイマー病の進行を加速することが判明",
    "summaryJa": "肥満はアルツハイマー病関連の血液バイオマーカーの上昇を予想以上に加速させることが判明。画像データと血漿データから、肥満者は神経変性やアミロイド蓄積に関連するタンパク質の増加が速いことが示唆された。",
    "explanationJa": "血液検査によって、肥満がアルツハイマー病の進行を加速させる可能性が示唆されました。",
    "translationJa": "肥満は、これまで認識されていたよりもはるかに急速に、アルツハイマー病に関連する血液バイオマーカーの上昇を加速させます。長期的な画像データと血漿データは、肥満の人が神経変性およびアミロイド蓄積に関連するタンパク質の増加をはるかに速く経験することを示しています。驚くべきことに、血液検査はPETスキャンよりも早くこれらの変化を検出しました。この結果は、肥満がアルツハイマー病の進行に対する主要な、修正可能な要因であることを示しています。",
    "insightJa": "この研究結果は、肥満予防がアルツハイマー病のリスク低減に繋がる可能性を示唆しています。健康的な食生活や運動習慣を心がけることが、将来の健康維持に重要であると言えるでしょう。",
    "recommendedBooks": [
      "アルツハイマー病 予防",
      "肥満 健康リスク",
      "認知症 早期発見"
    ],
    "tags": [
      "Alzheimer's disease",
      "Obesity",
      "Blood biomarkers",
      "認知症",
      "肥満"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Alzheimer's%20disease%2CObesity&sig=67"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "title": "Rising temperatures are slowing early childhood development",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "summary": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "publishedAt": "Wed, 10 Dec 2025 00:59:03 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "titleJa": "気温上昇が幼児の発達を遅らせる",
    "summaryJa": "研究により、異常な高温が幼児の発達を妨げることが判明。特に読み書きや算数の基礎スキルにおいて、重要な学習の節目に到達しにくい傾向が示されました。経済的に恵まれない子供ほど影響を受けやすいようです。",
    "explanationJa": "気温の上昇は、子供たちが学校に通う前から学習に影響を与える可能性があることがわかりました。",
    "translationJa": "研究者たちは、異常に高い気温が幼児期の発達を妨げる可能性があることを発見しました。高温の環境で生活する子どもたちは、特に読み書きや基本的な算数のスキルにおいて、重要な学習の節目に到達しにくいことがわかりました。経済的な困難や限られた資源に直面している子どもたちは、最も大きな打撃を受けています。この研究は、気候変動が、子どもたちが学齢期に達するずっと前から、その学習をどのように形作る可能性があるかを強調しています。",
    "insightJa": "この研究結果は、地球温暖化対策だけでなく、子供たちの学習環境の改善や、経済格差の是正といった多角的なアプローチの重要性を示唆しています。企業においては、従業員の子育て支援策を充実させることが、将来的な人材育成にも繋がると言えるでしょう。",
    "recommendedBooks": [
      "幼児教育 環境",
      "気候変動 子育て",
      "子どもの発達 格差"
    ],
    "tags": [
      "early childhood development",
      "climate change",
      "rising temperatures",
      "幼児発達",
      "気候変動"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?early%20childhood%20development%2Cclimate%20change&sig=76"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "title": "Scientists reveal a tiny brain chip that streams thoughts in real time",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "summary": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "publishedAt": "Tue, 09 Dec 2025 23:54:39 EST",
    "author": "",
    "category": "Science",
    "originalContent": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "titleJa": "思考をリアルタイムで伝送する超小型脳チップを科学者が発表",
    "summaryJa": "BISCは脳とコンピュータを繋ぐ超薄型インプラント。数万の電極を搭載し、AIモデルで動きや意図を解読。てんかん、麻痺、失明治療を変革する可能性。",
    "explanationJa": "この超小型脳チップは、脳の活動をリアルタイムでコンピュータに伝え、医療の未来を変えるかもしれません。",
    "translationJa": "BISCは、脳とコンピュータの間に高帯域幅のワイヤレスリンクを構築する超薄型神経インプラントです。その小型シングルチップ設計には数万の電極が搭載されており、動き、知覚、意図を解読するための高度なAIモデルをサポートしています。初期の臨床研究では、頭蓋骨の小さな開口部から挿入でき、詳細な神経活動を捉えながら安定した状態を維持できることが示されています。この技術は、てんかん、麻痺、失明の治療法を再構築する可能性があります。",
    "insightJa": "この技術が発展すれば、脳波によるデバイス操作や、脳の状態をモニタリングすることで病気の早期発見にも繋がる可能性があります。医療や福祉分野だけでなく、エンターテイメントや教育分野での応用も期待されます。",
    "recommendedBooks": [
      "脳科学 入門",
      "ニューロテクノロジー",
      "AI 医療応用"
    ],
    "tags": [
      "Brain-Computer Interface",
      "Neural Implant",
      "AI",
      "Neuroscience",
      "脳科学"
    ],
    "imageUrl": "https://source.unsplash.com/400x300/?Brain-Computer%20Interface%2CNeural%20Implant&sig=76"
  }
]