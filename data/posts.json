[
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "title": "Parents call for New York governor to sign landmark AI safety bill",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "summary": "A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill that would require developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.\nThe bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul reportedly proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the changes made to California's  …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T22:16:09.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STK485_STK414_AI_SAFETY_B.webp?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill <a href=\"https://legislation.nysenate.gov/pdf/bills/2025/S6953B\">that would require</a> developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.</p>\n<p class=\"has-text-align-none\">The bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul <a href=\"https://www.transformernews.ai/p/new-york-governor-hochul-raise-act-sb-53\">reportedly</a> proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the <a href=\"https://www.theverge.com/ai-artificial-intelligence/787918/sb-53-the-landmark-ai-transparency-bill-is-now-law-in-california\">changes made to California's  …</a></p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "親たちがニューヨーク州知事に画期的なAI安全法案の署名を求める",
    "summaryJa": "150人以上の親が、ニューヨーク州知事にAI安全法案（RAISE法）への署名を求めました。同法案は、大規模AIモデルの開発者に安全計画の策定と透明性の高い報告を義務付けるものです。",
    "explanationJa": "ニューヨーク州で、AIの安全性を高めるための重要な法案が議論されており、親たちが知事に署名を求めています。",
    "translationJa": "150人以上の親グループが金曜日、ニューヨーク州知事キャシー・ホークルに書簡を送り、責任あるAIの安全性と教育（RAISE）法を修正なしで署名するよう促しました。 RAISE法は、Meta、OpenAI、Deepseek、Googleなどの大規模AIモデルの開発者に対し、安全計画を作成し、安全に関する事故の報告に関する透明性ルールに従うことを義務付ける注目の法案です。\n\nこの法案は6月にニューヨーク州上院と下院の両方で可決されました。しかし今週、ホークルはRAISE法をほぼ完全に書き換え、テクノロジー企業にとってより有利なものにするよう提案しました。これは、カリフォルニア州で行われた変更の一部と同様です。\n\n詳細はThe Vergeの記事をご覧ください: [https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill]",
    "insightJa": "AI技術の進化は目覚ましいですが、同時に安全性への懸念も高まっています。この法案が成立すれば、AI技術の健全な発展を促し、私たちの生活やビジネスにおけるリスクを軽減することに繋がります。",
    "recommendedBooks": [
      "AI倫理",
      "AIリスクマネジメント",
      "AI 法規制"
    ],
    "tags": [
      "AI safety",
      "RAISE Act",
      "New York",
      "AI regulation",
      "人工知能安全"
    ],
    "imageUrl": "https://images.pexels.com/photos/16053029/pexels-photo-16053029.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075418",
    "title": "OK, what’s going on with LinkedIn’s algo?",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/ok-whats-going-on-with-linkedins-algo/",
    "summary": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "publishedAt": "Fri, 12 Dec 2025 19:38:16 +0000",
    "author": "Dominic-Madori Davis",
    "category": "AI",
    "originalContent": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "titleJa": "LinkedInのアルゴリズムに何が？",
    "summaryJa": "女性たちがLinkedInの新アルゴリズムが性差別的かどうか実験。証拠を見つけたと主張したが、専門家はもっと複雑な要因があると指摘しています。",
    "explanationJa": "LinkedInの新しいアルゴリズムが性差別的である可能性があるという実験結果について、専門家の意見が分かれています。",
    "translationJa": "女性たちがLinkedInの新しいアルゴリズムが性差別的かどうかを検証する実験を行い、それを証明したと考えました。しかし、専門家によれば、より複雑な要因が関係しているようです。",
    "insightJa": "もしLinkedInのアルゴリズムにバイアスがある場合、採用活動やキャリア形成に影響が出る可能性があります。企業は、アルゴリズムの公平性を常に意識し、定期的な検証を行う必要があるでしょう。",
    "recommendedBooks": [
      "アルゴリズム バイアス",
      "ジェンダーとテクノロジー",
      "AI 公平性"
    ],
    "tags": [
      "LinkedIn",
      "algorithm",
      "sexism",
      "bias",
      "AI ethics"
    ],
    "imageUrl": "https://images.pexels.com/photos/1089438/pexels-photo-1089438.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "title": "Google Translate brings real-time speech translations to any headphones",
    "source": "rss",
    "url": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "summary": "Google Translate's latest update brings live speech translations, originally available only on the Pixel Buds, to any headphones you want, with support for over 70 languages. It's rolling out today in beta and just requires a compatible Android phone with the Translate app (unlike Apple's similar feature, which requires AirPods). \nIt's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T18:11:14.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/google-translate-text-update-12-12-25.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google Translate's latest update brings live speech translations, originally available only <a href=\"https://www.theverge.com/2017/11/16/16659314/google-pixel-buds-review-bluetooth-headphones\">on the Pixel Buds</a>, to any headphones you want, with support for over 70 languages. It's <a href=\"https://blog.google/products/search/gemini-capabilities-translation-upgrades/\">rolling out today in beta</a> and just requires a compatible Android phone with the Translate app (unlike <a href=\"https://www.theverge.com/news/629506/apple-airpods-live-translation-ios-19\">Apple's similar feature</a>, which requires AirPods). </p>\n<p class=\"has-text-align-none\">It's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …</p>\n<p><a href=\"https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "Google翻訳、リアルタイム音声翻訳をあらゆるヘッドホンで利用可能に",
    "summaryJa": "Google翻訳の最新アップデートで、Pixel Buds限定だったリアルタイム音声翻訳が、あらゆるヘッドホンで利用可能に。70以上の言語に対応。Geminiにより、翻訳精度も向上。",
    "explanationJa": "Google翻訳がアップデートされ、お持ちのヘッドホンでリアルタイム翻訳が簡単に利用できるようになります。",
    "translationJa": "Google翻訳の最新アップデートにより、以前はPixel Budsでのみ利用可能だったリアルタイム音声翻訳が、お好きなヘッドホンで利用できるようになりました。70以上の言語をサポートしています。本日ベータ版として公開され、Translateアプリがインストールされた対応Androidスマートフォンが必要です（Appleの同様の機能のようにAirPodsは必要ありません）。\n\nこれは、Google翻訳に追加されるいくつかの新機能の1つで、テキスト翻訳も改善されています。Geminiを使用することで、Translateはイディオムやスラングなど、文字通りの意味とは異なるフレーズをより正確に翻訳できるようになります。例えば、「stealing my …」のような表現です。\n\nThe Vergeで全文をお読みください。",
    "insightJa": "このアップデートにより、海外旅行やビジネスシーンでのコミュニケーションがよりスムーズになるでしょう。異なる言語を話す人々との交流が、より身近になることが期待されます。",
    "recommendedBooks": [
      "翻訳技術",
      "多言語コミュニケーション",
      "AI翻訳の未来"
    ],
    "tags": [
      "Google Translate",
      "リアルタイム翻訳",
      "音声翻訳",
      "Gemini",
      "多言語対応"
    ],
    "imageUrl": "https://images.pexels.com/photos/607812/pexels-photo-607812.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075611",
    "title": "Trump’s AI executive order promises ‘one rulebook’ — startups may get legal limbo instead",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/trumps-ai-executive-order-promises-one-rulebook-startups-may-get-legal-limbo-instead/",
    "summary": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "publishedAt": "Fri, 12 Dec 2025 17:07:22 +0000",
    "author": "Rebecca Bellan",
    "category": "AI",
    "originalContent": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "titleJa": "トランプ大統領のAIに関する大統領令、「単一のルールブック」を約束もスタートアップは法的空白に陥る可能性",
    "summaryJa": "トランプ大統領が州法を対象としたAIに関する大統領令に署名し、国家統一ルールを約束。しかし、連邦規則の議論中に法廷闘争を引き起こし、スタートアップ企業の不確実性を長引かせる可能性があると批判されている。",
    "explanationJa": "トランプ大統領のAIに関する大統領令は、AI関連ビジネスのルールを統一しようとするものですが、混乱を招く可能性もあります。",
    "translationJa": "トランプ大統領は、州法を対象とし、単一の国家ルールブックを約束するAIに関する大統領令に署名しました。批評家たちは、この大統領令が法廷闘争を引き起こし、議会が連邦規則を議論している間、スタートアップ企業の不確実性を長引かせる可能性があると警告しています。",
    "insightJa": "この大統領令によって、AI関連のビジネスを行う企業は、今後の法規制の動向を注視する必要があります。特にスタートアップ企業は、ビジネス戦略に柔軟性を持たせることが重要になるでしょう。",
    "recommendedBooks": [
      "AI 法規制",
      "人工知能 スタートアップ",
      "技術革新 リスク"
    ],
    "tags": [
      "AI",
      "Artificial Intelligence",
      "executive order",
      "regulation",
      "startups"
    ],
    "imageUrl": "https://images.pexels.com/photos/20457109/pexels-photo-20457109.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075551",
    "title": "Google Translate now lets you hear real-time translations in your headphones",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/google-translate-now-lets-you-hear-real-time-translations-in-your-headphones/",
    "summary": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "publishedAt": "Fri, 12 Dec 2025 17:00:00 +0000",
    "author": "Aisha Malik",
    "category": "AI",
    "originalContent": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "titleJa": "Google翻訳、ヘッドホンでリアルタイム翻訳が可能に",
    "summaryJa": "Google翻訳が、話者の口調や強調、リズムをそのままに、リアルタイムでヘッドホンに翻訳を届ける機能を追加。会話の理解が容易になり、誰が話しているかも識別しやすくなります。",
    "explanationJa": "Google翻訳の新機能で、ヘッドホンを使ってリアルタイムの翻訳を聞くことができるようになりました。",
    "translationJa": "リアルタイムのヘッドホン翻訳体験では、各話者の口調、強調、リズムがそのまま維持されるため、会話を理解しやすく、誰が何を言っているのかを判別しやすくなります。",
    "insightJa": "この機能により、言語の壁を越えたコミュニケーションがより自然に、そして円滑になります。ビジネスシーンでは、国際会議や商談がよりスムーズに進むことが期待されます。",
    "recommendedBooks": [
      "翻訳技術",
      "多言語コミュニケーション",
      "AI音声認識"
    ],
    "tags": [
      "Google Translate",
      "Real-time Translation",
      "Headphones",
      "AI",
      "Language Learning"
    ],
    "imageUrl": "https://images.pexels.com/photos/267669/pexels-photo-267669.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=2607630",
    "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/chatgpt-everything-to-know-about-the-ai-chatbot/",
    "summary": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "publishedAt": "Fri, 12 Dec 2025 16:01:00 +0000",
    "author": "Kyle Wiggers, Cody Corrall, Kate Park, Alyssa Stringer",
    "category": "AI",
    "originalContent": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "titleJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと",
    "summaryJa": "この記事では、ChatGPTの最新情報とリリース履歴をまとめています。今年1年間のアップデートを時系列で追うことができます。",
    "explanationJa": "この記事では、話題のAIチャットボット、ChatGPTのアップデート情報をまとめて紹介しています。",
    "translationJa": "ChatGPTのプロダクトアップデートとリリース履歴のタイムラインです。最新の情報から順に、今年一年を通じて更新しています。",
    "insightJa": "ChatGPTの進化は、私たちのコミュニケーションや情報収集の方法を大きく変える可能性があります。ビジネスにおいては、顧客対応や業務効率化に貢献することが期待されます。",
    "recommendedBooks": [
      "ChatGPT 入門",
      "自然言語処理 AI",
      "AIチャットボット 活用"
    ],
    "tags": [
      "ChatGPT",
      "AI",
      "Chatbot",
      "自然言語処理",
      "アップデート"
    ],
    "imageUrl": "https://images.pexels.com/photos/16094040/pexels-photo-16094040.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "title": "I quit all my AI fitness plans, and I feel free",
    "source": "rss",
    "url": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "summary": "AI sure does use a lot of words to say very little.\t\n\nThis is Optimizer, a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. Optimizer arrives in our subscribers' inboxes at 10AM ET. Opt in for Optimizer here.\nThis time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt amazing. Then life happened. \nA year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T15:00:00.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Over the shoulder shot of someone reading a lengthy AI insight from the Runna app\" data-caption=\"AI sure does use a lot of words to say very little.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAI sure does use a lot of words to say very little.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>This is </em><a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a><em>, a weekly newsletter sent every Friday from Verge senior reviewer</em> <a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a><em> that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. </em>Optimizer<em> arrives in our subscribers' inboxes at 10AM ET. Opt in for </em>Optimizer <em><a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</em></p>\n<p class=\"has-drop-cap has-text-align-none\">This time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt <em>amazing.</em> Then life happened. </p>\n<p class=\"has-text-align-none\">A year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIフィットネスプランを全てやめたら、心が自由になった",
    "summaryJa": "筆者はAIフィットネスプランを利用していたが、長文で内容が薄いと感じ、全てやめた。以前は好調だったが、生活の変化で運動習慣が崩れ、AIに頼るのをやめた経緯を述べている。",
    "explanationJa": "AIフィットネスプランをやめた筆者が、その理由と解放感について語っています。",
    "translationJa": "これは、The Vergeのシニアレビュアーであるヴィクトリア・ソンが毎週金曜日に送信するニュースレター「Optimizer」です。このニュースレターでは、あなたの人生を変えると豪語する最新の携帯電話、スマートウォッチ、アプリ、その他のガジェットを詳しく分析し、議論します。Optimizerは、東部時間午前10時に購読者の受信箱に届きます。Optimizerの購読は<a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">こちら</a>からどうぞ。\n\n去年の今頃、私は6ヶ月間の継続的なトレーニングの後、4マイルのランニングタイムを16分短縮し、週に3〜4回ウェイトリフティングを行い、10ポンドの減量に成功していました。気分は最高でした。しかし、その後、人生に変化がありました。\n\n1年後、3ヶ月以上5K以上のランニングはしておらず、ストレスで10ポンドのリバウンド、そして…\n\n<a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">The Vergeで記事全文を読む</a>",
    "insightJa": "AIフィットネスは便利ですが、自分に合った方法を見つけることが重要です。AIに頼りすぎず、自分の体調やライフスタイルに合わせて運動プランを調整することが、継続的な健康維持につながります。",
    "recommendedBooks": [
      "フィットネス AI",
      "AI パーソナルトレーナー",
      "運動習慣 継続"
    ],
    "tags": [
      "AI fitness",
      "fitness plan",
      "Runna",
      "exercise",
      "健康"
    ],
    "imageUrl": "https://images.pexels.com/photos/6766999/pexels-photo-6766999.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "title": "How to vibe-write a country hit",
    "source": "rss",
    "url": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "summary": "You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"I Run\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.\nOn this episode of The Vergecast, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent Switched on Pop podcast. Charlie takes us th …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T14:23:18.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/VRG_VST_1212_Site.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"<a href=\"https://www.digitalmusicnews.com/2025/11/24/havens-i-run-ai-song-explained/\">I Run</a>\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.</p>\n<p class=\"has-text-align-none\">On <a href=\"https://link.chtbl.com/vergecast\">this episode of <em>The Vergecast</em></a>, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent <em>Switched on Pop </em>podcast. Charlie takes us th …</p>\n<p><a href=\"https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIでカントリーヒット曲を作る方法",
    "summaryJa": "AIツール、特にSunoが音楽制作、特にカントリーミュージックの中心地ナッシュビルで大きな役割を果たしている。TikTokでAI生成楽曲を耳にする機会が増加。",
    "explanationJa": "最近、AIを使って音楽を作るのが流行っています。特にカントリー音楽でよく使われるようになっているんです。",
    "translationJa": "ご存知ないかもしれませんが、あなたはほぼ確実に、ほとんど、あるいは完全にAIによって作られた曲に出会ったことがあるでしょう。ここ数週間TikTokをスクロールしているなら、おそらく「<a href=\"https://www.digitalmusicnews.com/2025/11/24/havens-i-run-ai-song-explained/\">I Run</a>」を何度か耳にしたことがあるでしょう。しかし、ソーシャルおよび音楽プラットフォーム上で広まっているものは数え切れません。一般的なAIツール、特にSunoは、音楽制作プロセスの大きな部分を占めるようになっています。そして、それはカントリーミュージックの本拠地、ナッシュビルにおいて最も当てはまります。\n\n<a href=\"https://link.chtbl.com/vergecast\">この<em>The Vergecast</em>のエピソード</a>では、音楽ジャーナリストであり、優れた<em>Switched on Pop</em>ポッドキャストの共同ホストでもあるチャーリー・ハーディングが、ニレイとデイビッドと一緒に登場します。チャーリーが私たちを案内してくれます…\n\n<a href=\"https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast\">The Vergeで記事全文を読む</a>。",
    "insightJa": "AI音楽は、個人の音楽制作を容易にする一方で、著作権や音楽業界の構造に大きな変化をもたらす可能性があります。今後は、AIと人間のクリエイターがどのように共存していくかが重要な課題となるでしょう。",
    "recommendedBooks": [
      "AI 音楽 作曲",
      "カントリーミュージック 歴史",
      "音楽著作権 法"
    ],
    "tags": [
      "AI music",
      "Country music",
      "Suno",
      "Nashville",
      "The Vergecast"
    ],
    "imageUrl": "https://images.pexels.com/photos/2453636/pexels-photo-2453636.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "43pZxbBPbS0s7iDFEyijjR",
    "title": "Ai2's new Olmo 3.1 extends reinforcement learning training for stronger reasoning benchmarks",
    "source": "rss",
    "url": "https://venturebeat.com/ai/ai2s-new-olmo-3-1-extends-reinforcement-learning-training-for-stronger",
    "summary": "The Allen Institute for AI (Ai2) recently released what it calls its most powerful family of models yet, Olmo 3. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.\nThe new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. \nAi2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. \nOlmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. \nAi2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. \n“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a blog post. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”\n\nTo get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.\nOlmo 3.1 Instruct 32B is \"optimized for chat, tool use, & multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a post on X. \nFor now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. \nBetter performance on benchmarks\nThe Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. \nOlmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. \nOlmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.\n“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. \n\nAi2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.\nCommitment to transparency and open source \nAi2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. \nOrganizations could add to the model’s data mix and retrain it to also learn from what’s been added.  \nThis has long been a commitment for Ai2, which also offers a tool called OlmoTrace that tracks how LLM outputs match its training data.  \n\n“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said.",
    "publishedAt": "Fri, 12 Dec 2025 05:00:00 GMT",
    "author": "",
    "category": "AI",
    "originalContent": "<p>The Allen Institute for AI (Ai2) recently released what it calls its most powerful <a href=\"https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning\"><u>family of models yet, Olmo 3</u></a>. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.</p><p>The new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. </p><p>Ai2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. </p><p>Olmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. </p><p>Ai2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. </p><p>“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a <a href=\"https://allenai.org/blog/olmo3\"><u>blog post</u></a>. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”</p><div></div><p>To get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.</p><p>Olmo 3.1 Instruct 32B is &quot;optimized for chat, tool use, &amp; multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a <a href=\"https://x.com/allen_ai/status/1999528338365247539\"><u>post on X</u></a>. </p><p>For now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. </p><h2>Better performance on benchmarks</h2><p>The Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. </p><p>Olmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. </p><p>Olmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.</p><p>“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. </p><div></div><p>Ai2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.</p><h2>Commitment to transparency and open source </h2><p>Ai2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. </p><p>Organizations could add to the model’s data mix and retrain it to also learn from what’s been added.  </p><p>This has long been a commitment for Ai2, which also offers a <a href=\"https://venturebeat.com/ai/whats-inside-the-llm-ai2-olmotrace-will-trace-the-source\"><u>tool called OlmoTrace</u></a> that tracks how LLM outputs match its training data.  </p><div></div><p>“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said. </p><p>\n\n\n\n\n\n</p>",
    "titleJa": "Ai2の新しいOlmo 3.1、強固な推論ベンチマークに向けた強化学習トレーニングを拡張",
    "summaryJa": "Allen Institute for AI (Ai2)が、Olmo 3.1を発表。Olmo 3を改良し、強化学習を拡張。効率性、透明性、制御に焦点を当て、ベンチマークで優れた性能を示した。",
    "explanationJa": "AI研究機関Ai2が、より高性能なAIモデルOlmo 3.1を発表しました。これにより、AIの性能がさらに向上することが期待されます。",
    "translationJa": "Allen Institute for AI (Ai2) は最近、これまでで最も強力なモデルファミリーである Olmo 3 を発表しました。しかし、同社はモデルの反復を続け、強化学習 (RL) の実行を拡大し、Olmo 3.1 を作成しました。\n\n新しい Olmo 3.1 モデルは、企業向けの効率性、透明性、および制御に焦点を当てています。\n\nAi2 は、Olmo 2 の 3 つのバージョンのうち 2 つを更新しました。高度な研究向けに最適化されたフラッグシップ モデルである Olmo 3.1 Think 32B と、指示の実行、複数ターンの対話、およびツールの使用向けに設計された Olmo 3.1 Instruct 32B です。\n\nOlmo 3 には、プログラミング、理解、および数学用の 3 番目のバージョンである Olmo 3-Base があります。これは、継続的な微調整にも適しています。\n\nAi2 は、Olmo 3 Think 32B を Olmo 3.1 にアップグレードするために、研究者たちは最高の RL 実行をより長いトレーニング スケジュールで拡張したと述べています。\n\n「オリジナルの Olmo 3 の発売後、Olmo 3 32B Think の RL トレーニングの実行を再開し、Dolci-Think-RL データセットで追加のエポックを使用して 224 個の GPU でさらに 21 日間トレーニングしました」と Ai2 はブログ投稿で述べています。「これにより、Olmo 3.1 32B Think が実現し、数学、推論、および指示の実行ベンチマーク全体で大幅な改善をもたらします。AIME で 5 ポイント以上、ZebraLogic で 4 ポイント以上、IFEval で 4 ポイント以上、IFBench で 20 ポイント以上の改善が見られたほか、コーディングや複雑な複数ステップのタスクでもより強力なパフォーマンスを発揮します。」\n\nOlmo 3.1 Instruct を実現するために、Ai2 はより小さい Instruct サイズである 7B の背後にあるレシピをより大きなモデルに適用したと述べています。\n\nOlmo 3.1 Instruct 32B は、「チャット、ツールの使用、および複数ターンの対話に最適化されており、Olmo 3 Instruct 7B のパフォーマンスが大幅に向上した兄弟モデルであり、実際のアプリケーションに対応できます」と Ai2 は X の投稿で述べています。\n\n今のところ、新しいチェックポイントは Ai2 Playground または Hugging Face で入手でき、API アクセスは近日中に提供されます。\n\nベンチマークでのパフォーマンスの向上\n\nOlmo 3.1 モデルは、ベンチマーク テストで良好なパフォーマンスを発揮し、当然のことながら Olmo 3 モデルを上回りました。\n\nOlmo 3.1 Think は、AIME 2025 ベンチマークで Qwen 3 32B モデルを上回り、Gemma 27B に近いパフォーマンスを発揮しました。\n\nOlmo 3.1 Instruct は、オープンソースの同等モデルに対して強力なパフォーマンスを発揮し、Math ベンチマークでは Gemma 3 などのモデルにも打ち勝ちました。\n\n「Olmo 3.1 32B Instruct については、チャット、ツールの使用、および複数ターンの対話向けに構築された、より大規模な指示調整モデルです。Olmo 3.1 32B Instruct は、これまでに最も優れた完全オープン チャット モデルであり、当社の評価では、最も強力な完全オープン 32B スケール指示モデルです」と同社は述べています。\n\nAi2 はまた、数学とコーディングのために RL-Zero 7B モデルをアップグレードしました。同社は X で、両方のモデルがより長く、より安定したトレーニング実行の恩恵を受けたと述べています。\n\n透明性とオープンソースへのコミットメント\n\nAi2 は以前 VentureBeat に、企業や研究室がモデルに入力されたデータとトレーニングをより詳細に制御および理解できるように、Olmo 3 ファミリーのモデルを設計したと語っています。\n\n組織は、モデルのデータミックスに追加し、それを再トレーニングして、追加されたものからも学習できます。\n\nこれは Ai2 にとって長年のコミットメントであり、LLM 出力がトレーニング データとどのように一致するかを追跡する OlmoTrace というツールも提供しています。\n\n「Olmo 3.1 Think 32B と Olmo 3.1 Instruct 32B は、オープン性とパフォーマンスがともに向上できることを示しています。同じモデルフローを拡張することで、データ、コード、およびトレーニングの決定に対するエンドツーエンドの透明性を維持しながら、機能を向上させ続けています」と Ai2 は述べています。",
    "insightJa": "Olmo 3.1の登場により、企業は自社のデータでAIモデルを再学習させることが容易になります。これにより、特定の業務に特化した、より高度なAIソリューションの開発が期待されます。",
    "recommendedBooks": [
      "大規模言語モデル",
      "強化学習 実践",
      "自然言語処理 エンタープライズ"
    ],
    "tags": [
      "AI",
      "Olmo 3.1",
      "Reinforcement Learning",
      "LLM",
      "Allen Institute for AI"
    ],
    "imageUrl": "https://images.pexels.com/photos/20457109/pexels-photo-20457109.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "title": "Trump signs AI executive order pushing to ban state laws",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "summary": "President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t\n\nOn Thursday evening, with White House AI and crypto czar David Sacks looking over his shoulder, Donald Trump signed an executive order aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order can't by itself unilaterally override state AI laws, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.\nIt specifically calls out Colorado's recently passed consumer protection law, making the claim that \"banning 'algorithmic discri …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T01:18:46.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks in the Oval Office\" data-caption=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/gettyimages-2251458899.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tPresident Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">On Thursday evening, with White House AI and crypto czar David Sacks <a href=\"https://www.youtube.com/live/rYDbVjXu5os?si=TUpA0_o7ORLU9jZh&amp;t=737\">looking over his shoulder</a>, Donald Trump <a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/\">signed an executive order</a> aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order <a href=\"https://www.theverge.com/column/829938/leaked-ai-executive-order-analysis\">can't by itself unilaterally override state AI laws</a>, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.</p>\n<p class=\"has-text-align-none\">It specifically calls out Colorado's <a href=\"https://leg.colorado.gov/bills/sb24-205\">recently passed consumer protection law</a>, making the claim that \"banning 'algorithmic discri …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "トランプ大統領、AI規制に関する大統領令に署名、州法の禁止を推進",
    "summaryJa": "トランプ大統領がAI規制に関する大統領令に署名。連邦政府がAI規制を主導し、州法の影響を抑制することを目的としている。コロラド州の消費者保護法が名指しされている。",
    "explanationJa": "トランプ大統領がAIに関する新しい大統領令に署名し、AI規制における連邦政府の権限を強化しようとしています。",
    "translationJa": "ドナルド・トランプ大統領は木曜日の夕方、ホワイトハウスのAIおよび暗号通貨担当官であるデビッド・サックス氏が背後で見守る中、人工知能（AI）の規制において連邦政府が一方的な権限を掌握することを目的とした大統領令に署名しました。この命令は、それ自体で州のAI関連法を一方的に覆すことはできませんが、連邦政府機関に対し、州法の影響を軽減または排除するための措置を講じ、連邦政府が異議を唱える可能性のある法律や、他のプログラムに対する重要な資金提供を危険にさらす可能性のある法律を州が制定することを阻止するよう指示しています。\n\n特に、コロラド州で最近可決された消費者保護法を名指しし、「アルゴリズムによる差別禁止」という主張を行っています。\n\nThe Vergeで全文をお読みください。",
    "insightJa": "この動きは、AI技術の発展と規制のバランスに影響を与える可能性があります。ビジネスにおいては、連邦政府と州政府の規制動向を注視し、コンプライアンス体制を整える必要性が高まるでしょう。",
    "recommendedBooks": [
      "人工知能 規制",
      "AIガバナンス",
      "技術と法律"
    ],
    "tags": [
      "Artificial Intelligence",
      "AI Regulation",
      "Executive Order",
      "Trump",
      "州法"
    ],
    "imageUrl": "https://images.pexels.com/photos/20457109/pexels-photo-20457109.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075457",
    "title": "Google launched its deepest AI research agent yet — on the same day OpenAI dropped GPT-5.2",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/",
    "summary": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "publishedAt": "Fri, 12 Dec 2025 00:18:56 +0000",
    "author": "Julie Bort",
    "category": "AI",
    "originalContent": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "titleJa": "Google、過去最高のAI研究エージェントを発表 - OpenAIがGPT-5.2を公開した同日に",
    "summaryJa": "GoogleはGemini 3 Proを基盤としたDeep Researchツールを開発者向けに公開。アプリへの組み込みが可能になりました。OpenAIのGPT-5.2公開と同日の発表です。",
    "explanationJa": "Googleの最新AI研究ツールが利用可能になり、より賢いアプリ開発が期待されます。",
    "translationJa": "Googleは、Gemini 3 Proを基盤とするDeep Researchツールを開発者が自身のアプリケーションに組み込めるようにしました。これは初の試みです。",
    "insightJa": "この技術により、より高度なAI機能が組み込まれたアプリケーションが登場し、日々の業務効率化や新たなビジネスチャンスの創出につながる可能性があります。AIの進化は今後も社会に大きな影響を与えるでしょう。",
    "recommendedBooks": [
      "AI開発 実践",
      "Gemini AI",
      "大規模言語モデル 応用"
    ],
    "tags": [
      "Google",
      "Gemini",
      "Deep Research",
      "AI",
      "OpenAI"
    ],
    "imageUrl": "https://images.pexels.com/photos/30869081/pexels-photo-30869081.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "7iBvnTz8OK7lcxexlxh4OW",
    "title": "Google’s new framework helps AI agents spend their compute and tool budget more wisely",
    "source": "rss",
    "url": "https://venturebeat.com/ai/googles-new-framework-helps-ai-agents-spend-their-compute-and-tool-budget",
    "summary": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.\nAs AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.\nFor enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.\nThe challenge of scaling tool use\nTraditional test-time scaling focuses on letting models \"think\" longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.\nThis introduces significant operational overhead for businesses. \"Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,\" Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. \"Tool calls themselves introduce additional API costs.\"\nThe researchers found that simply granting agents more test-time resources does not guarantee better performance. \"In a deep research task, if the agent has no sense of budget, it often goes down blindly,\" Wang and Liu explained. \"It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.\"\nOptimizing resources with Budget Tracker\nTo evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called \"Budget Tracker.\" This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.\nThe team hypothesized that \"providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.\"\nBudget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)\nIn Google's implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.\nTo test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.\nThey tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as Gemini 2.5 Pro, Gemini 2.5 Flash, and Claude Sonnet 4. The experiments show that this simple plug-in improves performance across various budget constraints.\n\"Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,\" the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.\nBATS: A comprehensive framework for budget-aware scaling\nTo further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent's behavior as it formulates its response.\nBATS uses multiple modules to orchestrate the agent's actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to \"dig deeper\" into a promising lead or \"pivot\" to alternative paths based on resource availability.\nGiven an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.\nThe iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.\nThe researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.\nBATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.\nAccording to the authors, this efficiency makes previously expensive workflows viable. \"This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,\" they said.\nAs enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.\n\"We believe the relationship between reasoning and economics will become inseparable,\" Wang and Liu said. \"In the future, [models] must reason about value.\"",
    "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
    "author": "bendee983@gmail.com (Ben Dickson)",
    "category": "AI",
    "originalContent": "<p>In a <a href=\"https://arxiv.org/abs/2511.17006\"><u>new paper</u></a> that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple &quot;Budget Tracker&quot; and a more comprehensive framework called &quot;Budget Aware Test-time Scaling.&quot; These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.</p><p>As AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.</p><p>For enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.</p><h2>The challenge of scaling tool use</h2><p>Traditional <a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>test-time scaling</u></a> focuses on letting models &quot;think&quot; longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.</p><p>This introduces significant operational overhead for businesses. &quot;Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,&quot; Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. &quot;Tool calls themselves introduce additional API costs.&quot;</p><p>The researchers found that simply granting agents more test-time resources does not guarantee better performance. &quot;In a deep research task, if the agent has no sense of budget, it often goes down blindly,&quot; Wang and Liu explained. &quot;It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.&quot;</p><h2>Optimizing resources with Budget Tracker</h2><p>To evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called &quot;Budget Tracker.&quot; This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.</p><p>The team hypothesized that &quot;providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.&quot;</p><p>Budget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)</p><p>In Google&#x27;s implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.</p><p>To test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.</p><p>They tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as <a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>, Gemini 2.5 Flash, and <a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>. The experiments show that this simple plug-in improves performance across various budget constraints.</p><p>&quot;Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,&quot; the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.</p><h2>BATS: A comprehensive framework for budget-aware scaling</h2><p>To further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent&#x27;s behavior as it formulates its response.</p><p>BATS uses multiple modules to orchestrate the agent&#x27;s actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to &quot;dig deeper&quot; into a promising lead or &quot;pivot&quot; to alternative paths based on resource availability.</p><p>Given an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.</p><p>The iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.</p><p>The researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.</p><p>BATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.</p><p>According to the authors, this efficiency makes previously expensive workflows viable. &quot;This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,&quot; they said.</p><p>As enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.</p><p>&quot;We believe the relationship between reasoning and economics will become inseparable,&quot; Wang and Liu said. &quot;In the future, [models] must reason about value.&quot;</p><p>\n</p>",
    "titleJa": "Googleの新しいフレームワーク、AIエージェントが計算リソースとツールをより賢く利用できるように",
    "summaryJa": "Googleの研究者らは、LLMエージェントのツール利用効率を向上させるフレームワークを開発。Budget TrackerとBATSという2つの技術で、コスト効率の良いAIエージェントの展開を可能にします。",
    "explanationJa": "Googleが開発したAIエージェント向けの新しい技術は、コストを抑えつつ効率的にタスクを実行できるようにするものです。",
    "translationJa": "<p>大規模言語モデル（LLM）エージェントにおけるツール利用を研究した<a href=\"https://arxiv.org/abs/2511.17006\"><u>新しい論文</u></a>で、Googleとカリフォルニア大学サンタバーバラ校の研究者らは、エージェントがツールと計算リソースの予算をより効率的に利用できるフレームワークを開発しました。研究者らは、シンプルな「Budget Tracker」と、より包括的なフレームワークである「Budget Aware Test-time Scaling（BATS）」という2つの新しい技術を紹介しました。これらの技術により、エージェントは残りの推論とツール利用の許容量を明確に認識できます。</p><p>AIエージェントが現実世界で機能するためにツール呼び出しに依存するにつれて、テスト時のスケーリングは、より賢いモデルというよりも、コストとレイテンシの制御が重要になってきています。</p><p>企業のリーダーや開発者にとって、予算を意識したスケーリング技術は、予測不可能なコストや計算リソースの消費に対する収益逓減に直面することなく、効果的なAIエージェントを展開するための現実的な道を提供します。</p><h2>ツール利用のスケーリングの課題</h2><p>従来の<a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>テスト時のスケーリング</u></a>は、モデルに「より長く考えさせる」ことに焦点を当てています。しかし、ウェブブラウジングのようなエージェント的なタスクの場合、ツール呼び出しの回数が、探索の深さと広さを直接決定します。</p><p>これは企業にとって重大な運用上のオーバーヘッドをもたらします。論文の共著者であるジフェン・ワン氏とテンシャオ・リュウ氏はVentureBeatに対し、「ウェブページのブラウジングなどのツール呼び出しは、より多くのトークン消費をもたらし、コンテキスト長を増加させ、追加の時間レイテンシをもたらします」と語りました。「ツール呼び出し自体が追加のAPIコストをもたらします。」</p><p>研究者らは、エージェントにより多くのテスト時リソースを与えるだけでは、パフォーマンスが向上するとは限らないことを発見しました。ワン氏とリュウ氏は、「深い研究タスクにおいて、エージェントが予算を意識していない場合、しばしば盲目的に突き進みます」と説明しました。「やや関連性のある手がかりを見つけ、それに10回または20回のツール呼び出しを費やして掘り下げますが、そのパス全体が行き止まりだったことに気づくだけです。」</p><h2>Budget Trackerによるリソースの最適化</h2><p>ツール利用の予算をどのように最適化できるかを評価するために、研究者らは最初に「Budget Tracker」と呼ばれる軽量なアプローチを試しました。このモジュールは、エージェントにリソースの利用可能性に関する継続的なシグナルを提供するプラグインとして機能し、予算を意識したツール利用を可能にします。</p><p>研究チームは、「明示的な予算シグナルを提供することで、モデルは追加のトレーニングを必要とせずに、リソース制約を内面化し、その戦略を適応させることができる」と仮説を立てました。</p><p>Budget Trackerは純粋にプロンプトレベルで動作するため、実装が容易です。（論文には、Budget Trackerに使用されるプロンプトの詳細が完全に記載されており、実装が容易になっています。）</p><p>Googleの実装では、トラッカーは予算体制と対応するツールの使用に関する推奨事項を説明する簡単なポリシーガイドラインを提供します。応答プロセスの各ステップで、Budget Trackerはエージェントにリソース消費と残りの予算を明確に認識させ、その後の推論ステップを更新されたリソース状態に基づいて条件付けできるようにします。</p><p>これをテストするために、研究者らは2つのパラダイムを実験しました。モデルが反復的に出力を改良するシーケンシャルスケーリングと、複数の独立した実行を実施して集約するパラレルスケーリングです。彼らは、ReActスタイルのループに従って検索およびブラウズツールを備えた検索エージェントで実験を行いました。ReAct（Reasoning + Acting）は、モデルが内部思考と外部アクションを交互に行う一般的な方法です。真のコストパフォーマンスのスケーリング傾向を追跡するために、内部トークン消費と外部ツールインタラクションの両方のコストを共同で考慮する統一されたコストメトリックを開発しました。</p><p>彼らは、<a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>、Gemini 2.5 Flash、および<a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>などのモデルを使用して、外部検索を必要とするBrowseCompやHLE-Searchを含む3つの情報検索QAデータセットでBudget Trackerをテストしました。実験結果は、このシンプルなプラグインがさまざまな予算制約にわたってパフォーマンスを向上させることを示しています。</p><p>著者らはVentureBeatに対し、「Budget Trackerを追加すると、検索呼び出しが40.4％、ブラウズ呼び出しが19.9％減少し、全体的なコストが31.3％削減され、同等の精度が得られます」と述べています。最後に、Budget Trackerは予算が増加するにつれてスケーリングを継続しましたが、プレーンなReActはあるしきい値を超えると停滞しました。</p><h2>BATS：予算を意識したスケーリングのための包括的なフレームワーク</h2><p>ツール利用のリソース最適化をさらに改善するために、研究者らはBudget Aware Test-time Scaling（BATS）を導入しました。これは、特定された予算の下でエージェントのパフォーマンスを最大化するように設計されたフレームワークです。BATSは、残りのリソースの継続的なシグナルを維持し、この情報を使用して、エージェントが応答を策定する際に動的にその動作を適応させます。</p><p>BATSは、複数のモジュールを使用してエージェントのアクションを調整します。計画モジュールは、ステップごとの労力を現在の予算に合わせて調整し、検証モジュールは、リソースの利用可能性に基づいて、有望な手がかりを「より深く掘り下げる」か、代替パスに「ピボット」するかを決定します。</p><p>情報検索の質問とツール呼び出しの予算が与えられた場合、BATSは最初に計画モジュールを使用して、構造化されたアクションプランを策定し、どのツールを呼び出すかを決定します。ツールが呼び出されると、その応答が推論シーケンスに追加され、新しい証拠とともにコンテキストが提供されます。エージェントが候補の回答を提案すると、検証モジュールはそれを検証し、現在のシーケンスを続行するか、残りの予算で新しい試行を開始するかを決定します。</p><p>予算化されたリソースが使い果たされると、反復プロセスが終了し、その時点でLLMとしてのジャッジがすべての検証済み回答の中から最良の回答を選択します。実行全体を通して、Budget Trackerはすべて反復でリソースの使用量と残りの予算の両方を継続的に更新します。</p><p>研究者らは、BrowseComp、BrowseComp-ZH、およびHLE-Searchベンチマークで、標準のReActやさまざまなトレーニングベースのエージェントを含むベースラインに対してBATSをテストしました。彼らの実験結果は、BATSが、競合する方法よりも少ないツール呼び出しを使用し、全体的なコストを低く抑えながら、より高いパフォーマンスを達成することを示しています。バックボーンとしてGemini 2.5 Proを使用すると、BATSはBrowseCompで24.6％の精度を達成しましたが、標準のReActでは12.6％であり、HLE-Searchでは27.0％でしたが、ReActでは20.5％でした。</p><p>BATSは、予算制約下での有効性を向上させるだけでなく、より優れたコストパフォーマンスのトレードオフも実現します。たとえば、BrowseCompデータセットでは、BATSは約23セントのコストでより高い精度を達成しましたが、パラレルスケーリングベースラインでは、同様の結果を達成するために50セント以上が必要でした。</p><p>著者らによると、この効率により、これまで高価だったワークフローが実行可能になります。彼らは、「これは、複雑なコードベースの保守、デューデリジェンス調査、競争環境調査、コンプライアンス監査、および複数ステップのドキュメント分析など、長期にわたるデータ集約型のエンタープライズアプリケーションの範囲を解放します」と述べています。</p><p>企業が独自のリソースを管理するエージェントの展開を検討するにつれて、精度とコストのバランスをとる能力が重要な設計要件になります。</p><p>ワン氏とリュウ氏は、「推論と経済学の関係は不可分になると信じています」と述べています。「将来的には、[モデル]は価値について推論する必要があります。」</p>",
    "insightJa": "この技術により、企業はAIエージェントの利用コストを最適化し、より複雑なタスクへの応用が期待できます。AIがビジネスの意思決定や業務効率化に貢献する可能性が広がりますね。",
    "recommendedBooks": [
      "AIエージェント",
      "LLM 活用",
      "AI コスト削減"
    ],
    "tags": [
      "AI Agents",
      "LLM",
      "Cost Optimization",
      "Budget Aware Scaling",
      "Tool Use"
    ],
    "imageUrl": "https://images.pexels.com/photos/30839686/pexels-photo-30839686.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "6h3LTzDwRwKFT22aRVaumY",
    "title": "GPT-5.2 first impressions: a powerful update, especially for business tasks and workflows",
    "source": "rss",
    "url": "https://venturebeat.com/ai/gpt-5-2-first-impressions-a-powerful-update-especially-for-business-tasks",
    "summary": "OpenAI has officially released GPT-5.2, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming \"incremental\" update for casual conversationalists.\nFollowing early access periods and today's broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. \nHere is a roundup of the first reactions to OpenAI’s latest flagship model.\n\"AI as a serious analyst\"\nThe strongest praise for GPT-5.2 centers on its ability to handle \"hard problems\" that require extended thinking time.\nMatt Shumer, CEO of HyperWriteAI, did not mince words in his review, calling GPT-5.2 Pro \"the best model in the world.\" \nShumer highlighted the model's tenacity, noting that \"it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.\"\nThis sentiment was echoed by Allie K. Miller, an AI entrepreneur and former AWS executive. Miller described the model as a step toward \"AI as a serious analyst\" rather than a \"friendly companion.\"\n\"The thinking and problem-solving feel noticeably stronger,\" Miller wrote on X. \"It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.\"\nEnterprise gains: Box reports distinct performance jumps\nFor the enterprise sector, the update appears to be even more significant. \nAaron Levie, CEO of Box, revealed on X that his company has been testing GPT-5.2 in early access. Levie reported that the model performs \"7 points better than GPT-5.1\" on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.\n\"The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,\" Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.\nRutuja Rajwade, a Senior Product Marketing Manager at Box, expanded on this in a company blog post, citing specific latency improvements. \n\"Complex extraction\" tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. \nRajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.\nA \"serious leap\" for coding and simulation\nDevelopers are finding GPT-5.2 particularly potent for \"one-shot\" generation of complex code structures.\nPietro Schirano, CEO of magicpathai, shared a video of the model building a full 3D graphics engine in a single file with interactive controls. \"It’s a serious leap forward in complex reasoning, math, coding, and simulations,\" Schirano posted. \"The pace of progress is unreal.\"\n\nSimilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, demonstrated the model's ability to create a visually complex shader—an infinite neo-gothic city in a stormy ocean—via a single prompt.\nThe Agentic Era: Long-running autonomy\nPerhaps the most functional shift is the model's ability to stay on task for hours without losing the thread.\nDan Shipper, CEO of thoughtful AI testing newsletter Every, reported that the model successfully performed a profit and loss (P&L) analysis that required it to work autonomously for two hours. \"It did a P&L analysis where it worked for 2 hours and gave me great results,\" Shipper wrote.\nHowever, Shipper also noted that for day-to-day tasks, the update feels \"mostly incremental.\" \nIn an article for Every, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is \"less resourceful\" than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user's location from email data.\nThe downsides: Speed and Rigidity\nDespite the reasoning capabilities, the \"feel\" of the model has drawn critique.\nShumer highlighted a significant \"speed penalty\" when using the model's Thinking mode. \"In my experience the Thinking mode is very slow for most questions,\" Shumer wrote in his deep-dive review. \"I almost never use Instant.\"\nAllie Miller also pointed out issues with the model's default behavior. \"The downside is tone and format,\" she noted. \"The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.\"\nThe Verdict\nThe early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: \"For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.\"\nHowever, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. \"My favorite model remains Claude Opus 4.5,\" Miller admitted, \"but my complex ChatGPT work will get a nice incremental boost.\"",
    "publishedAt": "Thu, 11 Dec 2025 23:26:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>OpenAI has officially <a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">released GPT-5.2</a>, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming &quot;incremental&quot; update for casual conversationalists.</p><p>Following early access periods and today&#x27;s broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. </p><p>Here is a roundup of the first reactions to OpenAI’s latest flagship model.</p><h3><b>&quot;AI as a serious analyst&quot;</b></h3><p>The strongest praise for GPT-5.2 centers on its ability to handle &quot;hard problems&quot; that require extended thinking time.</p><p>Matt Shumer, CEO of HyperWriteAI, did not mince words in <a href=\"https://shumer.dev/gpt52review\">his review</a>, calling GPT-5.2 Pro &quot;the best model in the world.&quot; </p><p>Shumer highlighted the model&#x27;s tenacity, noting that &quot;it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.&quot;</p><p>This sentiment was<a href=\"https://x.com/alliekmiller/status/1999189893910790427\"> echoed by Allie K. Miller</a>, an AI entrepreneur and former AWS executive. Miller described the model as a step toward &quot;AI as a serious analyst&quot; rather than a &quot;friendly companion.&quot;</p><p>&quot;The thinking and problem-solving feel noticeably stronger,&quot; Miller wrote on X. &quot;It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.&quot;</p><h3><b>Enterprise gains: Box reports distinct performance jumps</b></h3><p>For the enterprise sector, the update appears to be even more significant. </p><p><a href=\"https://x.com/levie/status/1999191612321391058\">Aaron Levie, CEO of Box, revealed on X</a> that his company has been testing GPT-5.2 in early access. Levie reported that the model performs &quot;7 points better than GPT-5.1&quot; on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.</p><p>&quot;The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,&quot; Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.</p><p>Rutuja Rajwade, a Senior Product Marketing Manager at Box, <a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">expanded on this in a company blog post</a>, citing specific latency improvements. </p><p>&quot;Complex extraction&quot; tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. </p><p>Rajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.</p><h3><b>A &quot;serious leap&quot; for coding and simulation</b></h3><p>Developers are finding GPT-5.2 particularly potent for &quot;one-shot&quot; generation of complex code structures.</p><p>Pietro Schirano, CEO of magicpathai, <a href=\"https://x.com/skirano/status/1999182295685644366\">shared a video </a>of the model building a full 3D graphics engine in a single file with interactive controls. &quot;It’s a serious leap forward in complex reasoning, math, coding, and simulations,&quot; Schirano posted. &quot;The pace of progress is unreal.&quot;</p><div></div><p>S<!-- -->imilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, <a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">demonstrated the model&#x27;s ability to create a visually complex shader</a>—an infinite neo-gothic city in a stormy ocean—via a single prompt.</p><h3><b>The Agentic Era: Long-running autonomy</b></h3><p>Perhaps the most functional shift is the model&#x27;s ability to stay on task for hours without losing the thread.</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">Dan Shipper, CEO of thoughtful AI testing newsletter Every</a>, reported that the model successfully performed a profit and loss (P&amp;L) analysis that required it to work autonomously for two hours. &quot;It did a P&amp;L analysis where it worked for 2 hours and gave me great results,&quot; Shipper wrote.</p><p>However, Shipper also noted that for day-to-day tasks, the update feels &quot;mostly incremental.&quot; </p><p>In <a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">an article for Every</a>, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is &quot;less resourceful&quot; than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user&#x27;s location from email data.</p><h3><b>The downsides: Speed and Rigidity</b></h3><p>Despite the reasoning capabilities, the &quot;feel&quot; of the model has drawn critique.</p><p>Shumer highlighted a significant &quot;speed penalty&quot; when using the model&#x27;s Thinking mode. &quot;In my experience the Thinking mode is very slow for most questions,&quot; Shumer wrote in his deep-dive review. &quot;I almost never use Instant.&quot;</p><p>Allie Miller also pointed out issues with the model&#x27;s default behavior. &quot;The downside is tone and format,&quot; she noted. &quot;The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.&quot;</p><h3><b>The Verdict</b></h3><p>The early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: &quot;For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.&quot;</p><p>However, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. &quot;My favorite model remains Claude Opus 4.5,&quot; Miller admitted, &quot;but my complex ChatGPT work will get a nice incremental boost.&quot;</p>",
    "titleJa": "GPT-5.2の第一印象：特にビジネス用途とワークフローにおいて強力なアップデート",
    "summaryJa": "GPT-5.2は、深い推論とコーディング能力が大幅に向上。ビジネス分野では性能向上が顕著だが、カジュアルな会話用途では変化は少ないとの評価。",
    "explanationJa": "GPT-5.2は、複雑な問題解決やコーディング能力が向上したモデルで、ビジネスでの活用が期待されます。",
    "translationJa": "<p>OpenAIは正式に<a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">GPT-5.2をリリース</a>しました。早期テスターからの反応（OpenAIは一般公開の数日前、場合によっては数週間前にモデルをテスト目的で提供していました）は二面性を示しています。それは、深遠な自律的推論とコーディングにおいては記念碑的な飛躍ですが、カジュアルな会話者にとっては「漸進的な」アップデートに過ぎない可能性があります。</p><p>早期アクセス期間と本日のより広範な展開に続き、役員、開発者、アナリストがX（旧Twitter）や企業のブログで最初のテスト結果を共有しています。</p><p>OpenAIの最新フラッグシップモデルに対する最初の反応をまとめました。</p><h3><b>「真面目なアナリストとしてのAI」</b></h3><p>GPT-5.2に対する最も強い称賛は、「困難な問題」に対処する能力、つまり長時間の思考時間を必要とする能力に集中しています。</p><p>HyperWriteAIのCEOであるマット・シューマー氏は、<a href=\"https://shumer.dev/gpt52review\">彼のレビュー</a>で率直に意見を述べ、GPT-5.2 Proを「世界最高のモデル」と呼びました。</p><p>シューマー氏はモデルの粘り強さを強調し、「**1時間以上**も困難な問題について考えます。そして、他のモデルでは対応できないタスクをこなします」と述べています。</p><p>この意見は、AI起業家であり、元AWS幹部である<a href=\"https://x.com/alliekmiller/status/1999189893910790427\">アリー・K・ミラー氏</a>も同調しています。ミラー氏は、このモデルを「友好的なコンパニオン」ではなく、「真面目なアナリストとしてのAI」への一歩だと表現しました。</p><p>「思考と問題解決は著しく強化されていると感じます」とミラー氏はXに書いています。「私が見慣れているよりもはるかに深い説明をしてくれます。ある時には、タスクの途中で自身のOCRを改善するためのコードを文字通り書いていました。」</p><h3><b>エンタープライズ分野での進歩：Boxが明確なパフォーマンス向上を報告</b></h3><p>エンタープライズセクターにとって、このアップデートはさらに重要な意味を持つようです。</p><p><a href=\"https://x.com/levie/status/1999191612321391058\">BoxのCEOであるアーロン・レヴィ氏はXで明らかにしました</a>。彼の会社は早期アクセスでGPT-5.2をテストしています。レヴィ氏は、金融サービスやライフサイエンスにおける現実世界の知識労働を近似した拡張された推論テストにおいて、モデルが「GPT-5.1よりも7ポイント優れている」と報告しました。</p><p>「このモデルは、GPT-5.1やGPT-5よりもはるかに高速にタスクの大半を実行しました」とレヴィ氏は述べ、Box AIがGPT-5.2の統合を間もなく展開することを確認しました。</p><p>Boxのシニアプロダクトマーケティングマネージャーであるルツジャ・ラジュワデ氏は、<a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">会社のブログ記事でこれを詳しく説明し</a>、具体的なレイテンシの改善を挙げています。</p><p>「複雑な抽出」タスクは、GPT-5では46秒かかっていたものが、GPT-5.2ではわずか12秒に短縮されました。</p><p>ラジュワデ氏はまた、メディアおよびエンターテインメント分野における推論能力の向上を指摘し、GPT-5.1の76％の精度から、新しいモデルでは81％に向上しました。</p><h3><b>コーディングとシミュレーションにおける「重大な飛躍」</b></h3><p>開発者は、GPT-5.2が複雑なコード構造の「ワンショット」生成に特に有効であると考えています。</p><p>magicpathaiのCEOであるピエトロ・シラーノ氏は、<a href=\"https://x.com/skirano/status/1999182295685644366\">インタラクティブなコントロールを備えた完全な3Dグラフィックスエンジンを単一のファイルで構築するモデルのビデオを共有しました</a>。「複雑な推論、数学、コーディング、シミュレーションにおいて重大な飛躍です」とシラーノ氏は投稿しました。「進歩のペースは非現実的です。」</p><div></div><p>同様に、ペンシルベニア大学ウォートン・スクールの教授であり、長年のLLMおよびAIパワーユーザー兼ライターであるイーサン・モリック氏は、<a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">モデルが視覚的に複雑なシェーダー（嵐の海の無限のネオゴシック都市）を単一のプロンプトで作成する能力を実証しました</a>。</p><h3><b>エージェント時代の到来：長期間の自律性</b></h3><p>おそらく最も機能的な変化は、モデルが途切れることなく何時間もタスクを継続できる能力でしょう。</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">思慮深いAIテストニュースレターEveryのCEOであるダン・シッパー氏</a>は、モデルが2時間自律的に動作する必要がある損益（P＆L）分析を正常に実行したと報告しました。「2時間かけて損益分析を行い、素晴らしい結果を出してくれました」とシッパー氏は書いています。</p><p>ただし、シッパー氏はまた、日々のタスクでは、アップデートは「ほとんど漸進的」に感じられると指摘しました。</p><p><a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">Everyの記事</a>で、ケイティ・パロット氏は、GPT-5.2は指示に従うことには優れているものの、ユーザーの場所をメールデータから推測するなど、特定のコンテキストではClaude Opus 4.5のような競合他社よりも「機転が利かない」と書いています。</p><h3><b>短所：速度と硬直性</b></h3><p>推論能力にもかかわらず、モデルの「感触」は批判を呼んでいます。</p><p>シューマー氏は、モデルの思考モードを使用すると、大幅な「速度のペナルティ」が発生することを強調しました。「私の経験では、思考モードはほとんどの質問に対して非常に遅いです」とシューマー氏は詳細なレビューで書いています。「私はほとんどインスタントを使いません。」</p><p>アリー・ミラー氏も、モデルのデフォルトの動作に問題があると指摘しました。「短所はトーンとフォーマットです」と彼女は述べました。「デフォルトの声は少し硬直的に感じられ、長さ/マークダウンの動作は極端です。単純な質問が58個の箇条書きと番号付きポイントになりました。」</p><h3><b>結論</b></h3><p>初期の反応は、GPT-5.2がカジュアルなチャットよりも、パワーユーザー、開発者、およびエンタープライズエージェント向けに最適化されたツールであることを示唆しています。シューマー氏がレビューで要約したように、「深い調査、複雑な推論、および注意深い思考から恩恵を受けるタスクにとって、GPT-5.2 Proは現在利用可能な最良のオプションです。」</p><p>ただし、クリエイティブな文章や迅速で流動的な回答を求めるユーザーにとっては、Claude Opus 4.5のようなモデルが依然として強力な競争相手です。「私のお気に入りのモデルはClaude Opus 4.5のままです」とミラー氏は認めました。「しかし、私の複雑なChatGPTの作業は、素晴らしい漸進的な後押しを受けるでしょう。」</p>",
    "insightJa": "GPT-5.2の登場により、ビジネスにおけるAIの活用がさらに進みそうです。特に専門的な知識や複雑な分析が求められる業務では、業務効率化や新たな価値創造に貢献することが期待されます。",
    "recommendedBooks": [
      "GPT-5.2 ビジネス活用",
      "大規模言語モデル エンタープライズ",
      "AI 推論 エンジニアリング"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "AI",
      "ビジネス",
      "自然言語処理"
    ],
    "imageUrl": "https://images.pexels.com/photos/16629368/pexels-photo-16629368.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10957v1",
    "title": "SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10957v1",
    "summary": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "publishedAt": "2025-12-11T18:59:56Z",
    "author": "Yukai Shi",
    "category": "AI",
    "originalContent": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "titleJa": "SceneMaker: 分離された隠蔽除去と姿勢推定モデルによるオープンセット3Dシーン生成",
    "summaryJa": "本研究ではSceneMakerという分離型3Dシーン生成フレームワークを提案。既存手法の課題を克服するため、隠蔽除去モデルを3Dオブジェクト生成から分離し、姿勢推定モデルを改善。オープンセット3Dシーンデータセットも構築。",
    "explanationJa": "SceneMakerは、3Dシーンをより自然に生成するための新しい技術で、様々な場面で活用が期待されます。",
    "translationJa": "本研究では、SceneMakerと呼ばれる分離型3Dシーン生成フレームワークを提案します。既存の手法は、十分なオープンセットの隠蔽除去と姿勢推定の事前知識が不足しているため、深刻な遮蔽とオープンセット設定下で高品質なジオメトリと正確な姿勢を同時に生成するのに苦労しています。これらの問題に対処するために、まず、隠蔽除去モデルを3Dオブジェクト生成から分離し、画像データセットと収集された隠蔽除去データセットを活用して、より多様なオープンセットの遮蔽パターンに対応できるよう強化します。次に、自己注意と交差注意の両方に対してグローバルおよびローカルのメカニズムを統合した、統一された姿勢推定モデルを提案し、精度を向上させます。さらに、姿勢推定モデルの汎化性能を向上させるために、オープンセット3Dシーンデータセットを構築します。包括的な実験により、屋内シーンとオープンセットシーンの両方で、提案する分離型フレームワークの優位性が実証されています。コードとデータセットはhttps://idea-research.github.io/SceneMaker/で公開されています。",
    "insightJa": "この技術により、ゲームや映画制作における3Dモデルの作成が効率化され、よりリアルな仮想空間の構築が容易になると考えられます。また、自動運転やロボット工学などの分野においても、周囲の状況認識能力向上に貢献する可能性があります。",
    "recommendedBooks": [
      "3Dモデリング 理論",
      "画像認識 最新",
      "コンピュータビジョン 実践"
    ],
    "tags": [
      "3D scene generation",
      "de-occlusion",
      "pose estimation",
      "open-set learning",
      "SceneMaker"
    ],
    "imageUrl": "https://images.pexels.com/photos/8347500/pexels-photo-8347500.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10952v1",
    "title": "Hierarchical Dataset Selection for High-Quality Data Sharing",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10952v1",
    "summary": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Xiaona Zhou",
    "category": "AI",
    "originalContent": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "titleJa": "高品質データ共有のための階層的データセット選択",
    "summaryJa": "機械学習の成功は高品質な学習データに依存。DaSHは、データセットとグループレベルで有用性をモデル化し、限られた観測から効率的な汎化を実現、既存手法を大幅に上回る。",
    "explanationJa": "高品質なデータセットを効率的に選択することで、機械学習の精度を向上させる新しい手法が開発されました。",
    "translationJa": "現代の機械学習の成功は、高品質な学習データへのアクセスにかかっています。公共リポジトリからのデータ取得や、複数の機関を跨いでのデータ共有など、多くの現実世界のシナリオでは、データは本質的に離散的なデータセットとして組織化され、関連性、品質、有用性においてばらつきがあります。したがって、有用なデータセットを検索するためにどのリポジトリまたは機関を選択するか、そしてどのデータセットをモデルの学習に組み込むかを決定することは非常に重要な判断です。しかし、既存のほとんどの手法は個々のサンプルを選択し、すべてのデータを等しく関連性があるものとして扱い、データセットとそのソース間の違いを無視しています。本研究では、データセット選択のタスクを形式化し、大規模で異質なプールからデータセット全体を選択して、リソース制約下でのダウンストリームのパフォーマンスを向上させることを目指します。我々は、データセットとグループ（例：コレクション、機関）の両方のレベルで有用性をモデル化するデータセット選択手法であるDaSH（Dataset Selection via Hierarchies）を提案し、限られた観測からの効率的な汎化を可能にします。2つの公開ベンチマーク（Digit-FiveとDomainNet）において、DaSHは最先端のデータ選択ベースラインを最大26.2%精度で上回り、探索ステップ数も大幅に削減しました。アブレーション実験の結果、DaSHは低リソース環境や関連データセットの欠如にも強く、実用的なマルチソース学習ワークフローにおけるスケーラブルで適応的なデータセット選択に適していることが示されました。",
    "insightJa": "この技術は、企業が持つ膨大なデータの中から、本当に価値のあるデータを選び出す手助けとなります。これにより、AIモデルの精度が向上し、より効率的なビジネス判断や新しいサービスの開発につながる可能性があります。",
    "recommendedBooks": [
      "機械学習 実践",
      "データサイエンス 入門",
      "深層学習 理論"
    ],
    "tags": [
      "Machine Learning",
      "Dataset Selection",
      "Data Quality",
      "Hierarchical Learning",
      "機械学習"
    ],
    "imageUrl": "https://images.pexels.com/photos/8294824/pexels-photo-8294824.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10949v1",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10949v1",
    "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "publishedAt": "2025-12-11T18:59:52Z",
    "author": "Yiwen Tang",
    "category": "AI",
    "originalContent": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "titleJa": "テキストからの3D生成における強化学習の準備はできているか？進歩的な調査",
    "summaryJa": "テキストから3Dモデルを生成する際に、強化学習を適用する研究。報酬設計、アルゴリズム、ベンチマーク、階層的アプローチを調査し、RL強化モデルAR3D-R1を開発。",
    "explanationJa": "テキストから3Dモデルを生成する技術に、強化学習を導入するための研究が進められているようです。",
    "translationJa": "強化学習（RL）は、大規模言語モデルやマルチモーダルモデルにおいて有効であることが以前に証明されており、最近では2D画像生成を強化するために拡張されて成功を収めています。しかし、3D生成へのRLの適用は、3Dオブジェクトの空間的複雑さが高いため、ほとんど探求されていません。3Dオブジェクトは、グローバルに一貫した形状と、きめ細かいローカルテクスチャを必要とします。これにより、3D生成は報酬設計とRLアルゴリズムに著しく影響を受けやすくなります。これらの課題に対処するために、テキストから3Dへの自己回帰生成に対するRLの最初の体系的な研究をいくつかの側面から実施します。(1) 報酬設計: 報酬の次元とモデルの選択肢を評価し、人間の好みに合わせることが重要であること、および一般的なマルチモーダルモデルが3D属性に対して堅牢な信号を提供することを示します。(2) RLアルゴリズム: GRPOバリアントを調査し、トークンレベルの最適化の有効性を強調し、トレーニングデータと反復のスケーリングをさらに調査します。(3) テキストから3Dへのベンチマーク: 既存のベンチマークは3D生成モデルにおける暗黙的な推論能力を測定できないため、MME-3DRを導入します。(4) 高度なRLパラダイム: 3D生成の自然な階層構造に触発されて、専用の報酬アンサンブルを通じてグローバルからローカルへの階層的3D生成を最適化するHi-GRPOを提案します。これらの洞察に基づいて、粗い形状からテクスチャの洗練までを専門とする、最初のRL強化テキストから3DモデルであるAR3D-R1を開発します。この研究が、3D生成のためのRL駆動型推論への洞察を提供することを願っています。コードはhttps://github.com/Ivan-Tang-3D/3DGen-R1で公開されています。",
    "insightJa": "この研究が進むと、ゲームや映画などのエンターテインメント業界における3Dモデリングの効率化や、製品デザインにおける試作プロセスの迅速化が期待できます。さらに、教育分野における教材作成や、建築設計の分野にも応用される可能性があります。",
    "recommendedBooks": [
      "3Dモデリング 入門",
      "強化学習 実践",
      "画像生成AI"
    ],
    "tags": [
      "Reinforcement Learning",
      "Text-to-3D",
      "3D Generation",
      "AR3D-R1",
      "Hi-GRPO"
    ],
    "imageUrl": "https://images.pexels.com/photos/17483874/pexels-photo-17483874.png?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "5AH2xqcQJzMolV09W5VM43",
    "title": "OpenAI's GPT-5.2 is here: what enterprises need to know",
    "source": "rss",
    "url": "https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know",
    "summary": "The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, GPT-5.2.\nIt comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival Google’s Gemini 3 LLM seized the top spot on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.\nOpenAI describes GPT-5.2 as its \"most capable model series yet for professional knowledge work,\" aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.\n\"It’s our most advanced frontier model and the strongest yet in the market for professional use,\" Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. \"We designed 5.2 to unlock even more economic value for people. It's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.\"\nGPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.\nThe model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes \"Reasoning token support,\" confirming the underlying architecture uses the chain-of-thought processing popularized by the \"o1\" series.\nThe 'Code Red' Reality Check\nThe release arrives following The Information's report of an emergency \"Code Red\" directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the \"quality gap\" exposed by Gemini 3. The Verge similarly reported on the timing of GPT-5.2's release ahead of the official announcement. \nDuring the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.\n\"It is important to note this has been in the works for many, many months,\" Simo told reporters. She clarified that while the \"Code Red\" helped focus the company, it wasn't the sole driver of the timeline. \n\"We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that's not the reason it's coming out this week in particular.\"\nMax Schwarzer, lead of OpenAI's post-training team, echoed this sentiment to dispel the idea of a panic launch. \"We've been planning for this release since a very long time ago... this specific week we talked about many months ago.\"\nA spokesperson from OpenAI further clarified that the \"Code Red\" call applied to ChatGPT as a product, not solely underlying model development or the release of new models.\nUnder the Hood: Instant, Thinking, and Pro\nOpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of \"reasoning\" models with user demand for speed:\n\nGPT-5.2 Instant: Optimized for speed and daily tasks like writing, translation, and information seeking.\n\nGPT-5.2 Thinking: Designed for \"complex, structured work\" and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.\n\nGPT-5.2 Pro: The new heavyweight champion. OpenAI describes this as its \"smartest and most trustworthy option,\" delivering the highest accuracy for difficult questions where quality outweighs latency.\n\nFor developers, the models are available immediately in the application programming interface (API) as gpt-5.2, gpt-5.2-chat-latest (Instant), and gpt-5.2-pro.\nThe Numbers: Beating the Benchmarks\nThe GPT-5.2 release includes leading metrics across most domains — specifically those that target the \"professional knowledge work\" gap where competitors have recently gained ground.\nOpenAI highlighted a new benchmark called GDPval, which measures performance on \"well-specified knowledge work tasks\" across 44 occupations. \n\"GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,\" Simo said.\nIn the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. \nHe emphasized that this benchmark is \"more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.\"Other key benchmark results include:\n\nGPQA Diamond (Science): GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).\n\nFrontierMath: On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.\n\nARC-AGI-1: GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring 90.5%\n\nThe Price of Intelligence\nPerformance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of \"thinking\" mode. They're also on the upper-end of API costs for the industry.  \n\nGPT-5.2 Thinking: Priced at $1.75 per 1 million input tokens and $14 per 1 million output tokens.\n\nGPT-5.2 Pro: The costs jump significantly to $21 per 1 million input tokens and $168 per 1 million output tokens.\n\nGPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.\nThe high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.\nOpenAI argues that despite the higher per-token cost, the model’s \"greater token efficiency\" and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.\nHere's how it compares to the current API costs for other competing models across the LLM field:\n\n\nModel\n\nInput (/1M)\n\nOutput (/1M)\n\nTotal Cost\n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nQwen 3 Plus\n\n$0.40\n\n$1.20\n\n$1.60\n\nAlibaba Cloud\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen-Max\n\n$1.60\n\n$6.40\n\n$8.00\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nClaude Opus 4.5\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nImage Generation: Nothing New Yet...But 'More to Come'\nDuring the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google's Gemini 3 Image aka Nano Banana Pro. \nUnfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI's integrated DALL-E 3 and gpt-4o native image generation models.\n\"On image Gen, nothing to announce today, but more to come,\" Simo said. She acknowledged the popularity of the feature, adding, \"We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.\" \nAidan Clark, OpenAI's lead of training, also declined to comment on visual generation specifics, stating simply, \"I can't really speak to image Gen myself.\" \nThe 'Mega-Agent' Era\nBeyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of \"long-running agents\" capable of executing multi-step workflows without human hand-holding.\"\nBox found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,\" Simo said. \nShe also noted that Notion reported the model \"outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.\"Schwarzer added that coding startups like Augment Code found the model \"delivered substantially stronger deep code capabilities than any prior model,\" which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. \nOpenAI's release blog post shows an example where \"a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.\"\nThe outcome? \"GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.\"\nA new evaluation called ScreenSpot-Pro, which tests a model's ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.\nScience and Reliability\nOpenAI leaders also stressed the model's utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. \nAidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.\n\"They tested it by asking it to generate the most important unanswered questions about the immune system,\" Clark said. \"That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.\n\"Reliability was another key focus. Schwarzer claimed the new model \"hallucinates substantially less than GPT-5.1,\" noting that on a set of de-identified queries, \"responses contained errors 38% less often.\"\nThe 'Vibe' Shift\nInterestingly, OpenAI acknowledged that not every user might immediately prefer the new models. \nWhen asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that \"models change a little bit every time.\n\"Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,\" Schwarzer said. He also noted that for some enterprise customers who have \"really fine-tuned a prompt for a specific model,\" there might be \"small regressions,\" necessitating access to the older versions.\nSafety, 'Adult Mode,' and Future Roadmap\nAddressing safety concerns, Simo confirmed that the company is preparing to roll out an \"Adult Mode\" in the first quarter of next year, following the implementation of a new age prediction system.\n\"We're in the process of improving that,\" Simo said regarding the age prediction technology. \n\"We want to do that ahead of launching adult mode.\"Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename \"Project Garlic,\" targeting a flagship release in early 2026. \nWhile executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.\n\"If you look at historical trends, compute has increased about 3x every year for the last three years,\" she explained. \"Revenue has also increased at the same pace... creating this virtuous cycle.\"\nClark added that efficiency is improving rapidly: \"The model we're releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it\" compared to models from a year ago.\nGPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.",
    "publishedAt": "Thu, 11 Dec 2025 18:16:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, <a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>.</p><p>It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival <a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">Google’s Gemini 3 LLM seized the top spot</a> on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.</p><p>OpenAI describes GPT-5.2 as its &quot;most capable model series yet for professional knowledge work,&quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.</p><p>&quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &quot;We designed 5.2 to unlock even more economic value for people. It&#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&quot;</p><p>GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.</p><p>The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &quot;Reasoning token support,&quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &quot;o1&quot; series.</p><h3><b>The &#x27;Code Red&#x27; Reality Check</b></h3><p>The release arrives following<i> </i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\"><i>The Information</i>&#x27;s report</a> of an emergency &quot;Code Red&quot; directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the &quot;quality gap&quot; exposed by Gemini 3.<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i> The Verge</i></a> similarly reported on the timing of GPT-5.2&#x27;s release ahead of the official announcement. </p><p>During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.</p><p>&quot;It is important to note this has been in the works for many, many months,&quot; Simo told reporters. She clarified that while the &quot;Code Red&quot; helped focus the company, it wasn&#x27;t the sole driver of the timeline. </p><p>&quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&#x27;s not the reason it&#x27;s coming out this week in particular.&quot;</p><p>Max Schwarzer, lead of OpenAI&#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &quot;We&#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&quot;</p><p>A spokesperson from OpenAI further clarified that the &quot;Code Red&quot; call applied to ChatGPT as a product, not solely underlying model development or the release of new models.</p><h3><b>Under the Hood: Instant, Thinking, and Pro</b></h3><p>OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &quot;reasoning&quot; models with user demand for speed:</p><ul><li><p><b>GPT-5.2 Instant:</b> Optimized for speed and daily tasks like writing, translation, and information seeking.</p></li><li><p><b>GPT-5.2 Thinking:</b> Designed for &quot;complex, structured work&quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.</p></li><li><p><b>GPT-5.2 Pro:</b> The new heavyweight champion. OpenAI describes this as its &quot;smartest and most trustworthy option,&quot; delivering the highest accuracy for difficult questions where quality outweighs latency.</p></li></ul><p>For developers, the models are available immediately in the application programming interface (API) as <code>gpt-5.2</code>, <code>gpt-5.2-chat-latest</code> (Instant), and <code>gpt-5.2-pro</code>.</p><h3><b>The Numbers: Beating the Benchmarks</b></h3><p>The GPT-5.2 release includes leading metrics across most domains — specifically those that target the &quot;professional knowledge work&quot; gap where competitors have recently gained ground.</p><p>OpenAI highlighted a new benchmark called GDPval, which measures performance on &quot;well-specified knowledge work tasks&quot; across 44 occupations. </p><p>&quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&quot; Simo said.</p><p>In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. </p><p>He emphasized that this benchmark is &quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&quot;Other key benchmark results include:</p><ul><li><p><b>GPQA Diamond (Science):</b> GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).</p></li><li><p><b>FrontierMath:</b> On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.</p></li><li><p><b>ARC-AGI-1:</b> GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring <b>90.5%</b></p></li></ul><h3><b>The Price of Intelligence</b></h3><p>Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &quot;thinking&quot; mode. They&#x27;re also on the upper-end of API costs for the industry.  </p><ul><li><p><b>GPT-5.2 Thinking:</b> Priced at <b>$1.75</b> per 1 million input tokens and <b>$14</b> per 1 million output tokens.</p></li><li><p><b>GPT-5.2 Pro:</b> The costs jump significantly to <b>$21</b> per 1 million input tokens and <b>$168</b> per 1 million output tokens.</p></li></ul><p>GPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.</p><p>The high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.</p><p>OpenAI argues that despite the higher per-token cost, the model’s &quot;greater token efficiency&quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.</p><p>Here&#x27;s how it compares to the current API costs for other competing models across the LLM field:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1M)</b></p></td><td><p><b>Output (/1M)</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>Image Generation: Nothing New Yet...But &#x27;More to Come&#x27;</b></h3><p>During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&#x27;s Gemini 3 Image aka Nano Banana Pro. </p><p>Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&#x27;s integrated DALL-E 3 and gpt-4o native image generation models.</p><p>&quot;On image Gen, nothing to announce today, but more to come,&quot; Simo said. She acknowledged the popularity of the feature, adding, &quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&quot; </p><p>Aidan Clark, OpenAI&#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &quot;I can&#x27;t really speak to image Gen myself.&quot; </p><h3><b>The &#x27;Mega-Agent&#x27; Era</b></h3><p>Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &quot;long-running agents&quot; capable of executing multi-step workflows without human hand-holding.&quot;</p><p>Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&quot; Simo said. </p><p>She also noted that Notion reported the model &quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&quot;Schwarzer added that coding startups like Augment Code found the model &quot;delivered substantially stronger deep code capabilities than any prior model,&quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. </p><p>OpenAI&#x27;s release blog post shows an example where &quot;a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.&quot;</p><p>The outcome? &quot;GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.&quot;</p><p>A new evaluation called ScreenSpot-Pro, which tests a model&#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.</p><h3><b>Science and Reliability</b></h3><p>OpenAI leaders also stressed the model&#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. </p><p>Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.</p><p>&quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&quot; Clark said. &quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.</p><p>&quot;Reliability was another key focus. Schwarzer claimed the new model &quot;hallucinates substantially less than GPT-5.1,&quot; noting that on a set of de-identified queries, &quot;responses contained errors 38% less often.&quot;</p><h3><b>The &#x27;Vibe&#x27; Shift</b></h3><p>Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. </p><p>When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &quot;models change a little bit every time.</p><p>&quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&quot; Schwarzer said. He also noted that for some enterprise customers who have &quot;really fine-tuned a prompt for a specific model,&quot; there might be &quot;small regressions,&quot; necessitating access to the older versions.</p><h3><b>Safety, &#x27;Adult Mode,&#x27; and Future Roadmap</b></h3><p>Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &quot;Adult Mode&quot; in the first quarter of next year, following the implementation of a new age prediction system.</p><p>&quot;We&#x27;re in the process of improving that,&quot; Simo said regarding the age prediction technology. </p><p>&quot;We want to do that ahead of launching adult mode.&quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &quot;Project Garlic,&quot; targeting a flagship release in early 2026. </p><p>While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.</p><p>&quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&quot; she explained. &quot;Revenue has also increased at the same pace... creating this virtuous cycle.&quot;</p><p>Clark added that efficiency is improving rapidly: &quot;The model we&#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&quot; compared to models from a year ago.</p><p>GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.</p>",
    "titleJa": "OpenAIのGPT-5.2登場：企業が知っておくべきこと",
    "summaryJa": "OpenAIがGPT-5.2を発表。推論、コーディング性能が向上し、企業向けに3つのモデルを提供。価格は高めだが、効率化でコストを相殺できると期待。",
    "explanationJa": "OpenAIの新しい高性能AIモデルGPT-5.2が登場し、企業の業務効率化に貢献することが期待されます。",
    "translationJa": "<p>噂は本当でした。OpenAIは木曜日、新たな最先端大規模言語モデル（LLM）ファミリーである<a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>のリリースを発表しました。</p><p>これは、AIの先駆者であるOpenAIにとって重要な時期に発表されました。競合の<a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">GoogleのGemini 3 LLMが主要な第三者機関によるパフォーマンスランキングや多くの重要なベンチマークで先月トップの座を獲得</a>して以来、OpenAIはますますプレッシャーにさらされていました。しかし、OpenAIのリーダーたちは記者会見で、今回のリリースはGemini 3のリリースよりもずっと前から議論され、準備が進められていたと強調しました。</p><p>OpenAIはGPT-5.2を「プロフェッショナルな知識労働にとってこれまでで最も有能なモデルシリーズ」と表現し、推論、コーディング、エージェントワークフローにおける大幅な向上により、パフォーマンスの王座を奪還することを目指しています。</p><p>「これは当社の最も高度な最先端モデルであり、プロフェッショナルな用途において市場で最も強力なものです」と、OpenAIのアプリケーション担当CEOであるFidji Simoは今日の記者会見で述べました。「5.2は、人々にとってさらに多くの経済的価値を引き出すように設計しました。スプレッドシートの作成、プレゼンテーションの構築、コードの記述、画像の認識、長文のコンテキストの理解、ツールの使用、複雑な複数段階のプロジェクトの処理において、より優れています。」</p><p>GPT-5.2は、400,000トークンという大規模なコンテキストウィンドウを備えており、一度に数百のドキュメントや大規模なコードリポジトリを取り込むことができます。また、最大128,000トークンの出力制限により、詳細なレポートや完全なアプリケーションを一度に生成できます。</p><p>このモデルは、2025年8月31日までの知識カットオフを備えており、比較的新しい世界情勢や技術文書に対応しています。また、「推論トークンのサポート」を明示的に含んでおり、基盤となるアーキテクチャが「o1」シリーズで普及した連鎖的思考処理を使用していることを確認しています。</p><h3><b>「コードレッド」の現実</b></h3><p>今回のリリースは、<i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\">The Informationの報道</a></i>を受けて行われました。その報道によると、ChatGPTを改善するために、サ​​ム・アルトマンCEOからOpenAIのスタッフに緊急の「コードレッド」指令が出されました。これは、Gemini 3によって露呈した「品質のギャップ」を受けてリソースを動員するように設計された動きであると伝えられています。<i><a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\">The Verge</a></i>も同様に、公式発表に先立ち、GPT-5.2のリリース時期について報道しました。</p><p>記者会見中、OpenAIの幹部はその指令を認めましたが、このモデルはGoogleに対抗するためだけに急いで作られたという見方を否定しました。</p><p>「これは何ヶ月も前から準備されていたものであることに注意することが重要です」とSimoは記者団に語りました。彼女は、「コードレッド」が会社を集中させるのに役立った一方で、それがタイムラインの唯一の推進力ではなかったことを明らかにしました。</p><p>「このコードレッドを発表したのは、特定の分野にリソースを集中させたいというシグナルを会社に送るためですが、それが特に今週リリースされる理由ではありません。」</p><p>OpenAIのポストトレーニングチームのリーダーであるMax Schwarzerは、パニック的なローンチという考えを払拭するために、この意見に同調しました。「このリリースは非常に長い間計画してきました... 今週という具体的な時期については、数か月前に話し合いました。」</p><p>OpenAIの広報担当者はさらに、「コードレッド」の呼びかけは、新しいモデルの開発やリリースだけでなく、製品としてのChatGPTに適用されたことを明らかにしました。</p><h3><b>内部構造：Instant、Thinking、Pro</b></h3><p>OpenAIは、GPT-5.2のリリースをChatGPT内で3つの異なる階層に分けています。これは、「推論」モデルの膨大な計算コストと、速度に対するユーザーの要求のバランスを取るように設計された戦略であると考えられます。</p><ul><li><p><b>GPT-5.2 Instant:</b> 書き込み、翻訳、情報検索などの日常的なタスク向けに最適化された速度重視のモデルです。</p></li><li><p><b>GPT-5.2 Thinking:</b> 「複雑で構造化された作業」および長期的なエージェント向けに設計されており、より深い推論チェーンを活用して、コーディング、数学、および複数段階のプロジェクトを処理します。</p></li><li><p><b>GPT-5.2 Pro:</b> 新しいヘビー級チャンピオン。OpenAIはこれを「最もスマートで信頼できるオプション」と表現し、品質が遅延よりも重要な難しい質問に対して最高の精度を提供します。</p></li></ul><p>開発者向けには、これらのモデルはアプリケーションプログラミングインターフェイス（API）で、<code>gpt-5.2</code>、<code>gpt-5.2-chat-latest</code>（Instant）、および<code>gpt-5.2-pro</code>としてすぐに利用できます。</p><h3><b>数値：ベンチマークを打ち破る</b></h3><p>GPT-5.2のリリースには、ほとんどの分野で主要な指標が含まれています。特に、競合他社が最近勢いを増している「プロフェッショナルな知識労働」ギャップをターゲットにしたものです。</p><p>OpenAIは、GDPvalと呼ばれる新しいベンチマークを強調しました。これは、44の職業にわたる「明確に指定された知識労働タスク」におけるパフォーマンスを測定します。</p><p>「GPT-5.2 Thinkingは現在、そのベンチマークで最先端であり... スプレッドシート、プレゼンテーション、ドキュメント作成などの明確に指定されたプロフェッショナルタスクの70.9％で、専門家による人間の審査員によると、業界トップのプロフェッショナルと同等かそれ以上です」とSimo氏は述べています。</p><p>コーディングという重要な分野で、OpenAIは決定的なリードを主張しています。Schwarzerは、実際のソフトウェアエンジニアリングの厳密な評価であるSWE-bench Proで、GPT-5.2 Thinkingが55.6％という新しい最先端のスコアを達成したと指摘しました。</p><p>彼は、このベンチマークが「SWE-bench Verifiedのような以前のベンチマークよりも、汚染に対する耐性が高く、挑戦的で、多様で、産業界に関連している」ことを強調しました。その他の主要なベンチマーク結果は次のとおりです。</p><ul><li><p><b>GPQA Diamond（科学）:</b> GPT-5.2 Proは93.2％のスコアを獲得し、GPT-5.2 Thinking（92.4％）をわずかに上回り、GPT-5.1 Thinking（88.1％）を上回りました。</p></li><li><p><b>FrontierMath:</b> Tier 1〜3の問題で、GPT-5.2 Thinkingは40.3％を解決し、前任者の31.0％から大幅に向上しました。</p></li><li><p><b>ARC-AGI-1:</b> GPT-5.2 Proは、この一般的な推論ベンチマークで90％のしきい値を超えた最初のモデルであると報告されており、<b>90.5％</b>のスコアを獲得しています</p></li></ul><h3><b>知性の代償</b></h3><p>パフォーマンスにはプレミアムが付きます。ChatGPTのサブスクリプション価格は今のところ変更されていませんが、新しいフラッグシップモデルのAPIコストは以前の世代と比較して高く、「思考」モードの高い計算需要を反映しています。また、業界のAPIコストの上限にあります。</p><ul><li><p><b>GPT-5.2 Thinking:</b> 100万入力トークンあたり<b>$1.75</b>、100万出力トークンあたり<b>$14</b>で販売されています。</p></li><li><p><b>GPT-5.2 Pro:</b> コストは大幅に上昇し、100万入力トークンあたり<b>$21</b>、100万出力トークンあたり<b>$168</b>になります。</p></li></ul><p>GPT-5.2 ThinkingのAPI価格は、標準のGPT-5.1（$1.25/$10）よりも40％高く、OpenAIが新しい推論機能を単なる効率化の更新ではなく、具体的な付加価値と見なしていることを示しています。</p><p>ハイエンドのGPT-5.2 Proも同じパターンに従い、以前のGPT-5 Pro（$15/$120）よりも40％高くなっています。高価ですが、それでもOpenAIの最も特殊な推論モデルであるo1-proを下回っており、100万入力トークンあたり150ドル、100万出力トークンあたり600ドルという驚異的な価格でメニューで最も高価な製品のままです。</p><p>OpenAIは、トークンあたりのコストは高いものの、モデルの「より高いトークン効率」と、より少ないターンでタスクを解決できる能力により、価値の高いエンタープライズワークフローにとって経済的に実行可能であると主張しています。</p><p>LLM分野の他の競合モデルの現在のAPIコストと比較すると、次のようになります。</p><table><tbody><tr><td><p><b>モデル</b></p></td><td><p><b>入力（/1M）</b></p></td><td><p><b>出力（/1M）</b></p></td><td><p><b>合計コスト</b></p></td><td><p><b>ソース</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast（推論）</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast（非推論）</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>画像生成：まだ新しいものはありません... しかし「今後さらに多くを」</b></h3><p>記者会見中、VentureBeatはOpenAIの参加者に、GoogleのGemini 3 Image（別名Nano Banana Pro）のような最近の競合製品の発売における同様の機能に対する興奮を指摘し、新しいリリースに画像生成機能の向上が含まれているかどうかを尋ねました。</p><p>テキストと情報が豊富なグラフィックや画像編集機能を再現しようとしている人にとって残念なことに、OpenAIの幹部は、GPT-5.2には、以前のGPT-5.1、およびOpenAIの統合されたDALL-E 3とgpt-4oのネイティブ画像生成モデルに対する画像改善は現在ないことを明らかにしました。</p><p>「画像生成については、今日発表することはありませんが、今後さらに多くを提供します」とSimo氏は述べています。彼女は、この機能の人気を認め、「これは人々が愛する非常に重要なユースケースであり、私たちが市場に導入したものです。今後も間違いなくさらに多くのことを提供します」と付け加えました。</p><p>OpenAIのトレーニング責任者であるAidan Clarkも、視覚生成の具体的な詳細についてはコメントを控え、「私は画像生成についてあまり詳しく話せません」と述べています。</p><h3><b>「メガエージェント」時代</b></h3><p>生のスコアを超えて、OpenAIはGPT-5.2を、人間の手を介さずに複数段階のワークフローを実行できる、新世代の「長期実行エージェント」のエンジンとして位置付けています。</p><p>Boxは、5.2が長くて複雑なドキュメントから情報を約40％速く抽出できることを発見し、ライフサイエンスおよびヘルスケアにおける推論の精度も40％向上しました」とSimo氏は述べています。</p><p>彼女はまた、Notionがモデルを「すべての次元で5.1よりも優れており... 真の知識労働を定義する一種の本当にあいまいな、より長いタスクに優れている」と報告していると指摘しました。Schwarzerは、Augment Codeのようなコーディングスタートアップが、モデルが「これまでのどのモデルよりも実質的に強力な深いコード機能を提供した」ことを発見したため、新しいコードレビューエージェントを強化するために選択されたと付け加えました。視覚機能もアップグレードされました。</p><p>OpenAIのリリースブログの投稿には、「旅行者がフライトの遅延、乗り継ぎの失敗、ニューヨークでの一泊、および医療上の座席の要件を報告する」という例が示されています。</p><p>結果は？ 「GPT‑5.2は、予約の変更、特別なアシスタンスの座席、および補償というタスクのチェーン全体を管理し、GPT‑5.1よりも完全な結果を提供します。」</p><p>GUIスクリーンショットを理解するモデルの能力をテストする新しい評価であるScreenSpot-Proでは、GPT-5.2 Thinkingが86.3％の精度を達成したのに対し、GPT-5.1はわずか64.2％でした。</p><h3><b>科学と信頼性</b></h3><p>OpenAIのリーダーはまた、科学研究におけるモデルの有用性を強調し、会話を単純なチャットボットから研究アシスタントへと移行させようとしました。</p><p>トレーニングチームのリーダーであるAidan Clarkは、モデルをテストした免疫学の上級研究者の例を共有しました。</p><p>「彼らは、免疫系に関する最も重要な未解決の質問を生成するように依頼してテストしました」とClarkは述べています。「その免疫学の研究者は、GPT-5.2が、以前のどのプロモデルと比較しても、より鋭い質問と、それらの質問が... 重要である理由のより強力な説明を生み出したと報告しました。</p><p>「信頼性も重要な焦点でした。Schwarzerは、新しいモデルが「GPT-5.1よりも実質的に幻覚を見る頻度が少ない」と主張し、匿名化された一連のクエリで「応答にエラーが含まれる頻度が38％少なくなった」と指摘しました。</p><h3><b>「雰囲気」の変化</b></h3><p>興味深いことに、OpenAIは、すべてのユーザーがすぐに新しいモデルを好むとは限らないことを認めました。</p><p>GPT-5.1のようなレガシーモデルが利用可能なままである理由を尋ねられたとき、Schwarzerは「モデルは毎回少しずつ変化します」と認めました。</p><p>「一部のユーザーは、最新のモデルが全体的にはるかに優れていると考えていても、以前のモデルの雰囲気を好むかもしれません」とSchwarzer氏は述べています。彼はまた、「特定のモデルに合わせてプロンプトを微調整した」一部のエンタープライズ顧客にとっては、「小さなリグレッション」が発生し、古いバージョンへのアクセスが必要になる可能性があると指摘しました。</p><h3><b>安全性、「アダルトモード」、および将来のロードマップ</b></h3><p>安全性に関する懸念に対処するために、Simoは、同社が新しい年齢予測システムの実装後、来年の第1四半期に「アダルトモード」を展開する準備をしていることを確認しました。</p><p>「改善の過程にあります」とSimoは年齢予測技術について述べています。</p><p>「アダルトモードの開始に先立って、それを行いたいと考えています。」さらに先を見据えて、業界レポートでは、OpenAIが「プロジェクトガーリック」というコードネームで、2026年初頭にフラッグシップリリースを目標とする、より根本的なアーキテクチャのシフトに取り組んでいることが示唆されています。</p><p>幹部たちは記者会見中、具体的な将来のロードマップについてはコメントしませんでしたが、Simoは現在の軌道の経済性について楽観的な見方を維持しました。</p><p>「過去の傾向を見ると、計算量は過去3年間で毎年約3倍に増加しています」と彼女は説明しました。「収益も同じペースで増加しており... この好循環を生み出しています。」</p><p>Clarkは、効率が急速に向上していると付け加えました。「本日リリースするモデルは、1年前のモデルと比較して、[ARC-AGI]でさらに優れたスコアを、ほぼ400分の1のコストと計算量で達成しています。」</p><p>GPT-5.2 Instant、Thinking、およびProは、本日よりChatGPTで有料ユーザー（Plus、Pro、Team、およびEnterprise）向けに段階的に展開されます。同社は、安定性を維持するために展開は段階的に行われると述べています。</p>",
    "insightJa": "GPT-5.2の登場により、ビジネスにおけるAIの活用がさらに進むと予想されます。特に、プロフェッショナルな知識労働の効率化や、自動化によるコスト削減に貢献する可能性があり、企業の競争力向上に繋がるでしょう。",
    "recommendedBooks": [
      "大規模言語モデル",
      "GPT-5",
      "AI 業務効率化"
    ],
    "tags": [
      "OpenAI",
      "GPT-5.2",
      "LLM",
      "Artificial Intelligence",
      "自然言語処理"
    ],
    "imageUrl": "https://images.pexels.com/photos/16629368/pexels-photo-16629368.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "title": "Stressed rats keep returning to cannabis and scientists know why",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "summary": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "publishedAt": "Thu, 11 Dec 2025 12:15:09 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "titleJa": "ストレスを感じやすいラットは、なぜ大麻に戻ってしまうのか？科学者がその理由を解明",
    "summaryJa": "ストレスレベルが高いラットは、大麻を自ら摂取しやすい傾向に。行動実験では、ストレスホルモンの高さが最も強い予測因子だった。認知柔軟性の低下や内因性カンナビノイドの低さも使用増加に寄与。薬物乱用の脆弱性を示す可能性。",
    "explanationJa": "ストレスを感じやすい人は、薬物に依存しやすい傾向があるかもしれません。今後の研究が期待されますね。",
    "translationJa": "生まれつきストレスレベルが高いラットは、自由にアクセスできる環境下で、より自発的に大麻を摂取する傾向が強いことがわかりました。行動実験の結果、ベースラインのストレスホルモンが、大麻を求める行動の最も強力な予測因子であることが示されました。認知の柔軟性の低下と内因性カンナビノイドレベルの低さも、使用量の増加に寄与していました。これらの結果は、薬物乱用に対する脆弱性を示す可能性のある初期指標を示唆しています。",
    "insightJa": "この研究結果は、ストレス管理の重要性を示唆しています。企業においては、従業員のメンタルヘルスケアを充実させることで、薬物依存のリスクを軽減できる可能性があります。",
    "recommendedBooks": [
      "ストレスマネジメント",
      "依存症の科学",
      "脳科学 ストレス"
    ],
    "tags": [
      "Cannabis",
      "Stress",
      "Addiction",
      "ラット",
      "大麻"
    ],
    "imageUrl": "https://images.pexels.com/photos/3259584/pexels-photo-3259584.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "7nAN91YGj5oC8TMc2YBtjK",
    "title": "Marble enters the race to bring AI to tax work, armed with $9 million and a free research tool",
    "source": "rss",
    "url": "https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a",
    "summary": "Marble, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.\nThe round, led by Susa Ventures with participation from MXV Capital and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.\n\"When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,\" said Bhavin Shah, Marble's chief executive officer, in an exclusive interview with VentureBeat. \"Accounting generates $250 billion in fee-based billing in the US every year. There's a tremendous opportunity to increase efficiency and improve margins for accounting firms.\"\nThe company has launched a free AI-powered tax research tool on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.\nMarble's backers share Shah's conviction about the market. \"Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,\" Chad Byers, general partner at Susa Ventures, told VentureBeat. \"We've known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.\"\nThe accounting industry lost 340,000 workers in four years — and replacements aren't coming\nMarble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.\nThe accounting profession has shed roughly 340,000 workers since 2019, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to AICPA data, and 2022 saw the lowest number of exam takers in 17 years.\nThe exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately 75% of all licensed CPAs reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.\n“Fewer CPAs are getting certified year over year,\" Shah said. \"The industry is compressing at the same time that there's more work to be done and the tax code is getting more complicated.\"\nThe National Pipeline Advisory Group, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the 150-hour education requirement for CPA licensure as a significant barrier to entry. A separate survey by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.\nRecent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.\nWhy AI transformed law and software development but left accounting behind\nDespite the profession's challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. Harvey and Legora have raised hundreds of millions to bring AI to legal work. Cursor and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.\nGeordie Konrad, Marble's executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI's capabilities.\n“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,\" Konrad said. \" That requires a bit more of a two-step analysis to see why it's a big opportunity.\"\nThe technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.\n\"If you want to put AI through its paces and ask how far it's come in replicating cognitive functions, this is an unbelievable playground to work in,\" Konrad said.\nA dramatic shift: AI adoption among tax and finance teams doubles in one year\nRecent data suggests the accounting profession's stance toward AI is shifting rapidly.\nA 2025 survey from Hanover Research and Avalara found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from Thomson Reuters Institute found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.\nLarge accounting firms have invested heavily in AI infrastructure. Deloitte has developed generative AI capabilities within its audit platform. BDO announced a $1B investment in AI over the next five years. EY launched an AI platform combining technology with strategy, transactions, and tax services. PwC estimates a complete AI-driven audit solution will launch by 2026.\nBut adoption at smaller firms remains uneven. According to Thomson Reuters research, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.\nMarble's founders believe the hesitance stems not from technophobia but from a lack of compelling options.\n“Firms want to embrace AI,\" Shah said. “They just haven't seen great software and tooling made for them. That's part of the opportunity — to work with them and build something they're excited to use on a day-to-day basis.”\nCan artificial intelligence rescue accounting's billable-hour business model?\nAI's arrival in accounting raises questions about the profession's billing structure.\nAccounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?\nMarble's founders argue the opposite. The chronic staffing shortage has already constrained firms' ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.\n\"Everyone in the industry agrees that an enormous amount of advisory work simply isn't getting done,\" Konrad said. \"Customers want it. Firms want to do it because it's high-margin, great work. But nobody gets to it.\"\nThe 2025 AICPA National Management of an Accounting Practice Survey supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.\nThe survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.\nAccountants won't adopt AI tools they can't trust with sensitive client data\nFor AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.\nAccording to Avalara's survey, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.\nMarble has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.\n\"Security is at the core of what we are building,\" Shah said. \"Every employee knows that security is critical. It's a part of our onboarding and something that we consider in everything we do.\"\nFrom number crunchers to strategic advisors: How AI could reshape accounting careers\nMarble's founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. \nThey draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.\n\"If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you're a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that's just a lot more fun to operate in,\" Konrad said.\nThe shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.\n\"Not only does the work become more enjoyable because of what you can focus on, but that's also what your clients are going to value more from you,\" Shah said.\nThe competitive landscape: Marble faces well-funded rivals and legacy giants\nMarble enters a market with formidable incumbents and well-funded competitors. BlueJ, a global tax research platform, has raised over $100 million. Thomson Reuters, CCH, and Intuit have deep customer relationships built over decades.\nBut the founders see opportunity in the transition moment.\n\"AI has changed what’s possible in the industry,\" Shah said. \"We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?\"\"\nThe decision to offer a free research tool reflects Marble's go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.\n\"It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don't know how to integrate it into their workflow,\" Shah said.\nThe $250 billion question: Can a startup transform how America does its taxes?\nMarble's roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.\nThe founders frame success not in terms of disruption but rebalancing. Today's tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble's bet is that AI can flip that equation.\n\"Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,\" Konrad said. \"How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?\"\nWhether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.\nBut the founders are betting that the industry's demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.\n\"AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,\" Shah said.\nThe accounting profession, it seems, is about to find out which side of that equation it lands on.",
    "publishedAt": "Thu, 11 Dec 2025 14:00:00 GMT",
    "author": "michael.nunez@venturebeat.com (Michael Nuñez)",
    "category": "AI",
    "originalContent": "<p><a href=\"http://marble.ai/\">Marble</a>, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.</p><p>The round, led by <a href=\"https://www.susaventures.com/\">Susa Ventures</a> with participation from <a href=\"https://mxv.vc/\">MXV Capital</a> and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.</p><p>&quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&quot; said Bhavin Shah, Marble&#x27;s chief executive officer, in an exclusive interview with VentureBeat. &quot;Accounting generates $250 billion in fee-based billing in the US every year. There&#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&quot;</p><p>The company has launched a <a href=\"https://marble.ai/\">free AI-powered tax research tool</a> on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.</p><p>Marble&#x27;s backers share Shah&#x27;s conviction about the market. &quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &quot;We&#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&quot;</p><h2><b>The accounting industry lost 340,000 workers in four years — and replacements aren&#x27;t coming</b></h2><p>Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.</p><p>The accounting profession has <a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">shed roughly 340,000 workers since 2019</a>, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to <a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPA data</a>, and 2022 saw the lowest number of exam takers in 17 years.</p><p>The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately <a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">75% of all licensed CPAs</a> reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.</p><p>“Fewer CPAs are getting certified year over year,&quot; Shah said. &quot;The industry is compressing at the same time that there&#x27;s more work to be done and the tax code is getting more complicated.&quot;</p><p>The <a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the <a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150-hour education requirement</a> for CPA licensure as a significant barrier to entry. A separate <a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">survey</a> by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.</p><p>Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.</p><h2><b>Why AI transformed law and software development but left accounting behind</b></h2><p>Despite the profession&#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. <a href=\"https://www.harvey.ai/\">Harvey</a> and <a href=\"https://legora.com/\">Legora</a> have raised hundreds of millions to bring AI to legal work. <a href=\"https://cursor.com/agents\">Cursor</a> and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.</p><p>Geordie Konrad, Marble&#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&#x27;s capabilities.</p><p>“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&quot; Konrad said. &quot; That requires a bit more of a two-step analysis to see why it&#x27;s a big opportunity.&quot;</p><p>The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.</p><p>&quot;If you want to put AI through its paces and ask how far it&#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&quot; Konrad said.</p><h2><b>A dramatic shift: AI adoption among tax and finance teams doubles in one year</b></h2><p>Recent data suggests the accounting profession&#x27;s stance toward AI is shifting rapidly.</p><p>A 2025 survey from <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a> found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from <a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a> found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.</p><p>Large accounting firms have invested heavily in AI infrastructure. <a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a> has developed generative AI capabilities within its audit platform. <a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a> announced a $1B investment in AI over the next five years. <a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a> launched an AI platform combining technology with strategy, transactions, and tax services. <a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a> estimates a complete AI-driven audit solution will launch by 2026.</p><p>But adoption at smaller firms remains uneven. According to <a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reuters research</a>, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.</p><p>Marble&#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.</p><p>“Firms want to embrace AI,&quot; Shah said. “They just haven&#x27;t seen great software and tooling made for them. That&#x27;s part of the opportunity — to work with them and build something they&#x27;re excited to use on a day-to-day basis.”</p><h2><b>Can artificial intelligence rescue accounting&#x27;s billable-hour business model?</b></h2><p>AI&#x27;s arrival in accounting raises questions about the profession&#x27;s billing structure.</p><p>Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?</p><p>Marble&#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.</p><p>&quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&#x27;t getting done,&quot; Konrad said. &quot;Customers want it. Firms want to do it because it&#x27;s high-margin, great work. But nobody gets to it.&quot;</p><p>The <a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a> supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.</p><p>The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.</p><h2><b>Accountants won&#x27;t adopt AI tools they can&#x27;t trust with sensitive client data</b></h2><p>For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.</p><p>According to <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalara&#x27;s survey</a>, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.</p><p><a href=\"https://marble.ai/\">Marble</a> has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.</p><p>&quot;Security is at the core of what we are building,&quot; Shah said. &quot;Every employee knows that security is critical. It&#x27;s a part of our onboarding and something that we consider in everything we do.&quot;</p><h2><b>From number crunchers to strategic advisors: How AI could reshape accounting careers</b></h2><p>Marble&#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. </p><p>They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.</p><p>&quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&#x27;s just a lot more fun to operate in,&quot; Konrad said.</p><p>The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.</p><p>&quot;Not only does the work become more enjoyable because of what you can focus on, but that&#x27;s also what your clients are going to value more from you,&quot; Shah said.</p><h2><b>The competitive landscape: Marble faces well-funded rivals and legacy giants</b></h2><p><b></b><a href=\"http://marble.ai/\">Marble</a> enters a market with formidable incumbents and well-funded competitors. <a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>, a global tax research platform, has raised over $100 million. <a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>, <a href=\"https://www.cch.com/\">CCH</a>, and <a href=\"https://www.intuit.com/\">Intuit</a> have deep customer relationships built over decades.</p><p>But the founders see opportunity in the transition moment.</p><p>&quot;AI has changed what’s possible in the industry,&quot; Shah said. &quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&quot;&quot;</p><p>The decision to offer a free research tool reflects Marble&#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.</p><p>&quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&#x27;t know how to integrate it into their workflow,&quot; Shah said.</p><h2><b>The $250 billion question: Can a startup transform how America does its taxes?</b></h2><p>Marble&#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.</p><p>The founders frame success not in terms of disruption but rebalancing. Today&#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&#x27;s bet is that AI can flip that equation.</p><p>&quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&quot; Konrad said. &quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&quot;</p><p>Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.</p><p>But the founders are betting that the industry&#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.</p><p>&quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&quot; Shah said.</p><p>The accounting profession, it seems, is about to find out which side of that equation it lands on.</p>",
    "titleJa": "Marble、税務業務へのAI導入競争に参入、900万ドルの資金調達と無料の研究ツール",
    "summaryJa": "税務専門家向けAIエージェント開発のMarbleが900万ドルの資金を調達。人手不足と規制の複雑化に対応し、AIを活用した税務業務の効率化を目指す。",
    "explanationJa": "Marble社は、AIを使って税務業務を効率化するサービスを提供し、税務業界の課題解決を目指しています。",
    "translationJa": "<p><a href=\"http://marble.ai/\">Marble</a>は、税務専門家向けの人工知能エージェントを構築しているスタートアップで、会計業界が深刻な人手不足と増大する規制の複雑さに苦慮している中、900万ドルのシード資金を調達しました。</p><p>Susa Venturesが主導し、MXV CapitalとKonrad Capitalが参加したこのラウンドにより、Marbleは、AIの導入が法律やソフトウェア開発のような他の知識産業に比べて大幅に遅れている市場で競争する立場となります。</p><p>Marbleの最高経営責任者であるBhavin Shahは、VentureBeatとの独占インタビューで、「経済を検討し、AIが企業の運営方法を変革する場所はどこか自問したとき、時間料金制のサービスモデルを持つ知識産業、特に企業に焦点を当てました。会計は米国で毎年2,500億ドルの料金制請求を生み出しています。会計事務所の効率を高め、利益率を向上させる絶好の機会があります。」と述べています。</p><p>同社は、ウェブサイト上で<a href=\"https://marble.ai/\">無料のAI搭載税務調査ツール</a>を公開しており、複雑な政府の税務データを、専門家がアクセスしやすい、引用に基づいた回答に変換します。Marbleは、コンプライアンスシナリオを分析し、最終的には税務申告ワークフローの一部を自動化できるAIエージェントに拡大する予定です。</p><p>Marbleの支援者たちは、Shahの市場に対する確信を共有しています。Susa VenturesのゼネラルパートナーであるChad ByersはVentureBeatに、「Marbleは会計システムを根本から見直しています。会計はプロフェッショナルサービスの中で最大規模であり、最も見過ごされている市場の一つです。私たちはBhavinがSusaのポートフォリオのエグゼクティブだった頃から彼のことを知っており、彼がどれほど鋭敏で実行力があるかを直接見てきました。彼とGeordieは、長年変化が遅れていた分野に、業務の深さと製品の本能の完璧な組み合わせをもたらしており、私たちと同じように大きな機会を見ているのです。」と語りました。</p><h2><b>会計業界は4年間で34万人の労働者を失い、補充は見込めない</b></h2><p>Marbleは、専門会計の経済状況を根本的に変えた構造的な力によって形作られた市場に参入します。</p><p>会計業界は<a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">2019年以降、約34万人の労働者を失いました</a>。これは17％の減少であり、企業はクライアントの需要を満たすために奔走しています。公認会計士試験の初回受験者は、<a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPAのデータ</a>によると、2016年から2021年の間に33％減少し、2022年には受験者数が17年間で最低となりました。</p><p>この流出は、ベビーブーマー世代の一斉退職と重なっています。米国公認会計士協会は、<a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">すべての公認会計士の約75％</a>が2019年までに定年退職年齢に達したと推定しており、業界が対処に苦労している人口統計上の崖を生み出しています。</p><p>「公認会計士の認定を受ける人が年々少なくなっています」とShahは言います。「業界は縮小している一方で、やるべき仕事は増え、税法はますます複雑になっています。」</p><p>AICPAが2023年7月に設立したマルチステークホルダー組織である<a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>は、CPAライセンス取得の<a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150時間の教育要件</a>を、参入に対する大きな障壁として特定した報告書を発表しました。Center for Audit Qualityによる別の<a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">調査</a>では、会計を専攻しないことを選択した経営学専攻の57％が、追加の単位時間を抑止力として挙げています。</p><p>最近の法改正は、その緊急性を反映しています。オハイオ州は現在、150時間要件の代替案を提供しており、州が入学者の減少を逆転させる可能性のある経路を試す用意があることを示唆しています。</p><h2><b>なぜAIは法律とソフトウェア開発を変革したが、会計を置き去りにしたのか</b></h2><p>会計業界の課題にもかかわらず、会計におけるAIの導入は、隣接する知識産業よりも遅れています。<a href=\"https://www.harvey.ai/\">Harvey</a>と<a href=\"https://legora.com/\">Legora</a>は、法律業務にAIを導入するために数億ドルを調達しました。<a href=\"https://cursor.com/agents\">Cursor</a>やその他のコーディングアシスタントは、ソフトウェア開発を変革しました。対照的に、会計は依然としてレガシーな調査プラットフォームと手動プロセスに大きく依存しています。</p><p>Marbleのエグゼクティブチェアマンであり、レストランソフトウェア会社TouchBistroの共同創業者であるGeordie Konradは、そのギャップを、人々がAIの能力をどのように概念化するかに起因すると考えています。</p><p>「LLMがソフトウェア開発者向けのコードを操作したり、弁護士向けの言葉を操作したりすることで、意味のある仕事ができることは、多くの人にとって明らかでした。会計業界では、LLMは推論エージェントとして使用されるでしょう」とKonradは言いました。「それが大きな機会である理由を理解するには、もう少し二段階の分析が必要です。」</p><p>技術的な課題はかなりのものです。税務規制は、人間が作成した最も複雑で相互接続された情報システムの一つを形成しており、数万もの相互に関連するルール、ガイダンス文書、および頻繁に重複または矛盾する管轄区域固有の要件があります。</p><p>「AIを試してみて、認知機能を複製する上でどこまで進んでいるかを尋ねたいなら、これは信じられないほどの遊び場です」とKonradは言いました。</p><h2><b>劇的な変化：税務および財務チームにおけるAIの採用は1年間で2倍になる</b></h2><p>最近のデータは、会計業界のAIに対する姿勢が急速に変化していることを示唆しています。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a>の2025年の調査によると、財務および税務チームの84％が現在、業務でAIを大幅に使用しており、2024年の47％から増加しています。<a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a>の2025年Generative AI in Professional Services Reportによると、税務事務所の21％がすでに生成AI技術を使用しており、53％が採用を計画しているか、積極的に検討しています。</p><p>大規模な会計事務所は、AIインフラストラクチャに多額の投資を行ってきました。<a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a>は、監査プラットフォーム内で生成AI機能を開発しました。<a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a>は、今後5年間でAIに10億ドルを投資すると発表しました。<a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a>は、テクノロジーと戦略、トランザクション、税務サービスを組み合わせたAIプラットフォームを立ち上げました。<a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a>は、完全なAI駆動の監査ソリューションが2026年までに開始されると予測しています。</p><p>しかし、中小企業での導入は依然として不均一です。<a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reutersの調査</a>によると、生成AIを使用している税務事務所の回答者の52％が、業界固有のソリューションではなく、ChatGPTのようなオープンソースツールに依存しています。これは、目的に合った代替手段が登場するにつれて変化する可能性があります。</p><p>Marbleの創業者たちは、その躊躇はテクノフォビアではなく、説得力のある選択肢の欠如から生じていると考えています。</p><p>「企業はAIを受け入れたいと思っています」とShahは言いました。「彼らは自分たちのために作られた優れたソフトウェアやツールを見たことがありません。それが機会の一部です。彼らと協力して、彼らが日常的に使用することに興奮する何かを構築することです。」</p><h2><b>人工知能は会計の請求時間制ビジネスモデルを救うことができるのか？</b></h2><p>会計におけるAIの登場は、業界の請求構造について疑問を投げかけています。</p><p>会計事務所は伝統的に、スタッフの時間の請求によって利益を生み出してきました。多くの場合、従業員の報酬コストの数倍で請求します。コンプライアンス作業を行うジュニアアソシエイトは、重要な収益源となります。AIがその作業を自動化できる場合、企業が依存するビジネスモデルを損なうのでしょうか？</p><p>Marbleの創業者たちは、その逆だと主張しています。慢性的な人員不足は、企業が利用可能な収益を獲得する能力をすでに制約しています。アドバイザリーおよびコンサルティング業務（クライアントが積極的に求めている、より利益率の高いサービス）は、実務者がコンプライアンス業務に埋もれているため、行われていません。</p><p>「業界の誰もが、膨大な量のアドバイザリー業務が単に行われていないことに同意しています」とKonradは言いました。「顧客はそれを求めています。企業はそれが高収益で素晴らしい仕事なのでやりたいと思っています。しかし、誰もそれにたどり着けません。」</p><p><a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a>はこの見解を支持しています。企業は、前年比でクライアントからの純手数料が6.7％増加したと報告しており、監査、保証、税務サービス、およびクライアント会計アドバイザリーの成長が見られました。パートナー1人当たりの純残余は、会計年度2022年から会計年度2024年にかけて11.9％増加し、252,663ドルに達しました。</p><p>この調査では、AIの導入に対する関心も高まっていることがわかりましたが、ほとんどの企業はまだ正式な予算を割り当てたり、構造化されたトレーニングプログラムを開発したりしていません。調査によると、継続的な導入は、サービスを拡大し、継続的な成長を促進するのに役立つ可能性があります。</p><h2><b>会計士は、機密クライアントデータを信頼できないAIツールを採用しない</b></h2><p>AIが会計で成功するためには、データセキュリティの高いハードルをクリアする必要があります。会計事務所は、経済の中で最も機密性の高い財務情報を扱います。実務者は、コンプライアンスまたは機密保持のリスクを生み出すツールを採用することはできません。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalaraの調査</a>によると、回答者の63％が、データセキュリティとプライバシーに関する懸念を、税務および財務機能を自動化する上での最大の障壁として挙げています。この懸念は、最初の選択から実装、継続的な使用まで、採用ライフサイクル全体にわたって残ります。</p><p><a href=\"https://marble.ai/\">Marble</a>は、セキュリティを基本的な優先事項としてきました。同社は、製品をリリースする前にソフトウェアコンプライアンス認証を取得し、データプライバシーが初日から業務文化に組み込まれていることを主張しています。</p><p>「セキュリティは、私たちが構築しているものの中心にあります」とShahは言いました。「すべての従業員は、セキュリティが重要であることを知っています。それは私たちのオンボーディングの一部であり、私たちが行うすべてのことで考慮するものです。」</p><h2><b>ナンバークランチから戦略的アドバイザーへ：AIは会計のキャリアをどのように再形成するか</b></h2><p>Marbleの創業者たちは、AIが会計の仕事を奪うだけだという見方を否定します。彼らは代わりに、AIは会計の仕事をより戦略的にし、反復的な実行によって特徴付けられることが少なくなるだろうと提案します。</p><p>彼らは、コンピューター支援設計が骨の折れる手作業による製図に取って代わった建築に例えています。建築家は姿を消したわけではありません。彼らは創造的なデザインにもっと時間を費やし、機械的な複製に費やす時間を減らすことができるツールを手に入れました。</p><p>「ジュニアまたは中堅の会計士であることの、時間集約的で創造性の低い作業の一部を取り除き、それを創造的で、アイデアを合成し、多くのタスクをAIアシスタントプラットフォームソリューションに委任できる専門家の役割に置き換えると、業界は運営するのがはるかに楽しくなります」とKonradは言いました。</p><p>この変化は、クライアントの成果も改善する可能性があります。会計士がコンプライアンスに費やす時間を減らすと、クライアントが重視する戦略的なアドバイザリー業務にもっと投資できます。</p><p>「何に焦点を当てることができるかによって仕事がより楽しくなるだけでなく、クライアントはあなたからそれをもっと高く評価するでしょう」とShahは言いました。</p><h2><b>競争環境：Marbleは資金力のあるライバルとレガシーな巨人に対峙する</b></h2><p><a href=\"http://marble.ai/\">Marble</a>は、強力な既存企業と資金力のある競争相手がいる市場に参入します。グローバルな税務調査プラットフォームである<a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>は、1億ドル以上を調達しました。<a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>、<a href=\"https://www.cch.com/\">CCH</a>、および<a href=\"https://www.intuit.com/\">Intuit</a>は、数十年にわたって構築された深い顧客関係を持っています。</p><p>しかし、創業者たちは移行の瞬間に機会を見出しています。</p><p>「AIは業界で何が可能かを変えました」とShahは言いました。「私たちは業界の一部のテクノロジー企業と協力し、統合する予定であり、AIを搭載した新製品で他の企業と競争する予定です。場合によっては、物事を行うための既存のテクノロジーソリューションを忘れ、タスク自体に戻ります。私たちは完全に新しい技術的能力を持っています。人間と協力してそのタスクを達成するために、白紙の状態から何かをどのように設計しますか？ 」」</p><p>無料の調査ツールを提供するという決定は、Marbleの市場投入の哲学を反映しています。料金なしで実務者にアクセスできるようにすることで、同社は信頼を構築し、能力を実証することを目指しています。</p><p>「AIの使用方法を心配している人や、採用方法を疑問視している人に、目的に合わせて作られた非常に説得力のある製品を公開することができます。ワークフローに統合する方法がわからない場合に、費用がかかるものを購入することを心配する必要はありません」とShahは言いました。</p><h2><b>2,500億ドルの質問：スタートアップ企業はアメリカの税金の処理方法を変革できるのか？</b></h2><p>Marbleのロードマップは調査を超えて広がっています。同社は、複雑な税務シナリオを分析し、コンプライアンスの問題を特定し、最終的にはコンプライアンスワークフローの重要な部分を自動化できるAIエージェントを開発する予定です。これらはすべて、実務者の管理下にとどまります。</p><p>創業者たちは、成功を混乱という観点ではなく、再調整という観点から捉えています。今日の税務業務はコンプライアンスに大きく偏っており、クライアントが切望する戦略的なアドバイザリーサービス（より高い利益を生み出す）は、常に未完了のままになっています。Marbleは、AIがその方程式を覆すことができると賭けています。</p><p>「誰もが、コンプライアンスがより簡単に行われ、戦略と計画について話し合う時間が増えることを望んでいます」とKonradは言いました。「コンプライアンスと戦略および計画のブレンドを、戦略と計画を優先し、コンプライアンスを大幅に簡素化されたものにするにはどうすればよいでしょうか？ 」</p><p>Marbleがそのビジョンを実行できるかどうかはまだわかりません。同社は、定着した競争相手、歴史的に技術革新に抵抗してきた専門職、およびハイステークスな財務業務向けのAIシステムを構築することに内在する予測不可能性に直面しています。</p><p>しかし、創業者たちは、業界の人口統計上の変化が、以前のテクノロジーの波では不可能だった方法で採用を加速させると賭けています。毎年この職業に参入する会計士が減少し、クライアントの需要が高まるばかりであるため、企業は残りのスタッフがより多くのことを行うことができるツールを受け入れる意欲が高まる可能性があります。</p><p>「AIはすべての業界を変えるでしょう。ビジネスモデルを支援する方法と、ビジネスモデルに挑戦する方法があります。AIは最終的に会計事務所のビジネスをより良く、より収益性の高いものにし、同時にエンドクライアントはより良いサービスをより良い価格で得られるようになると信じています」とShahは言いました。</p><p>会計業界は、その方程式のどちら側に落ち着くかを知ろうとしているようです。</p>",
    "insightJa": "AIによる税務業務の効率化は、会計士がより高度な戦略的業務に集中できるようになる可能性を秘めています。中小企業においても、専門家による高度なアドバイスを受けやすくなることが期待できますね。",
    "recommendedBooks": [
      "AI 税務",
      "会計 自動化",
      "税理士 AI 活用"
    ],
    "tags": [
      "AI",
      "Tax",
      "Accounting",
      "Artificial Intelligence",
      "Automation"
    ],
    "imageUrl": "https://images.pexels.com/photos/20457109/pexels-photo-20457109.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "title": "New research reveals how everyday cues secretly shape your habits",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "summary": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "publishedAt": "Wed, 10 Dec 2025 22:41:05 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "titleJa": "日常の合図がどのように習慣を密かに形成するのか、新たな研究で明らかに",
    "summaryJa": "脳タンパク質KCC2の低下でドーパミン神経が活発化し、報酬との関連が強まり習慣形成が加速。日常のトリガーが強い欲求を誘発する仕組みが解明。",
    "explanationJa": "日常的な合図が、脳内のタンパク質を通じて、私たちが思っている以上に習慣を強く形成している可能性があるのです。",
    "translationJa": "研究者たちは、KCC2と呼ばれる脳タンパク質のレベルの変化が、合図と報酬の結びつき方を再形成し、時に予想以上に早く、あるいは強力に習慣を形成させることを発見しました。このタンパク質が低下すると、ドーパミンニューロンの発火がより激しくなり、中毒性のある行動が定着するのと同じように、新しい関連付けが強化されます。ラットの研究では、短時間の同期的な神経活動のバーストでさえ、報酬学習を増幅させることが示され、朝のルーティンのような日常的なトリガーが、なぜ強い欲求を引き起こすのかについての洞察が得られました。",
    "insightJa": "この研究は、習慣形成のメカニズムを理解することで、より良い習慣を意図的に作り出すヒントを与えてくれます。ビジネスにおいては、顧客の習慣を理解し、効果的なマーケティング戦略を立案する上で役立つ可能性があります。",
    "recommendedBooks": [
      "習慣形成",
      "脳科学 行動経済学",
      "ドーパミン 報酬系"
    ],
    "tags": [
      "habit formation",
      "KCC2",
      "dopamine",
      "reward learning",
      "脳科学"
    ],
    "imageUrl": "https://images.pexels.com/photos/5486024/pexels-photo-5486024.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "title": "Blood tests reveal obesity rapidly accelerates Alzheimer’s progression",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "summary": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "publishedAt": "Wed, 10 Dec 2025 12:23:51 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "titleJa": "血液検査で判明：肥満がアルツハイマー病の進行を加速",
    "summaryJa": "肥満は従来考えられていたよりも速いスピードでアルツハイマー病関連の血中バイオマーカーの上昇を加速させる。画像データと血漿データから、肥満の人は神経変性やアミロイド蓄積に関連するタンパク質の増加が速いことが示された。",
    "explanationJa": "肥満はアルツハイマー病の進行を早める可能性があることが、血液検査で明らかになりました。",
    "translationJa": "肥満は、アルツハイマー病関連の血中バイオマーカーの上昇を、従来認識されていたよりもはるかに速く加速させます。長期的な画像データと血漿データの分析により、肥満の人は神経変性やアミロイド蓄積に関連するタンパク質の増加が、著しく速いペースで進行することが示されました。驚くべきことに、血液検査はPETスキャンよりも早くこれらの変化を検出しました。この結果は、肥満がアルツハイマー病の進行における主要かつ修正可能な要因であることを示唆しています。",
    "insightJa": "今回の研究結果は、日々の食生活を見直し、体重管理を行うことの重要性を示唆しています。企業においては、従業員の健康増進プログラムの一環として、肥満予防や早期発見のための健康診断を促進することが重要になるでしょう。",
    "recommendedBooks": [
      "アルツハイマー病 予防",
      "肥満 健康リスク",
      "認知症 早期発見"
    ],
    "tags": [
      "Alzheimer's",
      "Obesity",
      "Biomarkers",
      "Blood Test",
      "Neurodegeneration"
    ],
    "imageUrl": "https://images.pexels.com/photos/6642981/pexels-photo-6642981.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "title": "Rising temperatures are slowing early childhood development",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "summary": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "publishedAt": "Wed, 10 Dec 2025 00:59:03 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "titleJa": "気温上昇が幼児の発達を遅らせる",
    "summaryJa": "研究によると、異常な高温が幼児の発達を阻害する可能性があり、特に読み書きや算数のスキルに影響が出やすいとのことです。経済的に恵まれない子供ほど影響を受けやすいです。",
    "explanationJa": "気温の上昇は、子供たちの成長に悪影響を与える可能性があることがわかりました。地球温暖化対策が重要になります。",
    "translationJa": "研究者たちは、異常に高い気温が幼児の発達を阻害する可能性があることを発見しました。高温の環境で生活する子供たちは、特に読み書きや基本的な算数のスキルにおいて、重要な学習段階に到達する可能性が低くなりました。経済的困難や限られた資源に直面している子供たちは、最も大きな打撃を受けました。この研究は、気候変動が、子供たちが就学年齢に達するずっと前から、学習をどのように形作る可能性があるかを浮き彫りにしています。",
    "insightJa": "この研究結果は、地球温暖化が子供たちの未来に直接影響を与えることを示唆しています。企業は、環境に配慮した事業活動を推進し、持続可能な社会の実現に貢献することが求められます。",
    "recommendedBooks": [
      "幼児教育 環境",
      "地球温暖化 子供",
      "子どもの発達 気候変動"
    ],
    "tags": [
      "child development",
      "climate change",
      "幼児教育",
      "気温上昇",
      "学習格差"
    ],
    "imageUrl": "https://images.pexels.com/photos/7414954/pexels-photo-7414954.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "title": "Scientists reveal a tiny brain chip that streams thoughts in real time",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "summary": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "publishedAt": "Tue, 09 Dec 2025 23:54:39 EST",
    "author": "",
    "category": "Science",
    "originalContent": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "titleJa": "思考をリアルタイムで伝送する超小型脳チップを科学者が発表",
    "summaryJa": "BISCは脳とコンピュータを高帯域無線で繋ぐ超薄型インプラント。数万の電極とAIモデルを搭載し、運動、知覚、意図を解読。てんかん、麻痺、失明の治療を変革する可能性。",
    "explanationJa": "この技術は、脳の活動をリアルタイムで解析し、様々な病気の治療に役立つ可能性があります。",
    "translationJa": "BISCは、脳とコンピュータの間に高帯域幅の無線リンクを構築する超薄型ニューラルインプラントです。その小型シングルチップ設計には、数万もの電極が搭載されており、運動、知覚、意図を解読するための高度なAIモデルをサポートします。初期の臨床研究では、頭蓋骨の小さな開口部から挿入でき、詳細な神経活動を捉えながら安定性を維持できることが示されています。この技術は、てんかん、麻痺、失明の治療法を再構築する可能性があります。",
    "insightJa": "この技術が進歩すれば、脳波を使ったデバイス操作や、失われた感覚を取り戻す治療が実現するかもしれません。医療分野だけでなく、エンターテイメントや教育など、幅広い分野での応用が期待されます。",
    "recommendedBooks": [
      "脳科学 最前線",
      "ニューロテクノロジー 未来",
      "医療AI 最新動向"
    ],
    "tags": [
      "brain-computer interface",
      "neural implant",
      "AI",
      "脳科学",
      "ニューロテクノロジー"
    ],
    "imageUrl": "https://images.pexels.com/photos/16027824/pexels-photo-16027824.jpeg?auto=compress&cs=tinysrgb&h=350"
  }
]