[
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "title": "Parents call for New York governor to sign landmark AI safety bill",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "summary": "A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill that would require developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.\nThe bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul reportedly proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the changes made to California's  …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T22:16:09.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STK485_STK414_AI_SAFETY_B.webp?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill <a href=\"https://legislation.nysenate.gov/pdf/bills/2025/S6953B\">that would require</a> developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.</p>\n<p class=\"has-text-align-none\">The bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul <a href=\"https://www.transformernews.ai/p/new-york-governor-hochul-raise-act-sb-53\">reportedly</a> proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the <a href=\"https://www.theverge.com/ai-artificial-intelligence/787918/sb-53-the-landmark-ai-transparency-bill-is-now-law-in-california\">changes made to California's  …</a></p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "ニューヨーク州知事に画期的なAI安全法案の署名を求める親たち",
    "summaryJa": "150人以上の親が、AI開発企業に安全計画と透明性規則を義務付けるRAISE法案への署名をホークル知事に要請。法案修正案も報道されています。",
    "explanationJa": "ニューヨーク州で、AIの安全性を高めるための重要な法案の成立が期待されています。",
    "translationJa": "150人以上の親のグループが金曜日、ニューヨーク州知事のキャシー・ホークルに手紙を送り、責任あるAIの安全性と教育（RAISE）法を修正なしに署名するよう促しました。RAISE法は、メタ、OpenAI、Deepseek、Googleなどの大規模AIモデルの開発者に対し、安全計画を作成し、安全上の事故に関する透明性規則に従うことを義務付ける話題の法案です。\n\nこの法案は6月にニューヨーク州上院と下院の両方で可決されました。しかし今週、ホークルはRAISE法のほぼ全面的な書き換えを提案し、この法案をテクノロジー企業にとってより有利なものにするだろうと報じられています。これは、カリフォルニア州で行われた変更の一部に似ています。",
    "insightJa": "AIの安全性に関する法整備が進むことで、AI技術の悪用を防ぎ、より安全な社会の実現に貢献することが期待されます。ビジネスにおいては、AI技術の倫理的な利用や法規制への対応がより重要になります。",
    "recommendedBooks": [
      "AI倫理",
      "AIリスクマネジメント",
      "AI規制"
    ],
    "tags": [
      "AI Safety",
      "RAISE Act",
      "New York",
      "AI regulation",
      "人工知能"
    ],
    "imageUrl": "https://images.pexels.com/photos/16053029/pexels-photo-16053029.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075418",
    "title": "OK, what’s going on with LinkedIn’s algo?",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/ok-whats-going-on-with-linkedins-algo/",
    "summary": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "publishedAt": "Fri, 12 Dec 2025 19:38:16 +0000",
    "author": "Dominic-Madori Davis",
    "category": "AI",
    "originalContent": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "titleJa": "LinkedInのアルゴリズムに何が？",
    "summaryJa": "女性たちがLinkedInの新アルゴリズムが性差別的かどうか実験。専門家は複雑な要因があると言う。",
    "explanationJa": "LinkedInのアルゴリズムに関して、性差別の疑いがあるという実験結果が出ましたが、専門家はより複雑な要因を指摘しています。",
    "translationJa": "女性たちがLinkedInの新しいアルゴリズムが性差別的かどうかを検証する実験を行い、それを証明したと考えました。しかし、専門家によれば、それにはもっと複雑な要因が関係しているとのことです。",
    "insightJa": "もしLinkedInのアルゴリズムが性差別的な偏りを持つならば、キャリアアップの機会に影響が出る可能性があります。アルゴリズムの公平性を常に意識し、利用することが大切です。",
    "recommendedBooks": [
      "アルゴリズム バイアス",
      "ジェンダーとテクノロジー",
      "LinkedIn 活用術"
    ],
    "tags": [
      "LinkedIn",
      "algorithm",
      "sexism",
      "bias",
      "AI"
    ],
    "imageUrl": "https://images.pexels.com/photos/1089438/pexels-photo-1089438.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "title": "Google Translate brings real-time speech translations to any headphones",
    "source": "rss",
    "url": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "summary": "Google Translate's latest update brings live speech translations, originally available only on the Pixel Buds, to any headphones you want, with support for over 70 languages. It's rolling out today in beta and just requires a compatible Android phone with the Translate app (unlike Apple's similar feature, which requires AirPods). \nIt's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T18:11:14.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/google-translate-text-update-12-12-25.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google Translate's latest update brings live speech translations, originally available only <a href=\"https://www.theverge.com/2017/11/16/16659314/google-pixel-buds-review-bluetooth-headphones\">on the Pixel Buds</a>, to any headphones you want, with support for over 70 languages. It's <a href=\"https://blog.google/products/search/gemini-capabilities-translation-upgrades/\">rolling out today in beta</a> and just requires a compatible Android phone with the Translate app (unlike <a href=\"https://www.theverge.com/news/629506/apple-airpods-live-translation-ios-19\">Apple's similar feature</a>, which requires AirPods). </p>\n<p class=\"has-text-align-none\">It's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …</p>\n<p><a href=\"https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "Google翻訳、あらゆるヘッドホンでリアルタイム音声翻訳が可能に",
    "summaryJa": "Google翻訳がアップデート。Pixel Buds限定だったリアルタイム音声翻訳が、あらゆるヘッドホンで利用可能に。70以上の言語に対応。Geminiでテキスト翻訳も向上。",
    "explanationJa": "Google翻訳が進化し、どんなヘッドホンでもリアルタイムで外国語の会話が楽しめるようになります。",
    "translationJa": "Google翻訳の最新アップデートにより、当初Pixel Budsでのみ利用可能だったリアルタイム音声翻訳が、70以上の言語をサポートし、あらゆるヘッドホンで利用できるようになりました。今日からベータ版として提供され、対応するAndroidスマートフォンと翻訳アプリがあれば利用できます（Appleの同様の機能とは異なり、AirPodsは不要です）。\n\nこれは、Google翻訳に追加されるいくつかの新機能のうちの1つであり、テキスト翻訳の改善も含まれています。Geminiを使用することで、翻訳は慣用句やスラングなど、文字通りの意味とは異なるフレーズをより正確に翻訳できるようになります。例えば、「stealing my …",
    "insightJa": "この機能により、海外旅行や国際的なビジネスシーンでのコミュニケーションがよりスムーズになります。言語の壁を越えて、より多くの人々と繋がることが可能になります。",
    "recommendedBooks": [
      "機械翻訳",
      "多言語コミュニケーション",
      "AI 音声認識"
    ],
    "tags": [
      "Google Translate",
      "リアルタイム翻訳",
      "音声翻訳",
      "AI",
      "多言語対応"
    ],
    "imageUrl": "https://images.pexels.com/photos/607812/pexels-photo-607812.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075611",
    "title": "Trump’s AI executive order promises ‘one rulebook’ — startups may get legal limbo instead",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/trumps-ai-executive-order-promises-one-rulebook-startups-may-get-legal-limbo-instead/",
    "summary": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "publishedAt": "Fri, 12 Dec 2025 17:07:22 +0000",
    "author": "Rebecca Bellan",
    "category": "AI",
    "originalContent": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "titleJa": "トランプのAI大統領令、「単一のルールブック」を約束も、スタートアップは法的空白に陥る可能性",
    "summaryJa": "トランプ前大統領が州法を対象としたAI大統領令に署名。全国統一ルールを約束するも、訴訟やスタートアップの不確実性を招く恐れ。",
    "explanationJa": "トランプ前大統領のAIに関する大統領令は、AI関連の法規制を統一する試みですが、混乱を招く可能性もあります。",
    "translationJa": "トランプ前大統領は、州法を対象とし、全国統一のルールブックを約束するAIに関する大統領令に署名しました。批評家たちは、これが法廷闘争を引き起こし、連邦政府の規則に関する議会の議論が行われている間、スタートアップ企業の不確実性を長引かせる可能性があると警告しています。",
    "insightJa": "この動きは、AI関連ビジネスの全国展開を目指す企業にとっては追い風になる可能性があります。しかし、規制の変更に伴い、一時的な混乱や対応コストが発生する可能性も考慮する必要があります。",
    "recommendedBooks": [
      "AI 法規制",
      "AI スタートアップ",
      "技術と法律"
    ],
    "tags": [
      "AI",
      "executive order",
      "regulation",
      "startups",
      "legal limbo"
    ],
    "imageUrl": "https://images.pexels.com/photos/6476783/pexels-photo-6476783.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075551",
    "title": "Google Translate now lets you hear real-time translations in your headphones",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/google-translate-now-lets-you-hear-real-time-translations-in-your-headphones/",
    "summary": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "publishedAt": "Fri, 12 Dec 2025 17:00:00 +0000",
    "author": "Aisha Malik",
    "category": "AI",
    "originalContent": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "titleJa": "Google翻訳、ヘッドホンでリアルタイム翻訳を聞けるように",
    "summaryJa": "Google翻訳が、各話者の声の調子や強調などを保ったままリアルタイムにヘッドホンで翻訳を聞ける機能を追加。会話がより自然に。",
    "explanationJa": "Google翻訳の新しい機能で、より自然な会話をヘッドホンでリアルタイムに楽しめます。",
    "translationJa": "ヘッドホンでのリアルタイム翻訳体験では、各話者の声の調子、強調、リズムがそのまま維持されるため、会話をより理解しやすく、誰が何を言っているのかを区別しやすくなります。",
    "insightJa": "この機能により、言語の壁が低くなり、国際的なコミュニケーションがよりスムーズになるでしょう。ビジネスシーンでの会議や旅行先での会話などで役立つことが期待されます。",
    "recommendedBooks": [
      "翻訳技術",
      "異文化コミュニケーション",
      "AI翻訳"
    ],
    "tags": [
      "Google Translate",
      "Real-time Translation",
      "Headphones",
      "AI",
      "Language Learning"
    ],
    "imageUrl": "https://images.pexels.com/photos/267669/pexels-photo-267669.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=2607630",
    "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/chatgpt-everything-to-know-about-the-ai-chatbot/",
    "summary": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "publishedAt": "Fri, 12 Dec 2025 16:01:00 +0000",
    "author": "Kyle Wiggers, Cody Corrall, Kate Park, Alyssa Stringer",
    "category": "AI",
    "originalContent": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "titleJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと",
    "summaryJa": "ChatGPTの製品アップデートとリリースに関するタイムラインです。今年一年を通して更新されています。",
    "explanationJa": "ChatGPTは、AIを活用したチャットボットで、そのアップデート情報をまとめたものです。",
    "translationJa": "ChatGPTの製品アップデートとリリースに関するタイムラインです。最新の情報から始まり、今年一年を通して更新されています。",
    "insightJa": "ChatGPTのようなAI技術は、私たちの仕事やコミュニケーションの方法を大きく変える可能性があります。ビジネスでの活用や、日々の情報収集に役立つでしょう。",
    "recommendedBooks": [
      "ChatGPT 入門",
      "AIチャットボット ビジネス活用",
      "自然言語処理"
    ],
    "tags": [
      "ChatGPT",
      "AI",
      "チャットボット",
      "人工知能",
      "自然言語処理"
    ],
    "imageUrl": "https://images.pexels.com/photos/16094040/pexels-photo-16094040.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "title": "I quit all my AI fitness plans, and I feel free",
    "source": "rss",
    "url": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "summary": "AI sure does use a lot of words to say very little.\t\n\nThis is Optimizer, a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. Optimizer arrives in our subscribers' inboxes at 10AM ET. Opt in for Optimizer here.\nThis time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt amazing. Then life happened. \nA year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T15:00:00.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Over the shoulder shot of someone reading a lengthy AI insight from the Runna app\" data-caption=\"AI sure does use a lot of words to say very little.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAI sure does use a lot of words to say very little.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>This is </em><a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a><em>, a weekly newsletter sent every Friday from Verge senior reviewer</em> <a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a><em> that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. </em>Optimizer<em> arrives in our subscribers' inboxes at 10AM ET. Opt in for </em>Optimizer <em><a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</em></p>\n<p class=\"has-drop-cap has-text-align-none\">This time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt <em>amazing.</em> Then life happened. </p>\n<p class=\"has-text-align-none\">A year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIフィットネス計画をやめたら、自由になった",
    "summaryJa": "筆者はAIフィットネスプランを試したが、うまくいかず、最終的にやめた。AIの指示は冗長で、自分に合わなかったため、自由を感じている。",
    "explanationJa": "AIフィットネスプランが必ずしも全ての人に合うわけではないということを示唆しています。",
    "translationJa": "これはOptimizerです。The Vergeのシニアレビュアー、ヴィクトリア・ソングが毎週金曜日に配信するニュースレターで、あなたの人生を変えるとうたう最新の携帯電話、スマートウォッチ、アプリ、その他のガジェットを分析し、議論します。Optimizerは、東部時間午前10時に購読者の受信箱に届きます。Optimizerはこちらからお申し込みください。\n\n去年の今頃、私は4マイルのランニングタイムを16分短縮し、週に3〜4回ウェイトリフティングを行い、6ヶ月間の継続的なトレーニングの後、10ポンドの減量に成功していました。最高の気分でした。しかしその後、人生がうまくいかなくなりました。\n\n1年後、私は3ヶ月以上5キロ以上のランニングをしていません。ストレスで10ポンドのリバウンドし、悩まされています…\n\nThe Vergeで記事全文をお読みください。",
    "insightJa": "AIフィットネスは便利ですが、個人のニーズやライフスタイルに合わせた調整が重要です。自分自身の体調や目標を理解し、AIだけに頼らないことが大切です。",
    "recommendedBooks": [
      "フィットネス AI",
      "健康管理 アプリ",
      "運動療法 指導"
    ],
    "tags": [
      "AI fitness",
      "Runna",
      "Peloton",
      "fitness plan",
      "well-being"
    ],
    "imageUrl": "https://images.pexels.com/photos/8097819/pexels-photo-8097819.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "title": "How to vibe-write a country hit",
    "source": "rss",
    "url": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "summary": "You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"I Run\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.\nOn this episode of The Vergecast, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent Switched on Pop podcast. Charlie takes us th …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T14:23:18.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/VRG_VST_1212_Site.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"<a href=\"https://www.digitalmusicnews.com/2025/11/24/havens-i-run-ai-song-explained/\">I Run</a>\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.</p>\n<p class=\"has-text-align-none\">On <a href=\"https://link.chtbl.com/vergecast\">this episode of <em>The Vergecast</em></a>, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent <em>Switched on Pop </em>podcast. Charlie takes us th …</p>\n<p><a href=\"https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIでカントリーヒット曲を作る方法",
    "summaryJa": "AIツール、特にSunoが音楽制作、特にナッシュビルのカントリー音楽界で大きな役割を果たしています。TikTokでAI生成の楽曲が広まっています。",
    "explanationJa": "AI技術が音楽制作に浸透し、特にカントリー音楽の分野でその影響が大きくなっています。",
    "translationJa": "ご存知ないかもしれませんが、ほとんどまたは完全にAIで作られた曲に、ほぼ間違いなく遭遇しているはずです。ここ数週間TikTokをスクロールしているなら、おそらく「I Run」を何度か耳にしているでしょう。しかし、ソーシャルメディアや音楽プラットフォーム上では、数え切れないほどのAI楽曲が広まっています。一般的なAIツール、特にSunoは、音楽制作プロセスにおいて大きな部分を占めるようになっています。そして、カントリー音楽の本拠地であるナッシュビルでは、その傾向が特に顕著です。\n\nこの『The Vergecast』のエピソードでは、音楽ジャーナリストであり教授で、優れたポッドキャスト『Switched on Pop』の共同ホストでもあるチャーリー・ハーディングが、ニレイとデイビッドに加わります。チャーリーが私たちを…",
    "insightJa": "AI音楽は、個人の音楽制作を容易にするだけでなく、音楽業界全体の構造を変える可能性を秘めています。ビジネスにおいては、AIを活用した新しい音楽制作、配信、マーケティング戦略が求められるでしょう。",
    "recommendedBooks": [
      "AI音楽制作",
      "カントリー音楽 歴史",
      "音楽とテクノロジー"
    ],
    "tags": [
      "AI music",
      "Country music",
      "Suno",
      "Nashville",
      "音楽制作"
    ],
    "imageUrl": "https://images.pexels.com/photos/2453636/pexels-photo-2453636.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "43pZxbBPbS0s7iDFEyijjR",
    "title": "Ai2's new Olmo 3.1 extends reinforcement learning training for stronger reasoning benchmarks",
    "source": "rss",
    "url": "https://venturebeat.com/ai/ai2s-new-olmo-3-1-extends-reinforcement-learning-training-for-stronger",
    "summary": "The Allen Institute for AI (Ai2) recently released what it calls its most powerful family of models yet, Olmo 3. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.\nThe new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. \nAi2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. \nOlmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. \nAi2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. \n“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a blog post. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”\n\nTo get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.\nOlmo 3.1 Instruct 32B is \"optimized for chat, tool use, & multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a post on X. \nFor now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. \nBetter performance on benchmarks\nThe Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. \nOlmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. \nOlmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.\n“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. \n\nAi2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.\nCommitment to transparency and open source \nAi2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. \nOrganizations could add to the model’s data mix and retrain it to also learn from what’s been added.  \nThis has long been a commitment for Ai2, which also offers a tool called OlmoTrace that tracks how LLM outputs match its training data.  \n\n“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said.",
    "publishedAt": "Fri, 12 Dec 2025 05:00:00 GMT",
    "author": "",
    "category": "AI",
    "originalContent": "<p>The Allen Institute for AI (Ai2) recently released what it calls its most powerful <a href=\"https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning\"><u>family of models yet, Olmo 3</u></a>. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.</p><p>The new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. </p><p>Ai2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. </p><p>Olmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. </p><p>Ai2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. </p><p>“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a <a href=\"https://allenai.org/blog/olmo3\"><u>blog post</u></a>. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”</p><div></div><p>To get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.</p><p>Olmo 3.1 Instruct 32B is &quot;optimized for chat, tool use, &amp; multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a <a href=\"https://x.com/allen_ai/status/1999528338365247539\"><u>post on X</u></a>. </p><p>For now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. </p><h2>Better performance on benchmarks</h2><p>The Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. </p><p>Olmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. </p><p>Olmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.</p><p>“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. </p><div></div><p>Ai2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.</p><h2>Commitment to transparency and open source </h2><p>Ai2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. </p><p>Organizations could add to the model’s data mix and retrain it to also learn from what’s been added.  </p><p>This has long been a commitment for Ai2, which also offers a <a href=\"https://venturebeat.com/ai/whats-inside-the-llm-ai2-olmotrace-will-trace-the-source\"><u>tool called OlmoTrace</u></a> that tracks how LLM outputs match its training data.  </p><div></div><p>“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said. </p><p>\n\n\n\n\n\n</p>",
    "titleJa": "Ai2の新しいOlmo 3.1、強固な推論ベンチマークに向け強化学習トレーニングを拡張",
    "summaryJa": "Allen Institute for AI (Ai2)が、Olmo 3.1を発表。強化学習を拡張し、推論、数学、コーディング性能が向上。透明性とオープンソースを重視。",
    "explanationJa": "Ai2が開発したOlmo 3.1は、強化学習トレーニングを強化し、より高度な推論能力を実現するモデルです。",
    "translationJa": "Allen Institute for AI (Ai2) は最近、Olmo 3と呼ばれる、これまでで最も強力なモデル群をリリースしました。しかし、同社はモデルの反復を続け、強化学習（RL）の実行を拡大して、Olmo 3.1 を作成しました。\n\n新しい Olmo 3.1 モデルは、企業向けの効率、透明性、および制御に重点を置いています。\n\nAi2 は、Olmo 2 の 3 つのバージョンのうちの 2 つを更新しました。高度な研究向けに最適化されたフラッグシップモデルである Olmo 3.1 Think 32B と、指示に従うこと、複数ターンの対話、およびツール使用のために設計された Olmo 3.1 Instruct 32B です。\n\nOlmo 3 には、プログラミング、理解、および数学のための 3 番目のバージョンである Olmo 3-Base もあります。また、継続的な微調整にも適しています。\n\nAi2 は、Olmo 3 Think 32B を Olmo 3.1 にアップグレードするために、研究者たちは最高の RL 実行をより長いトレーニングスケジュールで拡張したと述べています。\n\n「元の Olmo 3 の発売後、Olmo 3 32B Think の RL トレーニング実行を再開し、Dolci-Think-RL データセット上で追加のエポックで 224 個の GPU でさらに 21 日間トレーニングしました」と Ai2 はブログ投稿で述べています。「これにより、Olmo 3.1 32B Think が生まれ、数学、推論、および指示に従うベンチマーク全体で大幅な向上をもたらします。AIME で 5 ポイント以上、ZebraLogic で 4 ポイント以上、IFEval で 4 ポイント以上、IFBench で 20 ポイント以上の改善、およびコーディングと複雑な複数ステップタスクでのより強力なパフォーマンスを実現します。」\n\nOlmo 3.1 Instruct を実現するために、Ai2 は、より小さな Instruct サイズである 7B の背後にあるレシピを、より大きなモデルに適用したと述べています。\n\nOlmo 3.1 Instruct 32B は、「チャット、ツール使用、および複数ターンの対話に最適化されており、Olmo 3 Instruct 7B のパフォーマンスが大幅に向上した兄弟であり、実際のアプリケーションに対応できます」と Ai2 は X の投稿で述べています。\n\n今のところ、新しいチェックポイントは Ai2 Playground または Hugging Face で入手可能で、API アクセスは近日中に提供されます。\n\nベンチマークでのより優れたパフォーマンス\n\nOlmo 3.1 モデルは、ベンチマークテストで優れたパフォーマンスを発揮し、予想どおり Olmo 3 モデルを上回りました。\n\nOlmo 3.1 Think は、AIME 2025 ベンチマークで Qwen 3 32B モデルを上回り、Gemma 27B に近いパフォーマンスを発揮しました。\n\nOlmo 3.1 Instruct は、オープンソースのピアに対して強力なパフォーマンスを発揮し、Math ベンチマークでは Gemma 3 のようなモデルさえも上回りました。\n\n「Olmo 3.1 32B Instruct に関しては、チャット、ツール使用、および複数ターンの対話のために構築された、より大規模な指示調整モデルです。Olmo 3.1 32B Instruct は、これまでのところ最も有能な完全にオープンなチャットモデルであり、当社の評価では、最も強力な完全にオープンな 32B スケールの指示モデルです」と同社は述べています。\n\nAi2 はまた、数学とコーディングのために RL-Zero 7B モデルをアップグレードしました。同社は X で、両方のモデルがより長く、より安定したトレーニング実行から恩恵を受けたことを述べています。\n\n透明性とオープンソースへのコミットメント\n\nAi2 は以前、VentureBeat に、Olmo 3 モデル群を、企業や研究機関がモデルに入力されたデータとトレーニングをより詳細に制御し、理解できるように設計したと述べています。\n\n組織はモデルのデータミックスに追加し、再トレーニングして、追加されたものから学習することもできます。\n\nこれは Ai2 にとって長年の取り組みであり、LLM 出力がそのトレーニングデータとどのように一致するかを追跡する OlmoTrace と呼ばれるツールも提供しています。\n\n「Olmo 3.1 Think 32B と Olmo 3.1 Instruct 32B を合わせると、オープン性とパフォーマンスが共に向上できることがわかります。同じモデルフローを拡張することで、データ、コード、およびトレーニングの決定に対するエンドツーエンドの透明性を維持しながら、機能を継続的に向上させています」と Ai2 は述べています。",
    "insightJa": "Olmo 3.1の登場により、企業はより透明性の高いAIモデルを業務に活用しやすくなります。特定のデータセットで再学習させることで、自社のニーズに最適化されたAIを構築できるでしょう。",
    "recommendedBooks": [
      "大規模言語モデル",
      "強化学習 実践",
      "オープンソースAI"
    ],
    "tags": [
      "AI",
      "強化学習",
      "自然言語処理",
      "オープンソース",
      "LLM"
    ],
    "imageUrl": "https://images.pexels.com/photos/20457109/pexels-photo-20457109.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "title": "Trump signs AI executive order pushing to ban state laws",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "summary": "President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t\n\nOn Thursday evening, with White House AI and crypto czar David Sacks looking over his shoulder, Donald Trump signed an executive order aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order can't by itself unilaterally override state AI laws, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.\nIt specifically calls out Colorado's recently passed consumer protection law, making the claim that \"banning 'algorithmic discri …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T01:18:46.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks in the Oval Office\" data-caption=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/gettyimages-2251458899.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tPresident Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">On Thursday evening, with White House AI and crypto czar David Sacks <a href=\"https://www.youtube.com/live/rYDbVjXu5os?si=TUpA0_o7ORLU9jZh&amp;t=737\">looking over his shoulder</a>, Donald Trump <a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/\">signed an executive order</a> aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order <a href=\"https://www.theverge.com/column/829938/leaked-ai-executive-order-analysis\">can't by itself unilaterally override state AI laws</a>, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.</p>\n<p class=\"has-text-align-none\">It specifically calls out Colorado's <a href=\"https://leg.colorado.gov/bills/sb24-205\">recently passed consumer protection law</a>, making the claim that \"banning 'algorithmic discri …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "トランプ大統領、AI規制に関する大統領令に署名、州法を制限へ",
    "summaryJa": "トランプ大統領がAI規制に関する大統領令に署名。州法の影響を抑制し、連邦政府によるAI規制を強化する狙い。",
    "explanationJa": "トランプ大統領がAIに関する大統領令に署名し、AI規制における連邦政府の権限を強化しようとしています。",
    "translationJa": "木曜日の夕方、ホワイトハウスのAI・暗号資産担当官であるデイビッド・サックスが見守る中、ドナルド・トランプ大統領は、人工知能の規制に関して連邦政府が一方的な権限を掌握することを目的とした大統領令に署名しました。この大統領令自体は、州のAI法を一方的に覆すことはできませんが、連邦機関に対し、州法の影響を軽減または排除するための措置を講じるよう指示し、連邦政府が異議を唱える可能性のある法律や、他のプログラムに対する重要な資金提供を危険にさらす可能性のある法律を州が制定することを抑制します。具体的には、コロラド州で最近可決された消費者保護法を取り上げ、「アルゴリズムによる差別」を禁止することを問題視しています。",
    "insightJa": "AI規制はビジネスだけでなく、私たちの生活にも深く関わる可能性があります。例えば、AIによる審査の透明性や公平性が確保されることで、不当な差別を防ぐことに繋がります。",
    "recommendedBooks": [
      "人工知能 規制",
      "AI ガバナンス",
      "機械学習 法規制"
    ],
    "tags": [
      "AI",
      "Artificial Intelligence",
      "Regulation",
      "Trump",
      "大統領令",
      "規制"
    ],
    "imageUrl": "https://images.pexels.com/photos/20457109/pexels-photo-20457109.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://techcrunch.com/?p=3075457",
    "title": "Google launched its deepest AI research agent yet — on the same day OpenAI dropped GPT-5.2",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/",
    "summary": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "publishedAt": "Fri, 12 Dec 2025 00:18:56 +0000",
    "author": "Julie Bort",
    "category": "AI",
    "originalContent": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "titleJa": "Googleが最新のAI研究エージェントを発表 - OpenAIがGPT-5.2を公開した同日に",
    "summaryJa": "GoogleはGemini 3 Proを基盤としたDeep Researchツールを公開。開発者はこれを自身のアプリに組み込めるようになりました。",
    "explanationJa": "Googleの最新AI技術が公開され、より多くのアプリケーションで利用できるようになりました。",
    "translationJa": "今回初めて、開発者はGemini 3 Proを基盤とするGoogleのDeep Researchツールを自身のアプリに組み込むことができるようになりました。",
    "insightJa": "この技術により、AIを活用したアプリケーション開発が加速し、より高度な情報検索や分析が身近になる可能性があります。ビジネスにおいては、業務効率化や新たなサービスの創出に貢献することが期待されます。",
    "recommendedBooks": [
      "深層学習",
      "自然言語処理",
      "AI アプリケーション"
    ],
    "tags": [
      "AI",
      "Google",
      "Gemini 3 Pro",
      "Deep Research",
      "OpenAI"
    ],
    "imageUrl": "https://images.pexels.com/photos/25626433/pexels-photo-25626433.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "7iBvnTz8OK7lcxexlxh4OW",
    "title": "Google’s new framework helps AI agents spend their compute and tool budget more wisely",
    "source": "rss",
    "url": "https://venturebeat.com/ai/googles-new-framework-helps-ai-agents-spend-their-compute-and-tool-budget",
    "summary": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.\nAs AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.\nFor enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.\nThe challenge of scaling tool use\nTraditional test-time scaling focuses on letting models \"think\" longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.\nThis introduces significant operational overhead for businesses. \"Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,\" Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. \"Tool calls themselves introduce additional API costs.\"\nThe researchers found that simply granting agents more test-time resources does not guarantee better performance. \"In a deep research task, if the agent has no sense of budget, it often goes down blindly,\" Wang and Liu explained. \"It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.\"\nOptimizing resources with Budget Tracker\nTo evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called \"Budget Tracker.\" This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.\nThe team hypothesized that \"providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.\"\nBudget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)\nIn Google's implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.\nTo test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.\nThey tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as Gemini 2.5 Pro, Gemini 2.5 Flash, and Claude Sonnet 4. The experiments show that this simple plug-in improves performance across various budget constraints.\n\"Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,\" the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.\nBATS: A comprehensive framework for budget-aware scaling\nTo further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent's behavior as it formulates its response.\nBATS uses multiple modules to orchestrate the agent's actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to \"dig deeper\" into a promising lead or \"pivot\" to alternative paths based on resource availability.\nGiven an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.\nThe iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.\nThe researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.\nBATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.\nAccording to the authors, this efficiency makes previously expensive workflows viable. \"This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,\" they said.\nAs enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.\n\"We believe the relationship between reasoning and economics will become inseparable,\" Wang and Liu said. \"In the future, [models] must reason about value.\"",
    "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
    "author": "bendee983@gmail.com (Ben Dickson)",
    "category": "AI",
    "originalContent": "<p>In a <a href=\"https://arxiv.org/abs/2511.17006\"><u>new paper</u></a> that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple &quot;Budget Tracker&quot; and a more comprehensive framework called &quot;Budget Aware Test-time Scaling.&quot; These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.</p><p>As AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.</p><p>For enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.</p><h2>The challenge of scaling tool use</h2><p>Traditional <a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>test-time scaling</u></a> focuses on letting models &quot;think&quot; longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.</p><p>This introduces significant operational overhead for businesses. &quot;Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,&quot; Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. &quot;Tool calls themselves introduce additional API costs.&quot;</p><p>The researchers found that simply granting agents more test-time resources does not guarantee better performance. &quot;In a deep research task, if the agent has no sense of budget, it often goes down blindly,&quot; Wang and Liu explained. &quot;It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.&quot;</p><h2>Optimizing resources with Budget Tracker</h2><p>To evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called &quot;Budget Tracker.&quot; This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.</p><p>The team hypothesized that &quot;providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.&quot;</p><p>Budget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)</p><p>In Google&#x27;s implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.</p><p>To test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.</p><p>They tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as <a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>, Gemini 2.5 Flash, and <a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>. The experiments show that this simple plug-in improves performance across various budget constraints.</p><p>&quot;Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,&quot; the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.</p><h2>BATS: A comprehensive framework for budget-aware scaling</h2><p>To further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent&#x27;s behavior as it formulates its response.</p><p>BATS uses multiple modules to orchestrate the agent&#x27;s actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to &quot;dig deeper&quot; into a promising lead or &quot;pivot&quot; to alternative paths based on resource availability.</p><p>Given an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.</p><p>The iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.</p><p>The researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.</p><p>BATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.</p><p>According to the authors, this efficiency makes previously expensive workflows viable. &quot;This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,&quot; they said.</p><p>As enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.</p><p>&quot;We believe the relationship between reasoning and economics will become inseparable,&quot; Wang and Liu said. &quot;In the future, [models] must reason about value.&quot;</p><p>\n</p>",
    "titleJa": "Googleの新フレームワーク、AIエージェントの計算資源とツール利用をより賢く配分",
    "summaryJa": "Googleの研究者は、LLMエージェントがツールと計算資源の予算を効率的に利用できるフレームワークを開発しました。",
    "explanationJa": "Googleが、AIエージェントがコストを抑えつつ賢くツールを使える新技術を開発しました。",
    "translationJa": "大規模言語モデル（LLM）エージェントにおけるツール利用を研究した新しい論文で、GoogleとUCサンタバーバラの研究者たちは、エージェントがツールと計算資源の予算をより効率的に利用できるようにするフレームワークを開発しました。研究者たちは、シンプルな「バジェットトラッカー」と、より包括的なフレームワークである「予算認識型テスト時スケーリング（BATS）」という2つの新しい技術を紹介しました。これらの技術により、エージェントは残りの推論とツール利用の許容量を明確に認識できます。\n\nAIエージェントが現実世界で機能するためにツール呼び出しに依存するにつれて、テスト時スケーリングは、より賢いモデルというよりも、コストとレイテンシーを制御することに重点が置かれるようになりました。\n\n企業リーダーや開発者にとって、予算認識型スケーリング技術は、予測不可能なコストや計算資源の支出による収益逓減に直面することなく、効果的なAIエージェントを展開するための実用的な道を提供します。\n\nツール利用のスケーリングの課題\n従来のテスト時スケーリングは、モデルがより長く「考える」ことに焦点を当てています。しかし、ウェブブラウジングのようなエージェントタスクでは、ツール呼び出しの数が探索の深さと幅を直接決定します。\n\nこれは企業にとって重大な運用上のオーバーヘッドをもたらします。「ウェブページのブラウジングなどのツール呼び出しは、より多くのトークン消費につながり、コンテキストの長さを増やし、追加の時間レイテンシーをもたらします」と、論文の共著者であるZifeng WangとTengxiao LiuはVentureBeatに語っています。「ツール呼び出し自体が追加のAPIコストをもたらします。」\n\n研究者たちは、エージェントにテスト時のリソースを多く与えるだけでは、パフォーマンスの向上は保証されないことを発見しました。「深い研究タスクでは、エージェントが予算感覚を持たない場合、しばしば盲目的に進んでしまいます」とWangとLiuは説明しました。「多少関連のある手がかりを見つけると、それに10回または20回のツール呼び出しを費やして掘り下げますが、そのパス全体が袋小路であったことに気づきます。」\n\nバジェットトラッカーによるリソースの最適化\nツール利用予算をどのように最適化できるかを評価するために、研究者たちは最初に「バジェットトラッカー」と呼ばれる軽量なアプローチを試しました。このモジュールは、リソースの可用性に関する継続的な信号をエージェントに提供するプラグインとして機能し、予算を意識したツール利用を可能にします。\n\nチームは、「明示的な予算信号を提供することで、モデルは追加のトレーニングを必要とせずにリソース制約を内面化し、戦略を適応させることができる」と仮説を立てました。\n\nバジェットトラッカーは完全にプロンプトレベルで動作するため、実装が容易です。（論文には、バジェットトラッカーに使用されるプロンプトの詳細が完全に記載されており、実装が容易になっています。）\n\nGoogleの実装では、トラッカーは予算体制とそれに対応するツールの使用に関する推奨事項を記述した簡単なポリシーガイドラインを提供します。応答プロセスの各ステップで、バジェットトラッカーはエージェントにリソース消費と残りの予算を明確に認識させ、後続の推論ステップを更新されたリソース状態に基づいて条件付けることができます。\n\nこれをテストするために、研究者たちは、モデルがその出力を反復的に改善するシーケンシャルスケーリングと、複数の独立した実行が実行され集計されるパラレルスケーリングという2つのパラダイムを実験しました。彼らは、ReActスタイルのループに従って検索およびブラウズツールを備えた検索エージェントで実験を行いました。ReAct（Reasoning + Acting）は、モデルが内部思考と外部アクションを交互に行う一般的な方法です。真のコストパフォーマンスのスケーリングトレンドを追跡するために、彼らは内部トークン消費と外部ツールインタラクションの両方のコストを共同で考慮する統一コストメトリックを開発しました。\n\n彼らは、Gemini 2.5 Pro、Gemini 2.5 Flash、Claude Sonnet 4などのモデルを使用して、BrowseCompやHLE-Searchなどの外部検索を必要とする3つの情報検索QAデータセットでバジェットトラッカーをテストしました。実験では、このシンプルなプラグインがさまざまな予算制約にわたってパフォーマンスを向上させることが示されています。\n\n「バジェットトラッカーを追加すると、検索呼び出しが40.4％減少し、ブラウズ呼び出しが19.9％減少し、全体的なコストが31.3％削減され、同等の精度が達成されます」と著者らはVentureBeatに語っています。最後に、バジェットトラッカーは予算が増加するにつれて引き続きスケールしましたが、プレーンなReActはあるしきい値を超えると停滞しました。\n\nBATS：予算認識型スケーリングのための包括的なフレームワーク\nツール利用リソースの最適化をさらに改善するために、研究者たちは、与えられた予算下でエージェントのパフォーマンスを最大化するように設計されたフレームワークである予算認識型テスト時スケーリング（BATS）を導入しました。BATSは、残りのリソースに関する継続的な信号を維持し、この情報を使用して、エージェントが応答を策定する際に動的にその動作を適応させます。\n\nBATSは、複数のモジュールを使用してエージェントのアクションを調整します。計画モジュールは、ステップごとの労力を現在の予算に合わせて調整し、検証モジュールは、有望な手がかりを「深く掘り下げる」か、リソースの可用性に基づいて代替パスに「ピボット」するかを決定します。\n\n情報検索の質問とツール呼び出しの予算が与えられた場合、BATSは最初に計画モジュールを使用して、構造化されたアクションプランを策定し、どのツールを呼び出すかを決定します。ツールが呼び出されると、その応答が推論シーケンスに追加され、新しい証拠を含むコンテキストが提供されます。エージェントが候補回答を提案すると、検証モジュールがそれを検証し、現在のシーケンスを続行するか、残りの予算で新しい試行を開始するかを決定します。\n\n予算化されたリソースが使い果たされると、反復プロセスが終了し、その時点でLLM-as-a-judgeがすべての検証済み回答から最良の回答を選択します。実行全体を通して、バジェットトラッカーは、すべてのイテレーションでリソースの使用量と残りの予算の両方を継続的に更新します。\n\n研究者たちは、標準的なReActやさまざまなトレーニングベースのエージェントを含むベースラインに対して、BrowseComp、BrowseComp-ZH、およびHLE-SearchベンチマークでBATSをテストしました。彼らの実験は、BATSが競合する方法よりも少ないツール呼び出しを使用し、全体的なコストを低く抑えながら、より高いパフォーマンスを達成することを示しています。Gemini 2.5 Proをバックボーンとして使用すると、BATSはBrowseCompで24.6％の精度を達成しましたが、標準的なReActでは12.6％、HLE-Searchでは27.0％を達成しましたが、ReActでは20.5％でした。\n\nBATSは、予算制約下での有効性を向上させるだけでなく、より優れたコストパフォーマンスのトレードオフも実現します。たとえば、BrowseCompデータセットでは、BATSは約23セントのコストでより高い精度を達成しましたが、同様の結果を達成するには、パラレルスケーリングベースラインでは50セント以上が必要でした。\n\n著者らによると、この効率により、これまで高価だったワークフローが実現可能になります。「これにより、複雑なコードベースの保守、デューデリジェンス調査、競争環境の調査、コンプライアンス監査、および多段階ドキュメント分析など、長期にわたるデータ集約型のエンタープライズアプリケーションの範囲が広がります」と述べています。\n\n企業が独自のリソースを管理するエージェントを展開することを検討するにつれて、精度とコストのバランスを取る能力が重要な設計要件になります。\n\n「推論と経済学の関係は切り離せなくなるだろう」とWangとLiuは述べています。「将来的には、（モデルは）価値について推論しなければならない。」",
    "insightJa": "この技術により、企業はAIエージェントをより手頃な価格で利用できるようになり、業務効率化や新たなビジネスチャンスにつながる可能性があります。",
    "recommendedBooks": [
      "AIエージェント 開発",
      "大規模言語モデル 実践",
      "AI プロンプト エンジニアリング"
    ],
    "tags": [
      "AI Agents",
      "LLM",
      "Budget Aware Scaling",
      "Tool Use",
      "コスト最適化"
    ],
    "imageUrl": "https://images.pexels.com/photos/30839686/pexels-photo-30839686.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "6h3LTzDwRwKFT22aRVaumY",
    "title": "GPT-5.2 first impressions: a powerful update, especially for business tasks and workflows",
    "source": "rss",
    "url": "https://venturebeat.com/ai/gpt-5-2-first-impressions-a-powerful-update-especially-for-business-tasks",
    "summary": "OpenAI has officially released GPT-5.2, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming \"incremental\" update for casual conversationalists.\nFollowing early access periods and today's broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. \nHere is a roundup of the first reactions to OpenAI’s latest flagship model.\n\"AI as a serious analyst\"\nThe strongest praise for GPT-5.2 centers on its ability to handle \"hard problems\" that require extended thinking time.\nMatt Shumer, CEO of HyperWriteAI, did not mince words in his review, calling GPT-5.2 Pro \"the best model in the world.\" \nShumer highlighted the model's tenacity, noting that \"it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.\"\nThis sentiment was echoed by Allie K. Miller, an AI entrepreneur and former AWS executive. Miller described the model as a step toward \"AI as a serious analyst\" rather than a \"friendly companion.\"\n\"The thinking and problem-solving feel noticeably stronger,\" Miller wrote on X. \"It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.\"\nEnterprise gains: Box reports distinct performance jumps\nFor the enterprise sector, the update appears to be even more significant. \nAaron Levie, CEO of Box, revealed on X that his company has been testing GPT-5.2 in early access. Levie reported that the model performs \"7 points better than GPT-5.1\" on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.\n\"The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,\" Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.\nRutuja Rajwade, a Senior Product Marketing Manager at Box, expanded on this in a company blog post, citing specific latency improvements. \n\"Complex extraction\" tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. \nRajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.\nA \"serious leap\" for coding and simulation\nDevelopers are finding GPT-5.2 particularly potent for \"one-shot\" generation of complex code structures.\nPietro Schirano, CEO of magicpathai, shared a video of the model building a full 3D graphics engine in a single file with interactive controls. \"It’s a serious leap forward in complex reasoning, math, coding, and simulations,\" Schirano posted. \"The pace of progress is unreal.\"\n\nSimilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, demonstrated the model's ability to create a visually complex shader—an infinite neo-gothic city in a stormy ocean—via a single prompt.\nThe Agentic Era: Long-running autonomy\nPerhaps the most functional shift is the model's ability to stay on task for hours without losing the thread.\nDan Shipper, CEO of thoughtful AI testing newsletter Every, reported that the model successfully performed a profit and loss (P&L) analysis that required it to work autonomously for two hours. \"It did a P&L analysis where it worked for 2 hours and gave me great results,\" Shipper wrote.\nHowever, Shipper also noted that for day-to-day tasks, the update feels \"mostly incremental.\" \nIn an article for Every, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is \"less resourceful\" than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user's location from email data.\nThe downsides: Speed and Rigidity\nDespite the reasoning capabilities, the \"feel\" of the model has drawn critique.\nShumer highlighted a significant \"speed penalty\" when using the model's Thinking mode. \"In my experience the Thinking mode is very slow for most questions,\" Shumer wrote in his deep-dive review. \"I almost never use Instant.\"\nAllie Miller also pointed out issues with the model's default behavior. \"The downside is tone and format,\" she noted. \"The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.\"\nThe Verdict\nThe early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: \"For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.\"\nHowever, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. \"My favorite model remains Claude Opus 4.5,\" Miller admitted, \"but my complex ChatGPT work will get a nice incremental boost.\"",
    "publishedAt": "Thu, 11 Dec 2025 23:26:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>OpenAI has officially <a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">released GPT-5.2</a>, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming &quot;incremental&quot; update for casual conversationalists.</p><p>Following early access periods and today&#x27;s broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. </p><p>Here is a roundup of the first reactions to OpenAI’s latest flagship model.</p><h3><b>&quot;AI as a serious analyst&quot;</b></h3><p>The strongest praise for GPT-5.2 centers on its ability to handle &quot;hard problems&quot; that require extended thinking time.</p><p>Matt Shumer, CEO of HyperWriteAI, did not mince words in <a href=\"https://shumer.dev/gpt52review\">his review</a>, calling GPT-5.2 Pro &quot;the best model in the world.&quot; </p><p>Shumer highlighted the model&#x27;s tenacity, noting that &quot;it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.&quot;</p><p>This sentiment was<a href=\"https://x.com/alliekmiller/status/1999189893910790427\"> echoed by Allie K. Miller</a>, an AI entrepreneur and former AWS executive. Miller described the model as a step toward &quot;AI as a serious analyst&quot; rather than a &quot;friendly companion.&quot;</p><p>&quot;The thinking and problem-solving feel noticeably stronger,&quot; Miller wrote on X. &quot;It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.&quot;</p><h3><b>Enterprise gains: Box reports distinct performance jumps</b></h3><p>For the enterprise sector, the update appears to be even more significant. </p><p><a href=\"https://x.com/levie/status/1999191612321391058\">Aaron Levie, CEO of Box, revealed on X</a> that his company has been testing GPT-5.2 in early access. Levie reported that the model performs &quot;7 points better than GPT-5.1&quot; on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.</p><p>&quot;The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,&quot; Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.</p><p>Rutuja Rajwade, a Senior Product Marketing Manager at Box, <a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">expanded on this in a company blog post</a>, citing specific latency improvements. </p><p>&quot;Complex extraction&quot; tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. </p><p>Rajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.</p><h3><b>A &quot;serious leap&quot; for coding and simulation</b></h3><p>Developers are finding GPT-5.2 particularly potent for &quot;one-shot&quot; generation of complex code structures.</p><p>Pietro Schirano, CEO of magicpathai, <a href=\"https://x.com/skirano/status/1999182295685644366\">shared a video </a>of the model building a full 3D graphics engine in a single file with interactive controls. &quot;It’s a serious leap forward in complex reasoning, math, coding, and simulations,&quot; Schirano posted. &quot;The pace of progress is unreal.&quot;</p><div></div><p>S<!-- -->imilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, <a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">demonstrated the model&#x27;s ability to create a visually complex shader</a>—an infinite neo-gothic city in a stormy ocean—via a single prompt.</p><h3><b>The Agentic Era: Long-running autonomy</b></h3><p>Perhaps the most functional shift is the model&#x27;s ability to stay on task for hours without losing the thread.</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">Dan Shipper, CEO of thoughtful AI testing newsletter Every</a>, reported that the model successfully performed a profit and loss (P&amp;L) analysis that required it to work autonomously for two hours. &quot;It did a P&amp;L analysis where it worked for 2 hours and gave me great results,&quot; Shipper wrote.</p><p>However, Shipper also noted that for day-to-day tasks, the update feels &quot;mostly incremental.&quot; </p><p>In <a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">an article for Every</a>, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is &quot;less resourceful&quot; than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user&#x27;s location from email data.</p><h3><b>The downsides: Speed and Rigidity</b></h3><p>Despite the reasoning capabilities, the &quot;feel&quot; of the model has drawn critique.</p><p>Shumer highlighted a significant &quot;speed penalty&quot; when using the model&#x27;s Thinking mode. &quot;In my experience the Thinking mode is very slow for most questions,&quot; Shumer wrote in his deep-dive review. &quot;I almost never use Instant.&quot;</p><p>Allie Miller also pointed out issues with the model&#x27;s default behavior. &quot;The downside is tone and format,&quot; she noted. &quot;The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.&quot;</p><h3><b>The Verdict</b></h3><p>The early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: &quot;For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.&quot;</p><p>However, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. &quot;My favorite model remains Claude Opus 4.5,&quot; Miller admitted, &quot;but my complex ChatGPT work will get a nice incremental boost.&quot;</p>",
    "titleJa": "GPT-5.2の第一印象：ビジネス業務とワークフローに特に強力なアップデート",
    "summaryJa": "GPT-5.2は、深い推論とコーディングで大幅な進歩。ビジネス分野で特に有効だが、日常会話では小幅な改善にとどまるという評価もある。",
    "explanationJa": "GPT-5.2は、特にビジネスにおいて、より複雑な問題解決やコーディング能力が向上したモデルです。",
    "translationJa": "OpenAIは正式にGPT-5.2をリリースしました。初期テスターからの反応は二つに分かれており、深い自律的な推論とコーディングにおいては飛躍的な進歩である一方、カジュアルな会話をする人々にとっては「漸進的な」アップデートに過ぎない可能性があります。\n\n早期アクセス期間と本日の広範なロールアウトに続き、経営幹部、開発者、アナリストはX（旧Twitter）や企業のブログで最初のテスト結果を共有しています。\n\nOpenAIの最新フラッグシップモデルに対する最初の反応のまとめは次のとおりです。\n\n\"真剣なアナリストとしてのAI\"\n\nGPT-5.2に対する最も強い称賛は、「困難な問題」を処理する能力、つまり、より長い思考時間を必要とする能力に集中しています。\n\nHyperWriteAIのCEOであるMatt Shumerは、彼のレビューで言葉を濁さず、GPT-5.2 Proを「世界最高のモデル」と呼んでいます。\n\nShumerはモデルの粘り強さを強調し、「難しい問題については1時間以上考えます。そして、他のモデルでは対応できないタスクをこなします」と述べています。\n\nこの感情は、AI起業家であり、元AWS幹部であるAllie K. Millerによっても反映されました。Millerは、このモデルを「友好的な仲間」ではなく、「真剣なアナリストとしてのAI」への一歩と表現しました。\n\n「思考と問題解決は著しく強力に感じられます」とMillerはXに書き込みました。「私が慣れているよりもはるかに深い説明をしてくれます。ある時点では、タスクの途中で独自のOCRを改善するためのコードを文字通り書いていました。」\n\nエンタープライズの利点：Boxは明確なパフォーマンスの向上を報告\n\nエンタープライズセクターにとって、このアップデートはさらに重要なようです。\n\nBoxのCEOであるAaron Levieは、彼の会社が早期アクセスでGPT-5.2をテストしていることをXで明らかにしました。Levieは、金融サービスやライフサイエンスにおける現実世界の知識労働に近い、彼らの拡張された推論テストで、モデルが「GPT-5.1よりも7ポイント優れている」と報告しました。\n\n「モデルは、GPT-5.1やGPT-5よりもはるかに高速にタスクの大部分を実行しました」とLevieは述べ、Box AIがGPT-5.2の統合を間もなく展開することを確認しました。\n\nBoxのシニアプロダクトマーケティングマネージャーであるRutuja Rajwadeは、企業ブログの投稿でこれを詳しく説明し、特定のレイテンシーの改善点を挙げています。\n\n「複雑な抽出」タスクは、GPT-5では46秒かかっていたものが、GPT-5.2ではわずか12秒に短縮されました。\n\nRajwadeはまた、メディアおよびエンターテインメントの垂直市場における推論能力の向上にも言及し、GPT-5.1の76％の精度から新しいモデルでは81％に上昇しました。\n\nコーディングとシミュレーションにおける「重大な飛躍」\n\n開発者は、GPT-5.2が複雑なコード構造の「ワンショット」生成に特に有効であると考えています。\n\nmagicpathaiのCEOであるPietro Schiranoは、インタラクティブなコントロールを備えた完全な3Dグラフィックスエンジンを1つのファイルで構築するモデルのビデオを共有しました。「複雑な推論、数学、コーディング、シミュレーションにおいて重大な飛躍です」とSchiranoは投稿しました。「進歩のペースは非現実的です。」\n\n同様に、ペンシルベニア大学ウォートン・スクールの教授であり、長年のLLMおよびAIパワーユーザー兼ライターであるEthan Mollickは、モデルが視覚的に複雑なシェーダー（嵐の海の無限のネオゴシック都市）を単一のプロンプトで作成する能力を実証しました。\n\nエージェント時代：長期的な自律性\n\nおそらく最も機能的な変化は、モデルが糸口を見失うことなく、何時間もタスクに取り組み続けることができることです。\n\n思慮深いAIテストニュースレターEveryのCEOであるDan Shipperは、モデルが2時間自律的に作業する必要がある損益（P＆L）分析を正常に実行したと報告しました。「2時間作業し、素晴らしい結果をもたらすP＆L分析を行いました」とShipperは書いています。\n\nただし、Shipperは、日常的なタスクでは、アップデートは「ほとんど漸進的」に感じられるとも述べています。\n\nEveryの記事で、Katie Parrottは、GPT-5.2は指示に従うことに優れている一方で、電子メールデータからユーザーの場所を推測するなど、特定の状況ではClaude Opus 4.5のような競合他社よりも「機転が利かない」と書いています。\n\n短所：速度と硬直性\n\n推論能力にもかかわらず、モデルの「感じ」には批判が集まっています。\n\nShumerは、モデルの思考モードを使用する際の重大な「速度ペナルティ」を強調しました。「私の経験では、思考モードはほとんどの質問に対して非常に遅いです」とShumerは彼の詳細なレビューに書いています。「インスタントはほとんど使用しません。」\n\nAllie Millerはまた、モデルのデフォルトの動作に関する問題も指摘しました。「欠点は、トーンと形式です」と彼女は指摘しました。「デフォルトの声は少し硬直的に感じられ、長さ/マークダウンの動作は極端です。単純な質問が58個の箇条書きと番号付きのポイントになりました。」\n\n判決\n\n初期の反応は、GPT-5.2がカジュアルなチャットではなく、パワーユーザー、開発者、およびエンタープライズエージェント向けに最適化されたツールであることを示唆しています。Shumerが彼のレビューで要約したように、「綿密な調査、複雑な推論、および注意深い思考から恩恵を受けるタスクの場合、GPT-5.2 Proは現在利用可能な最良のオプションです。」\n\nただし、創造的な文章や、すばやく流動的な回答を求めるユーザーにとっては、Claude Opus 4.5のようなモデルが依然として強力な競合相手です。「私のお気に入りのモデルはClaude Opus 4.5のままです」とMillerは認めました。「しかし、私の複雑なChatGPTの作業は、優れた漸進的な向上を遂げるでしょう。」",
    "insightJa": "GPT-5.2の登場で、ビジネスにおけるAI活用がさらに加速すると予想されます。日常業務の効率化や、より高度な分析が可能になることで、競争力強化に繋がるでしょう。",
    "recommendedBooks": [
      "GPT-5.2 活用",
      "大規模言語モデル ビジネス",
      "AI 業務効率化"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "AI",
      "LLM",
      "Business"
    ],
    "imageUrl": "https://images.pexels.com/photos/16629368/pexels-photo-16629368.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10957v1",
    "title": "SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10957v1",
    "summary": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "publishedAt": "2025-12-11T18:59:56Z",
    "author": "Yukai Shi",
    "category": "AI",
    "originalContent": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "titleJa": "SceneMaker：分離されたデ・オクルージョンと姿勢推定モデルによるオープンセット3Dシーン生成",
    "summaryJa": "SceneMakerは、遮蔽除去と姿勢推定を分離し、高品質な3Dシーン生成を実現。屋内・屋外シーンで優れた性能を発揮します。",
    "explanationJa": "SceneMakerは、隠れた部分を考慮しつつ、物体の正確な位置を把握して3D空間を作る技術です。",
    "translationJa": "本研究では、SceneMakerという分離された3Dシーン生成フレームワークを提案します。既存の手法では、十分なオープンセットのデ・オクルージョンと姿勢推定の事前知識が不足しているため、深刻な遮蔽やオープンセット環境下で、高品質な形状と正確な姿勢を同時に生成することが困難です。これらの問題に対処するため、まず、デ・オクルージョンモデルを3Dオブジェクト生成から分離し、画像データセットと収集されたデ・オクルージョンデータセットを活用して、より多様なオープンセットの遮蔽パターンに対応できるように強化します。次に、自己注意と交差注意の両方に対してグローバルメカニズムとローカルメカニズムを統合した、統一された姿勢推定モデルを提案し、精度を向上させます。さらに、姿勢推定モデルの汎化性能を向上させるために、オープンセットの3Dシーンデータセットを構築します。包括的な実験により、屋内およびオープンセットのシーンの両方において、提案する分離されたフレームワークの優位性が示されています。",
    "insightJa": "この技術は、ゲームやVRコンテンツの品質向上、自動運転における周囲認識の精度向上に貢献すると期待されます。また、建築設計や都市計画など、幅広い分野での応用が考えられます。",
    "recommendedBooks": [
      "3Dモデリング",
      "コンピュータビジョン",
      "画像認識"
    ],
    "tags": [
      "3D scene generation",
      "De-occlusion",
      "Pose estimation",
      "SceneMaker",
      "コンピュータビジョン"
    ],
    "imageUrl": "https://images.pexels.com/photos/8347500/pexels-photo-8347500.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10952v1",
    "title": "Hierarchical Dataset Selection for High-Quality Data Sharing",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10952v1",
    "summary": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Xiaona Zhou",
    "category": "AI",
    "originalContent": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "titleJa": "高品質なデータ共有のための階層的データセット選択",
    "summaryJa": "機械学習の成功は高品質な学習データに依存。データセット選択は重要だが、既存手法はデータセット間の差異を無視。DaSHは階層構造で効率的なデータセット選択を実現。",
    "explanationJa": "高品質な学習データセットを選ぶことで、機械学習の性能を向上させる研究です。",
    "translationJa": "現代の機械学習の成功は、高品質な学習データへのアクセスにかかっています。公共リポジトリからデータを取得したり、機関間でデータを共有したりするなど、多くの現実世界のシナリオでは、データは関連性、品質、有用性が異なる個別のデータセットとして自然に整理されています。したがって、有用なデータセットを検索するためにどのリポジトリまたは機関を選択するか、およびモデルトレーニングにどのデータセットを組み込むかを選択することは重要な決定事項ですが、既存の方法のほとんどは個々のサンプルを選択し、すべてのデータを同等に関連するものとして扱い、データセットとそのソース間の違いを無視しています。本研究では、データセット選択のタスクを定式化します。大規模で異質なプールからデータセット全体を選択し、リソース制約下でのダウンストリームパフォーマンスを向上させることです。データセットとグループ（コレクション、機関など）レベルの両方で有用性をモデル化し、限られた観測からの効率的な一般化を可能にするデータセット選択手法であるDataset Selection via Hierarchies（DaSH）を提案します。2つの公開ベンチマーク（Digit-FiveとDomainNet）において、DaSHは最先端のデータ選択ベースラインよりも最大26.2％精度が向上し、探索に必要なステップ数も大幅に少なくなっています。アブレーション実験の結果、DaSHは低リソース環境や関連データセットの不足に対してロバストであり、実用的なマルチソース学習ワークフローにおけるスケーラブルで適応的なデータセット選択に適していることが示されています。",
    "insightJa": "この技術が発展すれば、企業はより少ないコストで精度の高いAIモデルを開発できるようになります。例えば、マーケティング戦略の改善や顧客サービスの自動化などが期待できます。",
    "recommendedBooks": [
      "機械学習 実践",
      "データサイエンス 入門",
      "深層学習 理論"
    ],
    "tags": [
      "Dataset Selection",
      "Machine Learning",
      "Data Sharing",
      "階層的学習",
      "機械学習"
    ],
    "imageUrl": "https://images.pexels.com/photos/8294824/pexels-photo-8294824.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "http://arxiv.org/abs/2512.10949v1",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10949v1",
    "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "publishedAt": "2025-12-11T18:59:52Z",
    "author": "Yiwen Tang",
    "category": "AI",
    "originalContent": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "titleJa": "テキストから3D生成への強化学習の準備はできたか？段階的な調査",
    "summaryJa": "3D生成に強化学習を適用する研究。報酬設計、アルゴリズム、ベンチマーク、新しいパラダイムを調査し、RL強化モデルAR3D-R1を開発。",
    "explanationJa": "テキストから3Dモデルを作る技術に、強化学習という方法を取り入れる研究が進められています。",
    "translationJa": "強化学習（RL）は、大規模言語モデルやマルチモーダルモデルでその有効性がすでに証明されており、最近では2D画像生成を強化するために拡張されています。しかし、3D生成へのRLの適用は、3Dオブジェクトの空間的な複雑さが高いため、ほとんど探求されていません。3Dオブジェクトは、グローバルに一貫したジオメトリと、きめ細かいローカルテクスチャを必要とするためです。これにより、3D生成は報酬設計とRLアルゴリズムに非常に敏感になります。これらの課題に対処するために、テキストから3Dへの自己回帰生成に対するRLの最初の体系的な研究をいくつかの側面から行います。（1）報酬設計：報酬の次元とモデルの選択肢を評価し、人間の好みとの整合性が重要であること、および一般的なマルチモーダルモデルが3D属性に対して堅牢なシグナルを提供することを示します。（2）RLアルゴリズム：GRPOのバリアントを研究し、トークンレベルの最適化の有効性を強調し、トレーニングデータとイテレーションのスケーリングをさらに調査します。（3）テキストから3Dへのベンチマーク：既存のベンチマークは、3D生成モデルにおける暗黙的な推論能力を測定できないため、MME-3DRを導入します。（4）高度なRLパラダイム：3D生成の自然な階層構造に動機付けられ、専用の報酬アンサンブルを通じてグローバルからローカルへの階層的な3D生成を最適化するHi-GRPOを提案します。これらの洞察に基づいて、粗い形状からテクスチャの改良まで、最初のRL強化テキストから3DモデルであるAR3D-R1を開発します。この研究が、3D生成のためのRL駆動型推論への洞察を提供することを願っています。",
    "insightJa": "この技術が進歩することで、ゲームや映画などのエンターテイメント業界での3Dモデル作成が効率化される可能性があります。また、製品デザインや建築設計などの分野でも、アイデアの可視化が容易になることが期待されます。",
    "recommendedBooks": [
      "3Dモデリング 入門",
      "強化学習 理論と実践",
      "深層学習 3Dデータ"
    ],
    "tags": [
      "Reinforcement Learning",
      "Text-to-3D",
      "3D Generation",
      "Reward Design",
      "AR3D-R1"
    ],
    "imageUrl": "https://images.pexels.com/photos/17483874/pexels-photo-17483874.png?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "5AH2xqcQJzMolV09W5VM43",
    "title": "OpenAI's GPT-5.2 is here: what enterprises need to know",
    "source": "rss",
    "url": "https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know",
    "summary": "The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, GPT-5.2.\nIt comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival Google’s Gemini 3 LLM seized the top spot on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.\nOpenAI describes GPT-5.2 as its \"most capable model series yet for professional knowledge work,\" aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.\n\"It’s our most advanced frontier model and the strongest yet in the market for professional use,\" Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. \"We designed 5.2 to unlock even more economic value for people. It's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.\"\nGPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.\nThe model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes \"Reasoning token support,\" confirming the underlying architecture uses the chain-of-thought processing popularized by the \"o1\" series.\nThe 'Code Red' Reality Check\nThe release arrives following The Information's report of an emergency \"Code Red\" directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the \"quality gap\" exposed by Gemini 3. The Verge similarly reported on the timing of GPT-5.2's release ahead of the official announcement. \nDuring the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.\n\"It is important to note this has been in the works for many, many months,\" Simo told reporters. She clarified that while the \"Code Red\" helped focus the company, it wasn't the sole driver of the timeline. \n\"We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that's not the reason it's coming out this week in particular.\"\nMax Schwarzer, lead of OpenAI's post-training team, echoed this sentiment to dispel the idea of a panic launch. \"We've been planning for this release since a very long time ago... this specific week we talked about many months ago.\"\nA spokesperson from OpenAI further clarified that the \"Code Red\" call applied to ChatGPT as a product, not solely underlying model development or the release of new models.\nUnder the Hood: Instant, Thinking, and Pro\nOpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of \"reasoning\" models with user demand for speed:\n\nGPT-5.2 Instant: Optimized for speed and daily tasks like writing, translation, and information seeking.\n\nGPT-5.2 Thinking: Designed for \"complex, structured work\" and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.\n\nGPT-5.2 Pro: The new heavyweight champion. OpenAI describes this as its \"smartest and most trustworthy option,\" delivering the highest accuracy for difficult questions where quality outweighs latency.\n\nFor developers, the models are available immediately in the application programming interface (API) as gpt-5.2, gpt-5.2-chat-latest (Instant), and gpt-5.2-pro.\nThe Numbers: Beating the Benchmarks\nThe GPT-5.2 release includes leading metrics across most domains — specifically those that target the \"professional knowledge work\" gap where competitors have recently gained ground.\nOpenAI highlighted a new benchmark called GDPval, which measures performance on \"well-specified knowledge work tasks\" across 44 occupations. \n\"GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,\" Simo said.\nIn the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. \nHe emphasized that this benchmark is \"more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.\"Other key benchmark results include:\n\nGPQA Diamond (Science): GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).\n\nFrontierMath: On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.\n\nARC-AGI-1: GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring 90.5%\n\nThe Price of Intelligence\nPerformance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of \"thinking\" mode. They're also on the upper-end of API costs for the industry.  \n\nGPT-5.2 Thinking: Priced at $1.75 per 1 million input tokens and $14 per 1 million output tokens.\n\nGPT-5.2 Pro: The costs jump significantly to $21 per 1 million input tokens and $168 per 1 million output tokens.\n\nGPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.\nThe high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.\nOpenAI argues that despite the higher per-token cost, the model’s \"greater token efficiency\" and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.\nHere's how it compares to the current API costs for other competing models across the LLM field:\n\n\nModel\n\nInput (/1M)\n\nOutput (/1M)\n\nTotal Cost\n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nQwen 3 Plus\n\n$0.40\n\n$1.20\n\n$1.60\n\nAlibaba Cloud\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen-Max\n\n$1.60\n\n$6.40\n\n$8.00\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nClaude Opus 4.5\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nImage Generation: Nothing New Yet...But 'More to Come'\nDuring the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google's Gemini 3 Image aka Nano Banana Pro. \nUnfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI's integrated DALL-E 3 and gpt-4o native image generation models.\n\"On image Gen, nothing to announce today, but more to come,\" Simo said. She acknowledged the popularity of the feature, adding, \"We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.\" \nAidan Clark, OpenAI's lead of training, also declined to comment on visual generation specifics, stating simply, \"I can't really speak to image Gen myself.\" \nThe 'Mega-Agent' Era\nBeyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of \"long-running agents\" capable of executing multi-step workflows without human hand-holding.\"\nBox found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,\" Simo said. \nShe also noted that Notion reported the model \"outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.\"Schwarzer added that coding startups like Augment Code found the model \"delivered substantially stronger deep code capabilities than any prior model,\" which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. \nOpenAI's release blog post shows an example where \"a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.\"\nThe outcome? \"GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.\"\nA new evaluation called ScreenSpot-Pro, which tests a model's ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.\nScience and Reliability\nOpenAI leaders also stressed the model's utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. \nAidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.\n\"They tested it by asking it to generate the most important unanswered questions about the immune system,\" Clark said. \"That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.\n\"Reliability was another key focus. Schwarzer claimed the new model \"hallucinates substantially less than GPT-5.1,\" noting that on a set of de-identified queries, \"responses contained errors 38% less often.\"\nThe 'Vibe' Shift\nInterestingly, OpenAI acknowledged that not every user might immediately prefer the new models. \nWhen asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that \"models change a little bit every time.\n\"Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,\" Schwarzer said. He also noted that for some enterprise customers who have \"really fine-tuned a prompt for a specific model,\" there might be \"small regressions,\" necessitating access to the older versions.\nSafety, 'Adult Mode,' and Future Roadmap\nAddressing safety concerns, Simo confirmed that the company is preparing to roll out an \"Adult Mode\" in the first quarter of next year, following the implementation of a new age prediction system.\n\"We're in the process of improving that,\" Simo said regarding the age prediction technology. \n\"We want to do that ahead of launching adult mode.\"Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename \"Project Garlic,\" targeting a flagship release in early 2026. \nWhile executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.\n\"If you look at historical trends, compute has increased about 3x every year for the last three years,\" she explained. \"Revenue has also increased at the same pace... creating this virtuous cycle.\"\nClark added that efficiency is improving rapidly: \"The model we're releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it\" compared to models from a year ago.\nGPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.",
    "publishedAt": "Thu, 11 Dec 2025 18:16:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, <a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>.</p><p>It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival <a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">Google’s Gemini 3 LLM seized the top spot</a> on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.</p><p>OpenAI describes GPT-5.2 as its &quot;most capable model series yet for professional knowledge work,&quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.</p><p>&quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &quot;We designed 5.2 to unlock even more economic value for people. It&#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&quot;</p><p>GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.</p><p>The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &quot;Reasoning token support,&quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &quot;o1&quot; series.</p><h3><b>The &#x27;Code Red&#x27; Reality Check</b></h3><p>The release arrives following<i> </i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\"><i>The Information</i>&#x27;s report</a> of an emergency &quot;Code Red&quot; directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the &quot;quality gap&quot; exposed by Gemini 3.<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i> The Verge</i></a> similarly reported on the timing of GPT-5.2&#x27;s release ahead of the official announcement. </p><p>During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.</p><p>&quot;It is important to note this has been in the works for many, many months,&quot; Simo told reporters. She clarified that while the &quot;Code Red&quot; helped focus the company, it wasn&#x27;t the sole driver of the timeline. </p><p>&quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&#x27;s not the reason it&#x27;s coming out this week in particular.&quot;</p><p>Max Schwarzer, lead of OpenAI&#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &quot;We&#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&quot;</p><p>A spokesperson from OpenAI further clarified that the &quot;Code Red&quot; call applied to ChatGPT as a product, not solely underlying model development or the release of new models.</p><h3><b>Under the Hood: Instant, Thinking, and Pro</b></h3><p>OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &quot;reasoning&quot; models with user demand for speed:</p><ul><li><p><b>GPT-5.2 Instant:</b> Optimized for speed and daily tasks like writing, translation, and information seeking.</p></li><li><p><b>GPT-5.2 Thinking:</b> Designed for &quot;complex, structured work&quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.</p></li><li><p><b>GPT-5.2 Pro:</b> The new heavyweight champion. OpenAI describes this as its &quot;smartest and most trustworthy option,&quot; delivering the highest accuracy for difficult questions where quality outweighs latency.</p></li></ul><p>For developers, the models are available immediately in the application programming interface (API) as <code>gpt-5.2</code>, <code>gpt-5.2-chat-latest</code> (Instant), and <code>gpt-5.2-pro</code>.</p><h3><b>The Numbers: Beating the Benchmarks</b></h3><p>The GPT-5.2 release includes leading metrics across most domains — specifically those that target the &quot;professional knowledge work&quot; gap where competitors have recently gained ground.</p><p>OpenAI highlighted a new benchmark called GDPval, which measures performance on &quot;well-specified knowledge work tasks&quot; across 44 occupations. </p><p>&quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&quot; Simo said.</p><p>In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. </p><p>He emphasized that this benchmark is &quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&quot;Other key benchmark results include:</p><ul><li><p><b>GPQA Diamond (Science):</b> GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).</p></li><li><p><b>FrontierMath:</b> On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.</p></li><li><p><b>ARC-AGI-1:</b> GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring <b>90.5%</b></p></li></ul><h3><b>The Price of Intelligence</b></h3><p>Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &quot;thinking&quot; mode. They&#x27;re also on the upper-end of API costs for the industry.  </p><ul><li><p><b>GPT-5.2 Thinking:</b> Priced at <b>$1.75</b> per 1 million input tokens and <b>$14</b> per 1 million output tokens.</p></li><li><p><b>GPT-5.2 Pro:</b> The costs jump significantly to <b>$21</b> per 1 million input tokens and <b>$168</b> per 1 million output tokens.</p></li></ul><p>GPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.</p><p>The high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.</p><p>OpenAI argues that despite the higher per-token cost, the model’s &quot;greater token efficiency&quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.</p><p>Here&#x27;s how it compares to the current API costs for other competing models across the LLM field:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1M)</b></p></td><td><p><b>Output (/1M)</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>Image Generation: Nothing New Yet...But &#x27;More to Come&#x27;</b></h3><p>During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&#x27;s Gemini 3 Image aka Nano Banana Pro. </p><p>Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&#x27;s integrated DALL-E 3 and gpt-4o native image generation models.</p><p>&quot;On image Gen, nothing to announce today, but more to come,&quot; Simo said. She acknowledged the popularity of the feature, adding, &quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&quot; </p><p>Aidan Clark, OpenAI&#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &quot;I can&#x27;t really speak to image Gen myself.&quot; </p><h3><b>The &#x27;Mega-Agent&#x27; Era</b></h3><p>Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &quot;long-running agents&quot; capable of executing multi-step workflows without human hand-holding.&quot;</p><p>Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&quot; Simo said. </p><p>She also noted that Notion reported the model &quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&quot;Schwarzer added that coding startups like Augment Code found the model &quot;delivered substantially stronger deep code capabilities than any prior model,&quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. </p><p>OpenAI&#x27;s release blog post shows an example where &quot;a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.&quot;</p><p>The outcome? &quot;GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.&quot;</p><p>A new evaluation called ScreenSpot-Pro, which tests a model&#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.</p><h3><b>Science and Reliability</b></h3><p>OpenAI leaders also stressed the model&#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. </p><p>Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.</p><p>&quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&quot; Clark said. &quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.</p><p>&quot;Reliability was another key focus. Schwarzer claimed the new model &quot;hallucinates substantially less than GPT-5.1,&quot; noting that on a set of de-identified queries, &quot;responses contained errors 38% less often.&quot;</p><h3><b>The &#x27;Vibe&#x27; Shift</b></h3><p>Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. </p><p>When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &quot;models change a little bit every time.</p><p>&quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&quot; Schwarzer said. He also noted that for some enterprise customers who have &quot;really fine-tuned a prompt for a specific model,&quot; there might be &quot;small regressions,&quot; necessitating access to the older versions.</p><h3><b>Safety, &#x27;Adult Mode,&#x27; and Future Roadmap</b></h3><p>Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &quot;Adult Mode&quot; in the first quarter of next year, following the implementation of a new age prediction system.</p><p>&quot;We&#x27;re in the process of improving that,&quot; Simo said regarding the age prediction technology. </p><p>&quot;We want to do that ahead of launching adult mode.&quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &quot;Project Garlic,&quot; targeting a flagship release in early 2026. </p><p>While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.</p><p>&quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&quot; she explained. &quot;Revenue has also increased at the same pace... creating this virtuous cycle.&quot;</p><p>Clark added that efficiency is improving rapidly: &quot;The model we&#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&quot; compared to models from a year ago.</p><p>GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.</p>",
    "titleJa": "OpenAIのGPT-5.2発表：企業が知っておくべきこと",
    "summaryJa": "OpenAIがGPT-5.2を発表。推論、コーディング能力が向上。3つのモデルをAPIで提供。価格は高めだが、性能向上を強調。",
    "explanationJa": "OpenAIから新しい高性能なGPT-5.2が登場し、より高度な作業が可能になります。ビジネスでの活用が期待されます。",
    "translationJa": "噂は本当でした。OpenAIは木曜日、最新の巨大言語モデル（LLM）ファミリーであるGPT-5.2を発表しました。\n\nこれは、AIの先駆者であるOpenAIにとって重要な時期に発表されました。ライバルのGoogleがGemini 3 LLMで主要な第三者パフォーマンスリーダーボードや主要ベンチマークでトップの座を奪って以来、OpenAIはますますプレッシャーにさらされていました。しかし、OpenAIの幹部は記者会見で、今回のリリースはGemini 3のリリースよりもずっと前から議論され、準備されていたと強調しました。\n\nOpenAIはGPT-5.2を「プロフェッショナルな知識労働において、これまでで最も能力の高いモデルシリーズ」と表現し、推論、コーディング、およびエージェントワークフローにおける大幅な改善により、パフォーマンスの王座を取り戻すことを目指しています。\n\nOpenAIのアプリケーション担当CEOであるFidji Simoは、今日の記者会見で「これは当社の最先端のモデルであり、プロフェッショナルな用途において市場で最も強力なものです」と述べました。「5.2は、人々にとってより多くの経済的価値を引き出すように設計しました。スプレッドシートの作成、プレゼンテーションの作成、コードの記述、画像の認識、長文コンテキストの理解、ツールの使用、および複雑な複数ステップのプロジェクトの処理に優れています。」\n\nGPT-5.2は、40万トークンという大規模なコンテキストウィンドウを備えており、一度に数百のドキュメントまたは大規模なコードリポジトリを取り込むことができます。また、最大12万8千トークンの出力制限により、広範なレポートや完全なアプリケーションを一度に生成できます。\n\nこのモデルは、2025年8月31日までの知識カットオフを備えており、比較的新しい世界的な出来事や技術ドキュメントに遅れを取らないようにします。また、「推論トークンサポート」が明示的に含まれており、基盤となるアーキテクチャが「o1」シリーズで普及したchain-of-thought処理を使用していることを確認しています。\n\n「コードレッド」の現実\n\nこのリリースは、OpenAIのCEOであるSam AltmanがChatGPTを改善するためにOpenAIのスタッフに緊急の「コードレッド」指令を出したというThe Informationのレポートに続いて行われました。これは、Gemini 3によって露呈した「品質のギャップ」を受けてリソースを動員するために設計された動きであると伝えられています。The Vergeも同様に、公式発表に先立ち、GPT-5.2のリリース時期について報道しました。\n\n記者会見で、OpenAIの幹部はその指令を認めましたが、このモデルがGoogleに対応するためだけに急いで作成されたという話は否定しました。\n\n「これは何ヶ月も前から準備されていたものであることに注意することが重要です」とSimoは記者団に語りました。彼女は、「コードレッド」が会社の焦点を絞るのに役立ったが、それがタイムラインの唯一の推進力ではなかったと明らかにしました。\n\n「このコードレッドを発表したのは、特定の一つの分野にリソースを集中させたいというシグナルを会社に送るためでしたが…それが特に今週リリースされる理由ではありません。」\n\nOpenAIのポストトレーニングチームの責任者であるMax Schwarzerも、パニック的な発売という考えを払拭するために、この感情を繰り返しました。「私たちは非常に長い間、このリリースを計画してきました…特に今週について、何ヶ月も前に話し合っていました。」\n\nOpenAIの広報担当者はさらに、「コードレッド」の呼びかけは、新しいモデルの開発またはリリースだけでなく、製品としてのChatGPTに適用されると説明しました。\n\n内部構造：Instant、Thinking、およびPro\n\nOpenAIは、GPT-5.2のリリースをChatGPT内の3つの異なる層に分割しています。これは、「推論」モデルの莫大な計算コストと、速度に対するユーザーの需要のバランスを取るように設計された戦略であると考えられます。\n\nGPT-5.2 Instant：書き込み、翻訳、および情報検索などの日常的なタスクのために最適化されています。\n\nGPT-5.2 Thinking：「複雑で構造化された作業」および長期的なエージェント向けに設計されたこのモデルは、より深い推論チェーンを活用して、コーディング、数学、および複数ステップのプロジェクトを処理します。\n\nGPT-5.2 Pro：新しいヘビー級チャンピオン。OpenAIはこれを「最もスマートで信頼できるオプション」と表現し、品質が待ち時間よりも重要な難しい質問に対して最高の精度を提供します。\n\n開発者向けに、モデルはアプリケーションプログラミングインターフェース（API）で、gpt-5.2、gpt-5.2-chat-latest（Instant）、およびgpt-5.2-proとしてすぐに利用できます。\n\n数値：ベンチマークを打ち負かす\n\nGPT-5.2のリリースには、ほとんどのドメインにわたる主要な指標が含まれています。特に、競合他社が最近勢いを増している「プロフェッショナルな知識労働」のギャップをターゲットにしています。\n\nOpenAIは、GDPvalと呼ばれる新しいベンチマークを強調しました。これは、44の職業にわたる「明確に指定された知識労働タスク」のパフォーマンスを測定します。\n\n「GPT-5.2 Thinkingは、そのベンチマークで最先端であり…専門家である人間の審査員によると、スプレッドシート、プレゼンテーション、およびドキュメント作成などの明確に指定された専門的なタスクの70.9％で、業界のトッププロフェッショナルを打ち負かすか、同等の結果を出しています」とSimoは述べています。\n\nコーディングの重要な分野で、OpenAIは決定的なリードを主張しています。Schwarzerは、実際のソフトウェアエンジニアリングの厳密な評価であるSWE-bench Proで、GPT-5.2 Thinkingが55.6％という新しい最先端のスコアを設定したと述べました。\n\n彼は、このベンチマークが「SWE-bench Verifiedのような以前のベンチマークよりも、汚染耐性が高く、挑戦的で、多様で、業界に関連している」ことを強調しました。その他の主要なベンチマーク結果は次のとおりです。\n\nGPQA Diamond（科学）：GPT-5.2 Proは93.2％のスコアを獲得し、GPT-5.2 Thinking（92.4％）をわずかに上回り、GPT-5.1 Thinking（88.1％）を上回りました。\n\nFrontierMath：Tier 1〜3の問題では、GPT-5.2 Thinkingは40.3％を解決しました。これは、前任者の31.0％から大幅な増加です。\n\nARC-AGI-1：GPT-5.2 Proは、この一般的な推論ベンチマークで90％のしきい値を超えた最初のモデルであると報告されており、90.5％のスコアを獲得しています。\n\nインテリジェンスの価格\n\nパフォーマンスにはプレミアムが付きます。ChatGPTのサブスクリプション価格は今のところ変更されていませんが、新しいフラッグシップモデルのAPIコストは、以前の世代と比較して高額であり、「思考」モードの高い計算需要を反映しています。また、業界のAPIコストの上限にあります。\n\nGPT-5.2 Thinking：100万入力トークンあたり1.75ドル、100万出力トークンあたり14ドルで価格設定されています。\n\nGPT-5.2 Pro：コストは大幅に上昇し、100万入力トークンあたり21ドル、100万出力トークンあたり168ドルになります。\n\nGPT-5.2 Thinkingは、APIで標準のGPT-5.1（1.25ドル/10ドル）よりも40％高い価格設定になっています。これは、OpenAIが新しい推論機能を単なる効率の向上ではなく、明確な付加価値と見なしていることを示しています。\n\nハイエンドのGPT-5.2 Proも同じパターンに従い、以前のGPT-5 Pro（15ドル/120ドル）よりも40％高くなっています。高価ですが、OpenAIの最も特殊な推論モデルであるo1-proよりも依然として低価格であり、100万入力トークンあたり150ドル、100万出力トークンあたり600ドルという驚異的な価格で、メニューの中で最も高価な製品のままです。\n\nOpenAIは、トークンあたりのコストは高いものの、モデルの「トークン効率の向上」と、より少ないターンでタスクを解決できる能力により、価値の高いエンタープライズワークフローにとって経済的に実行可能であると主張しています。\n\nLLM分野の他の競合モデルの現在のAPIコストと比較すると、次のようになります。\n\n[テーブル]\n\n画像生成：今のところ新しいものはありません…しかし「もっと来る」\n\n記者会見中、VentureBeatはOpenAIの参加者に、新しいリリースに画像生成機能の向上が含まれているかどうか尋ねました。GoogleのGemini 3 Image aka Nano Banana Proのような最近の競合他社の発表における同様の機能に対する興奮に注目しました。\n\nテキストと情報を多用するグラフィックスや画像編集機能を再現しようとしている人にとっては残念ながら、OpenAIの幹部は、GPT-5.2には、以前のGPT-5.1およびOpenAIの統合されたDALL-E 3およびgpt-4oネイティブ画像生成モデルに対する現在の画像の改善はないことを明らかにしました。\n\n「画像生成に関しては、今日は発表するものはありませんが、もっと来るでしょう」とSimoは述べています。彼女は、この機能の人気を認め、「これは人々が愛する非常に重要なユースケースであり、私たちが市場に導入したものであり、間違いなくもっと多くのことがそこに来るでしょう」と付け加えました。\n\nOpenAIのトレーニング責任者であるAidan Clarkも、視覚生成の具体的な詳細についてはコメントを控え、「私は画像生成についてはあまり話すことができません」と簡単に述べています。\n\n「メガエージェント」時代\n\nOpenAIは、生のスコアを超えて、GPT-5.2を人間の手を煩わせることなく複数ステップのワークフローを実行できる、新世代の「長期実行エージェント」のエンジンとして位置付けています。\n\n「Boxは、5.2が長くて複雑なドキュメントから情報を約40％速く抽出できることを発見し、ライフサイエンスとヘルスケアの推論精度が40％向上しました」とSimoは述べています。\n\n彼女はまた、Notionがモデルは「あらゆる側面で5.1よりも優れており…実際の知識労働を定義する種類の本当に曖昧でより長い上昇タスクに優れている」と報告したと述べました。Schwarzerは、Augment Codeのようなコーディングスタートアップが、モデルは「以前のどのモデルよりも大幅に強力なディープコード機能を提供した」ため、新しいコードレビューエージェントの強化に選ばれたと付け加えました。視覚機能もアップグレードされています。\n\nOpenAIのリリースブログ投稿では、「旅行者がフライトの遅延、乗り継ぎの失敗、ニューヨークでの一晩の滞在、および医療上の座席要件を報告する」例を示しています。\n\n結果は？「GPT-5.2は、再予約、特別支援座席、および補償というタスクチェーン全体を管理し、GPT-5.1よりも完全な結果を提供します。」\n\nモデルがGUIスクリーンショットを理解する能力をテストする新しい評価であるScreenSpot-Proでは、GPT-5.2 Thinkingが86.3％の精度を達成したのに対し、GPT-5.1はわずか64.2％でした。\n\n科学と信頼性\n\nOpenAIのリーダーはまた、科学研究におけるモデルの有用性を強調し、単純なチャットボットから研究アシスタントへの会話を移行しようと試みました。\n\nトレーニングチームの責任者であるAidan Clarkは、モデルをテストした免疫学の上級研究者の例を共有しました。\n\n「彼らは、免疫系に関する最も重要な未解決の質問を生成するようにモデルに依頼することでそれをテストしました」とClarkは言いました。「その免疫学の研究者は、GPT-5.2が、以前のどのプロモデルと比較しても、より鋭い質問と、なぜそれらの質問が…重要なのかについてのより強力な説明を生み出したと報告しました。」\n\n信頼性も重要な焦点でした。Schwarzerは、新しいモデルは「GPT-5.1よりも大幅に幻覚が少ない」と主張し、匿名化されたクエリのセットでは、「応答に含まれるエラーが38％少なかった」と指摘しました。\n\n「雰囲気」の変化\n\n興味深いことに、OpenAIは、すべてのユーザーが新しいモデルをすぐに好むとは限らないことを認めました。\n\nGPT-5.1のようなレガシーモデルが利用可能なままである理由を尋ねられたとき、Schwarzerは「モデルは毎回少しずつ変化する」と認めました。\n\n「一部のユーザーは、最新のモデルが全体的にはるかに優れていると考えていても、以前のモデルの雰囲気を好むかもしれません」とSchwarzerは述べています。彼はまた、「特定のモデルに合わせてプロンプトを微調整した」一部のエンタープライズ顧客にとっては、「小さな後退」がある可能性があり、古いバージョンへのアクセスが必要になる可能性があると指摘しました。\n\n安全性、「アダルトモード」、および今後のロードマップ\n\n安全性の懸念に対処するため、Simoは、新しい年齢予測システムの実装後、来年の第1四半期に「アダルトモード」を展開する準備をしていることを確認しました。\n\n「それを改善する過程にあります」とSimoは年齢予測技術について語りました。\n\n「アダルトモードの開始に先立ってそれを実行したいと考えています。」さらに先を見据えて、業界レポートでは、OpenAIがコードネーム「プロジェクトガーリック」の下で、2026年初頭にフラッグシップリリースを目標とする、より根本的なアーキテクチャの変更に取り組んでいることが示唆されています。\n\n幹部は記者会見中に特定の将来のロードマップについてはコメントしませんでしたが、Simoは現在の軌道の経済性について楽観的なままでした。\n\n「過去の傾向を見ると、過去3年間でコンピューティングは約3倍増加しています」と彼女は説明しました。「収益も同じペースで増加しており…この好循環を生み出しています。」\n\nClarkは、効率が急速に向上していると付け加えました。「本日リリースするモデルは、1年前のモデルと比較して、ほぼ400分の1のコストとコンピューティングで、[ARC-AGI]でさらに優れたスコアを達成しています。」\n\nGPT-5.2 Instant、Thinking、およびProは、本日よりChatGPTで有料ユーザー（Plus、Pro、Team、およびEnterprise）に展開を開始します。同社は、安定性を維持するために段階的に展開すると述べています。",
    "insightJa": "GPT-5.2の登場で、業務効率化や新しいサービス開発が期待されます。価格設定は高めですが、その性能に見合う価値を提供できるかが今後の課題となるでしょう。",
    "recommendedBooks": [
      "大規模言語モデル",
      "AIエージェント",
      "GPT-5 活用事例"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "LLM",
      "AI",
      "自然言語処理"
    ],
    "imageUrl": "https://images.pexels.com/photos/16629368/pexels-photo-16629368.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "title": "Stressed rats keep returning to cannabis and scientists know why",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "summary": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "publishedAt": "Thu, 11 Dec 2025 12:15:09 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "titleJa": "ストレスを感じやすいラットはなぜ大麻に戻るのか？科学者がその理由を解明",
    "summaryJa": "ストレスの高いラットは自ら大麻を摂取しやすい。ストレスホルモン、認知の柔軟性、内因性カンナビノイドが関連。薬物乱用の脆弱性を示唆。",
    "explanationJa": "ストレスを感じやすいラットは大麻を求める傾向があり、その原因が研究で明らかになりつつあります。",
    "translationJa": "生まれつきストレスレベルが高いラットは、自由にアクセスできる場合、自ら大麻を摂取する傾向が強いことがわかりました。行動試験の結果、ベースラインのストレスホルモンが、大麻を求める行動の最も強い予測因子であることが示されました。認知の柔軟性の低下と内因性カンナビノイドレベルの低下も、使用量の増加に寄与しました。この結果は、薬物乱用に対する脆弱性の早期指標を示唆しています。",
    "insightJa": "この研究は、ストレス管理が薬物依存予防に重要であることを示唆しています。企業においては、従業員のストレス軽減対策が、結果的に依存症リスクの低減に繋がる可能性があります。",
    "recommendedBooks": [
      "ストレスマネジメント",
      "依存症の科学",
      "脳科学 ストレス"
    ],
    "tags": [
      "cannabis",
      "stress",
      "rat",
      "addiction",
      "大麻"
    ],
    "imageUrl": "https://images.pexels.com/photos/3259584/pexels-photo-3259584.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "7nAN91YGj5oC8TMc2YBtjK",
    "title": "Marble enters the race to bring AI to tax work, armed with $9 million and a free research tool",
    "source": "rss",
    "url": "https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a",
    "summary": "Marble, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.\nThe round, led by Susa Ventures with participation from MXV Capital and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.\n\"When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,\" said Bhavin Shah, Marble's chief executive officer, in an exclusive interview with VentureBeat. \"Accounting generates $250 billion in fee-based billing in the US every year. There's a tremendous opportunity to increase efficiency and improve margins for accounting firms.\"\nThe company has launched a free AI-powered tax research tool on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.\nMarble's backers share Shah's conviction about the market. \"Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,\" Chad Byers, general partner at Susa Ventures, told VentureBeat. \"We've known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.\"\nThe accounting industry lost 340,000 workers in four years — and replacements aren't coming\nMarble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.\nThe accounting profession has shed roughly 340,000 workers since 2019, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to AICPA data, and 2022 saw the lowest number of exam takers in 17 years.\nThe exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately 75% of all licensed CPAs reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.\n“Fewer CPAs are getting certified year over year,\" Shah said. \"The industry is compressing at the same time that there's more work to be done and the tax code is getting more complicated.\"\nThe National Pipeline Advisory Group, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the 150-hour education requirement for CPA licensure as a significant barrier to entry. A separate survey by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.\nRecent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.\nWhy AI transformed law and software development but left accounting behind\nDespite the profession's challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. Harvey and Legora have raised hundreds of millions to bring AI to legal work. Cursor and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.\nGeordie Konrad, Marble's executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI's capabilities.\n“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,\" Konrad said. \" That requires a bit more of a two-step analysis to see why it's a big opportunity.\"\nThe technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.\n\"If you want to put AI through its paces and ask how far it's come in replicating cognitive functions, this is an unbelievable playground to work in,\" Konrad said.\nA dramatic shift: AI adoption among tax and finance teams doubles in one year\nRecent data suggests the accounting profession's stance toward AI is shifting rapidly.\nA 2025 survey from Hanover Research and Avalara found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from Thomson Reuters Institute found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.\nLarge accounting firms have invested heavily in AI infrastructure. Deloitte has developed generative AI capabilities within its audit platform. BDO announced a $1B investment in AI over the next five years. EY launched an AI platform combining technology with strategy, transactions, and tax services. PwC estimates a complete AI-driven audit solution will launch by 2026.\nBut adoption at smaller firms remains uneven. According to Thomson Reuters research, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.\nMarble's founders believe the hesitance stems not from technophobia but from a lack of compelling options.\n“Firms want to embrace AI,\" Shah said. “They just haven't seen great software and tooling made for them. That's part of the opportunity — to work with them and build something they're excited to use on a day-to-day basis.”\nCan artificial intelligence rescue accounting's billable-hour business model?\nAI's arrival in accounting raises questions about the profession's billing structure.\nAccounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?\nMarble's founders argue the opposite. The chronic staffing shortage has already constrained firms' ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.\n\"Everyone in the industry agrees that an enormous amount of advisory work simply isn't getting done,\" Konrad said. \"Customers want it. Firms want to do it because it's high-margin, great work. But nobody gets to it.\"\nThe 2025 AICPA National Management of an Accounting Practice Survey supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.\nThe survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.\nAccountants won't adopt AI tools they can't trust with sensitive client data\nFor AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.\nAccording to Avalara's survey, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.\nMarble has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.\n\"Security is at the core of what we are building,\" Shah said. \"Every employee knows that security is critical. It's a part of our onboarding and something that we consider in everything we do.\"\nFrom number crunchers to strategic advisors: How AI could reshape accounting careers\nMarble's founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. \nThey draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.\n\"If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you're a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that's just a lot more fun to operate in,\" Konrad said.\nThe shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.\n\"Not only does the work become more enjoyable because of what you can focus on, but that's also what your clients are going to value more from you,\" Shah said.\nThe competitive landscape: Marble faces well-funded rivals and legacy giants\nMarble enters a market with formidable incumbents and well-funded competitors. BlueJ, a global tax research platform, has raised over $100 million. Thomson Reuters, CCH, and Intuit have deep customer relationships built over decades.\nBut the founders see opportunity in the transition moment.\n\"AI has changed what’s possible in the industry,\" Shah said. \"We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?\"\"\nThe decision to offer a free research tool reflects Marble's go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.\n\"It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don't know how to integrate it into their workflow,\" Shah said.\nThe $250 billion question: Can a startup transform how America does its taxes?\nMarble's roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.\nThe founders frame success not in terms of disruption but rebalancing. Today's tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble's bet is that AI can flip that equation.\n\"Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,\" Konrad said. \"How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?\"\nWhether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.\nBut the founders are betting that the industry's demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.\n\"AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,\" Shah said.\nThe accounting profession, it seems, is about to find out which side of that equation it lands on.",
    "publishedAt": "Thu, 11 Dec 2025 14:00:00 GMT",
    "author": "michael.nunez@venturebeat.com (Michael Nuñez)",
    "category": "AI",
    "originalContent": "<p><a href=\"http://marble.ai/\">Marble</a>, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.</p><p>The round, led by <a href=\"https://www.susaventures.com/\">Susa Ventures</a> with participation from <a href=\"https://mxv.vc/\">MXV Capital</a> and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.</p><p>&quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&quot; said Bhavin Shah, Marble&#x27;s chief executive officer, in an exclusive interview with VentureBeat. &quot;Accounting generates $250 billion in fee-based billing in the US every year. There&#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&quot;</p><p>The company has launched a <a href=\"https://marble.ai/\">free AI-powered tax research tool</a> on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.</p><p>Marble&#x27;s backers share Shah&#x27;s conviction about the market. &quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &quot;We&#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&quot;</p><h2><b>The accounting industry lost 340,000 workers in four years — and replacements aren&#x27;t coming</b></h2><p>Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.</p><p>The accounting profession has <a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">shed roughly 340,000 workers since 2019</a>, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to <a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPA data</a>, and 2022 saw the lowest number of exam takers in 17 years.</p><p>The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately <a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">75% of all licensed CPAs</a> reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.</p><p>“Fewer CPAs are getting certified year over year,&quot; Shah said. &quot;The industry is compressing at the same time that there&#x27;s more work to be done and the tax code is getting more complicated.&quot;</p><p>The <a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the <a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150-hour education requirement</a> for CPA licensure as a significant barrier to entry. A separate <a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">survey</a> by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.</p><p>Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.</p><h2><b>Why AI transformed law and software development but left accounting behind</b></h2><p>Despite the profession&#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. <a href=\"https://www.harvey.ai/\">Harvey</a> and <a href=\"https://legora.com/\">Legora</a> have raised hundreds of millions to bring AI to legal work. <a href=\"https://cursor.com/agents\">Cursor</a> and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.</p><p>Geordie Konrad, Marble&#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&#x27;s capabilities.</p><p>“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&quot; Konrad said. &quot; That requires a bit more of a two-step analysis to see why it&#x27;s a big opportunity.&quot;</p><p>The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.</p><p>&quot;If you want to put AI through its paces and ask how far it&#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&quot; Konrad said.</p><h2><b>A dramatic shift: AI adoption among tax and finance teams doubles in one year</b></h2><p>Recent data suggests the accounting profession&#x27;s stance toward AI is shifting rapidly.</p><p>A 2025 survey from <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a> found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from <a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a> found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.</p><p>Large accounting firms have invested heavily in AI infrastructure. <a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a> has developed generative AI capabilities within its audit platform. <a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a> announced a $1B investment in AI over the next five years. <a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a> launched an AI platform combining technology with strategy, transactions, and tax services. <a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a> estimates a complete AI-driven audit solution will launch by 2026.</p><p>But adoption at smaller firms remains uneven. According to <a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reuters research</a>, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.</p><p>Marble&#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.</p><p>“Firms want to embrace AI,&quot; Shah said. “They just haven&#x27;t seen great software and tooling made for them. That&#x27;s part of the opportunity — to work with them and build something they&#x27;re excited to use on a day-to-day basis.”</p><h2><b>Can artificial intelligence rescue accounting&#x27;s billable-hour business model?</b></h2><p>AI&#x27;s arrival in accounting raises questions about the profession&#x27;s billing structure.</p><p>Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?</p><p>Marble&#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.</p><p>&quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&#x27;t getting done,&quot; Konrad said. &quot;Customers want it. Firms want to do it because it&#x27;s high-margin, great work. But nobody gets to it.&quot;</p><p>The <a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a> supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.</p><p>The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.</p><h2><b>Accountants won&#x27;t adopt AI tools they can&#x27;t trust with sensitive client data</b></h2><p>For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.</p><p>According to <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalara&#x27;s survey</a>, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.</p><p><a href=\"https://marble.ai/\">Marble</a> has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.</p><p>&quot;Security is at the core of what we are building,&quot; Shah said. &quot;Every employee knows that security is critical. It&#x27;s a part of our onboarding and something that we consider in everything we do.&quot;</p><h2><b>From number crunchers to strategic advisors: How AI could reshape accounting careers</b></h2><p>Marble&#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. </p><p>They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.</p><p>&quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&#x27;s just a lot more fun to operate in,&quot; Konrad said.</p><p>The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.</p><p>&quot;Not only does the work become more enjoyable because of what you can focus on, but that&#x27;s also what your clients are going to value more from you,&quot; Shah said.</p><h2><b>The competitive landscape: Marble faces well-funded rivals and legacy giants</b></h2><p><b></b><a href=\"http://marble.ai/\">Marble</a> enters a market with formidable incumbents and well-funded competitors. <a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>, a global tax research platform, has raised over $100 million. <a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>, <a href=\"https://www.cch.com/\">CCH</a>, and <a href=\"https://www.intuit.com/\">Intuit</a> have deep customer relationships built over decades.</p><p>But the founders see opportunity in the transition moment.</p><p>&quot;AI has changed what’s possible in the industry,&quot; Shah said. &quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&quot;&quot;</p><p>The decision to offer a free research tool reflects Marble&#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.</p><p>&quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&#x27;t know how to integrate it into their workflow,&quot; Shah said.</p><h2><b>The $250 billion question: Can a startup transform how America does its taxes?</b></h2><p>Marble&#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.</p><p>The founders frame success not in terms of disruption but rebalancing. Today&#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&#x27;s bet is that AI can flip that equation.</p><p>&quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&quot; Konrad said. &quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&quot;</p><p>Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.</p><p>But the founders are betting that the industry&#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.</p><p>&quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&quot; Shah said.</p><p>The accounting profession, it seems, is about to find out which side of that equation it lands on.</p>",
    "titleJa": "Marble社、AIによる税務業務参入で900万ドル調達、無料の研究ツールも提供",
    "summaryJa": "AIスタートアップのMarble社が900万ドルの資金調達。会計業界の人手不足と規制の複雑化に対応するため、AIを活用した税務業務の効率化を目指します。",
    "explanationJa": "Marble社はAIで税務業務を効率化し、会計業界の人手不足を解消することを目指しています。",
    "translationJa": "税務専門家向けに人工知能エージェントを開発しているスタートアップのMarble社は、会計業界が深刻な人手不足と増大する規制の複雑さに苦しむ中、900万ドルのシード資金を調達しました。\n\nこのラウンドは、Susa Venturesが主導し、MXV CapitalとKonrad Capitalが参加しました。Marble社は、法律やソフトウェア開発などの他の知識産業と比較してAIの導入が大幅に遅れている市場で競争する態勢を整えました。\n\nMarble社の最高経営責任者であるBhavin Shah氏は、VentureBeatとの独占インタビューで、「経済状況を検討し、AIが企業の業務を変革する場所を自問したとき、私たちは知識産業、特に時間単位の料金ベースのサービスモデルを持つ企業に焦点を当てました」と述べました。「会計は米国で毎年2500億ドルの料金ベースの請求を生み出しています。会計事務所にとって効率を高め、利益率を向上させる大きな機会があります。」\n\n同社はウェブサイトで、複雑な政府の税務データを、専門家がアクセスしやすい、引用裏付けのある回答に変換する無料のAI搭載税務調査ツールを立ち上げました。Marble社は、コンプライアンスシナリオを分析し、最終的には税務申告ワークフローの一部を自動化できるAIエージェントに事業を拡大する予定です。\n\nMarble社の出資者は、Shah氏の市場に関する確信を共有しています。Susa VenturesのゼネラルパートナーであるChad Byers氏は、VentureBeatに「Marble社は会計システムを根本から再考しています。会計はプロフェッショナルサービスの中で最大規模であり、最も見過ごされている市場の一つです」と語りました。「私たちは、Shah氏がSusaポートフォリオのエグゼクティブを務めていたときから彼を知っており、彼がどれほど鋭く、実行力があるかを直接見てきました。彼とGeordie氏は、業務の深さと製品に対する直感という完璧な組み合わせを、変化が長らく待ち望まれていた分野にもたらします。そして、彼らは私たちと同じように巨大な機会を見ているのです。」\n\n会計業界は4年間で34万人の労働者を失い、補充は期待できない\n\nMarble社は、専門会計の経済状況を根本的に変えた構造的な力によって形作られた市場に参入します。\n\n会計業界は2019年以降、約34万人の労働者を失い、これは17％の減少であり、企業は顧客の要求を満たすために奔走しています。公認会計士試験の初回受験者数は、AICPAのデータによると、2016年から2021年の間に33％減少し、2022年には過去17年間で最も少ない受験者数となりました。\n\nこの流出は、ベビーブーマー世代が大量に退職することによって引き起こされています。米国公認会計士協会は、認可されたすべてのCPAの約75％が2019年までに定年退職年齢に達し、業界が対処に苦労している人口動態の崖を生み出していると推定しています。\n\n「毎年、認定されるCPAの数は減っています」とShah氏は述べています。「業界は縮小している一方で、やるべき仕事は増え、税法はますます複雑になっています。」\n\nAICPAが2023年7月に設立したマルチステークホルダー団体であるNational Pipeline Advisory Groupは、CPAライセンスの150時間教育要件が参入に対する大きな障壁であると特定する報告書を発表しました。Center for Audit Qualityによる別の調査では、会計を追求しないことを選択した経営学専攻の57％が、追加の単位時間を抑止要因として挙げています。\n\n最近の法改正は、緊急性を反映しています。オハイオ州は現在、150時間要件の代替案を提供しており、州が入学者の減少を逆転させる可能性のある経路を試す意思があることを示しています。\n\nなぜAIは法律とソフトウェア開発を変革したが、会計を置き去りにしたのか\n\n業界の課題にもかかわらず、会計におけるAIの導入は、隣接する知識産業よりも緩やかに進んでいます。HarveyとLegoraは、法律業務にAIをもたらすために数億ドルを調達しました。Cursorなどのコーディングアシスタントは、ソフトウェア開発を変革しました。対照的に、会計は依然としてレガシーな調査プラットフォームと手作業に大きく依存しています。\n\nMarble社のエグゼクティブチェアマンであり、レストランソフトウェア会社TouchBistroの共同創業者であるGeordie Konrad氏は、このギャップを、人々がAIの能力をどのように概念化するかに起因すると考えています。\n\n「LLMがソフトウェア開発者向けにコードを操作し、弁護士向けに言葉を操作することで、有意義な仕事ができることは多くの人にとって明らかでした。会計業界では、LLMは推論エージェントとして使用されるでしょう」とKonrad氏は述べています。「それが大きな機会である理由を理解するには、もう少し2段階の分析が必要です。」\n\n技術的な課題は非常に大きいです。税法は、人間が作成した最も複雑で相互接続された情報システムの一つを形成しています。それは、数万もの相互に連動する規則、ガイダンス文書、および管轄固有の要件であり、それらは頻繁に重複または矛盾しています。\n\n「AIを試して、認知機能を複製する上でAIがどこまで進歩したかを尋ねたいのであれば、これは信じられないほどの遊び場です」とKonrad氏は述べています。\n\n劇的な変化：税務および財務チームにおけるAIの導入が1年で倍増\n\n最近のデータは、会計業界のAIに対する姿勢が急速に変化していることを示唆しています。\n\nHanover Research and Avalaraによる2025年の調査では、現在、財務および税務チームの84％が業務でAIを多用していることがわかりました。これは、2024年の47％から増加しています。Thomson Reuters Instituteによる2025年のGenerative AI in Professional Services Reportでは、税務事務所の21％がすでに生成AIテクノロジーを使用しており、53％が採用を計画しているか、積極的に検討していることがわかりました。\n\n大手会計事務所は、AIインフラストラクチャに多額の投資を行っています。Deloitteは、監査プラットフォーム内で生成AI機能を開発しました。BDOは、今後5年間でAIに10億ドルの投資を発表しました。EYは、テクノロジーと戦略、トランザクション、および税務サービスを組み合わせたAIプラットフォームを立ち上げました。PwCは、完全なAI駆動型監査ソリューションが2026年までにローンチされると推定しています。\n\nしかし、中小企業での導入は依然として不均一です。Thomson Reutersの調査によると、生成AIを使用する税務事務所の回答者の52％は、業界固有のソリューションではなく、ChatGPTのようなオープンソースツールに依存しています。目的別の代替手段が登場するにつれて、このパターンは変化する可能性があります。\n\nMarble社の創業者たちは、そのためらいはテクノフォビアからではなく、魅力的な選択肢の欠如から生じていると考えています。\n\n「企業はAIを受け入れたいと思っています」とShah氏は述べています。「彼らは自分たちのために作られた優れたソフトウェアやツールを見たことがありません。それが機会の一部です。彼らと協力して、彼らが日常的に使用することに興奮するものを構築することです。」\n\n人工知能は、会計の請求時間ビジネスモデルを救うことができるのか？\n\nAIの会計への参入は、業界の請求構造に関する疑問を提起します。\n\n会計事務所は伝統的に、従業員の給与コストの数倍で、スタッフの時間に対してクライアントに請求することで利益を生み出してきました。コンプライアンス業務を行うジュニアアソシエイトは、重要な収益源となります。AIがその業務を自動化できる場合、それは企業が依存するビジネスモデルを損なうことになるのでしょうか？\n\nMarble社の創業者たちは、その逆を主張しています。慢性的な人員不足は、企業が利用可能な収益を獲得する能力をすでに制約しています。アドバイザリーおよびコンサルティング業務（クライアントが積極的に求めている、より利益率の高いサービス）は、実務家がコンプライアンス業務に埋もれているため、行われていません。\n\n「業界の誰もが、膨大な量のアドバイザリー業務が単に行われていないことに同意しています」とKonrad氏は述べています。「顧客はそれを望んでいます。企業はそれが高収益で素晴らしい仕事だからやりたいと思っています。しかし、誰もそれにたどり着けません。」\n\n2025 AICPA National Management of an Accounting Practice Surveyは、この見解を裏付けています。企業は前年比で純顧客料金が中央値で6.7％増加したと報告しており、監査、保証、税務サービス、およびクライアント会計アドバイザリーの成長が見られました。パートナー1人当たりの純残高は、2022年度から2024年度にかけて11.9％増加し、252,663ドルに達しました。\n\n調査ではまた、AIの導入に対する関心が高まっていることもわかりましたが、ほとんどの企業はまだ正式な予算を割り当てるか、構造化されたトレーニングプログラムを開発していません。調査によると、継続的な導入は、サービスの拡大と継続的な成長を促進するのに役立つ可能性があります。\n\n会計士は、機密性の高いクライアントデータを信頼できないAIツールを採用しない\n\nAIが会計で成功するためには、データセキュリティの高い基準をクリアする必要があります。会計事務所は、経済の中で最も機密性の高い財務情報の一部を扱います。実務家は、コンプライアンスまたは機密保持のリスクを生み出すツールを採用することはできません。\n\nAvalaraの調査によると、回答者の63％が、データセキュリティとプライバシーの懸念を、税務および財務機能の自動化に対する最大の障壁として挙げています。この懸念は、最初の選択から実装、継続的な使用まで、導入ライフサイクル全体にわたって持続します。\n\nMarble社は、セキュリティを基本的な優先事項としています。同社は、製品をリリースする前にソフトウェアコンプライアンス認証を取得し、データプライバシーが初日から運用文化に組み込まれていると主張しています。\n\n「セキュリティは私たちが構築しているものの核心です」とShah氏は述べています。「すべての従業員がセキュリティが重要であることを知っています。それは私たちのオンボーディングの一部であり、私たちがするすべてのことで考慮するものです。」\n\n数値計算者から戦略的アドバイザーへ：AIは会計キャリアをどのように再構築できるか\n\nMarble社の創業者たちは、AIが会計の仕事を奪うだけだという物語を否定します。彼らは代わりに、AIが会計の仕事をより戦略的にし、反復的な実行によって特徴付けられることが少なくなるだろうと提案します。\n\n彼らは、コンピューター支援設計が労力のかかる手作業の製図に取って代わった建築に例えます。建築家は消えませんでした。彼らは、機械的な複製ではなく、創造的な設計により多くの時間を費やすことができるツールを手に入れました。\n\n「もしあなたが時間集約的で、創造性の低い仕事をジュニアまたは中級会計士から取り除き、それを創造的で、アイデアを総合し、多くのタスクをAIアシスタントプラットフォームソリューションに委任できるプロフェッショナルとしての役割に置き換えるならば、あなたは経営するのがはるかに楽しい業界になるでしょう」とKonrad氏は述べています。\n\nこの変化はまた、クライアントの成果を改善する可能性があります。会計士がコンプライアンスに費やす時間が少なくなると、クライアントが評価する戦略的なアドバイザリー業務により多くの投資をすることができます。\n\n「仕事は集中できることのために楽しくなるだけでなく、クライアントがあなたからより高く評価するものにもなります」とShah氏は述べています。\n\n競争環境：Marble社は資金力のあるライバルとレガシーな巨人に直面している\n\nMarble社は、手ごわい既存企業と資金力のある競合他社がいる市場に参入します。グローバルな税務調査プラットフォームであるBlueJは、1億ドル以上を調達しました。Thomson Reuters、CCH、およびIntuitは、数十年にわたって構築された深い顧客関係を持っています。\n\nしかし、創業者たちは移行の瞬間に機会を見出しています。\n\n「AIは業界で何が可能かを変えました」とShah氏は述べています。「私たちは業界のいくつかのテクノロジープレーヤーと協力し、統合し、AIを搭載した新製品で他のプレーヤーと競争するつもりです。場合によっては、物事を行うための既存のテクノロジーソリューションを忘れ、タスク自体に戻ります。私たちは完全に新しい技術的能力を持っています。そのタスクを達成するために人間と協力する白紙の状態から何かをどのように設計しますか？」\n\n無料の調査ツールを提供するという決定は、Marble社の市場参入哲学を反映しています。有料の壁なしに実務家がアクセスできるようにすることで、同社は信頼を築き、能力を実証することを目指しています。\n\n「それは、AIの使用方法を心配している人や、AIをどのように採用するか疑問に思っている人に、目的別に構築された本当に魅力的な製品を公開することを可能にします。ワークフローに統合する方法がわからない場合に、コストがかかりすぎるものを購入することを心配する必要はありません」とShah氏は述べています。\n\n2500億ドルの疑問：スタートアップはアメリカが税金を処理する方法を変革できるか？\n\nMarble社のロードマップは調査を超えて広がっています。同社は、複雑な税務シナリオを分析し、コンプライアンスの問題を特定し、最終的にはコンプライアンスワークフローの重要な部分を自動化できるAIエージェントを開発する予定です。そのすべてを、実務家が管理できるようにします。\n\n創業者たちは、成功を混乱という観点ではなく、リバランスという観点で捉えています。今日の税務業務はコンプライアンスに大きく偏っており、クライアントが切望し、より高い利益を生み出す戦略的なアドバイザリーサービスは、永続的に行われません。Marble社の賭けは、AIがその方程式を覆すことができるということです。\n\n「誰もが、コンプライアンスがより簡単に完了し、戦略と計画について話し合う時間が取れることを望んでいます」とKonrad氏は述べています。「コンプライアンス対戦略と計画のブレンドを、戦略と計画を最初にして、コンプライアンスが劇的に簡単になったものに変えるにはどうすればよいでしょうか？」\n\nMarble社がそのビジョンを実行できるかどうかはまだわかりません。同社は、根強い競合他社、歴史的に技術的な変化に抵抗してきた業界、およびリスクの高い金融業務向けのAIシステムを構築することの固有の予測不可能性に直面しています。\n\nしかし、創業者たちは、業界の人口動態の変化が、以前のテクノロジーの波ではできなかった方法で導入を加速させると確信しています。毎年業界に参入する会計士が減少し、顧客の要求が高まるばかりであるため、企業は残りのスタッフがより多くの仕事ができるツールを受け入れる意欲が高まる可能性があります。\n\n「AIはすべての業界を変えるでしょう。ビジネスモデルを支援する方法もあれば、ビジネスモデルに挑戦する方法もあります。AIは最終的に会計事務所のビジネスをより良く、より収益性の高いものにし、同時にエンドクライアントはより良いサービスをより良い価格で受けることができると信じています」とShah氏は述べています。\n\n会計業界は、その方程式のどちら側に着地するかをまさに知ろうとしているようです。",
    "insightJa": "AIの導入により、税務・会計業務が効率化され、より戦略的な業務に集中できるようになるでしょう。中小企業でもAIツールを活用することで、競争力を高めることが期待されます。",
    "recommendedBooks": [
      "税務 AI 活用",
      "会計 自動化",
      "AI 会計事務所"
    ],
    "tags": [
      "AI",
      "Accounting",
      "Tax",
      "Automation",
      "人工知能"
    ],
    "imageUrl": "https://images.pexels.com/photos/16629368/pexels-photo-16629368.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "title": "New research reveals how everyday cues secretly shape your habits",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "summary": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "publishedAt": "Wed, 10 Dec 2025 22:41:05 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "titleJa": "日常的な合図がどのように習慣を密かに形成するのかを解明する新しい研究",
    "summaryJa": "脳内タンパク質KCC2のレベル変化が報酬と合図の結びつきを再形成し、習慣形成を促進。ドーパミン神経細胞の活動が強まり、中毒性行動に類似した形で新しい関連付けが強化される。",
    "explanationJa": "日常的な合図が、脳のタンパク質の変化を通じて、私たちの習慣形成に影響を与えているようです。",
    "translationJa": "研究者たちは、KCC2と呼ばれる脳タンパク質のレベルの変化が、合図が報酬と結びつく方法を再形成し、時に予想以上に早く、あるいは強力に習慣を形成させることを明らかにしました。このタンパク質が減少すると、ドーパミン神経細胞の発火がより活発になり、中毒性行動がどのように定着するかと類似した方法で、新しい関連付けが強化されます。ラットの研究では、短時間の神経活動の同期的なバーストでさえ、報酬学習を増幅させることが示され、朝のルーチンのような日常的なトリガーがなぜ強い欲求を引き起こすのかについての洞察が得られました。",
    "insightJa": "この研究は、私たちが無意識のうちに行っている習慣が、脳の働きによって形作られていることを示唆しています。ビジネスにおいては、従業員の行動を促す効果的な合図を設計する上で役立つ可能性があります。",
    "recommendedBooks": [
      "習慣形成",
      "脳科学",
      "行動経済学"
    ],
    "tags": [
      "habit formation",
      "KCC2",
      "dopamine",
      "reward learning",
      "neuroscience"
    ],
    "imageUrl": "https://images.pexels.com/photos/5486024/pexels-photo-5486024.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "title": "Blood tests reveal obesity rapidly accelerates Alzheimer’s progression",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "summary": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "publishedAt": "Wed, 10 Dec 2025 12:23:51 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "titleJa": "血液検査で肥満がアルツハイマー病の進行を加速させることが判明",
    "summaryJa": "肥満はアルツハイマー病関連の血液バイオマーカーの上昇を加速。長期的な画像データと血漿データから、肥満者は神経変性やアミロイド蓄積に関連するタンパク質の増加が速いことが判明。血液検査の方がPETスキャンより早く変化を検出。",
    "explanationJa": "肥満はアルツハイマー病の進行を加速させる大きな要因であることが、今回の研究で明らかになりました。",
    "translationJa": "肥満は、これまで認識されていたよりもはるかに急速に、アルツハイマー病に関連する血液バイオマーカーの上昇を加速させます。長期的な画像データと血漿データは、肥満者が神経変性やアミロイドの蓄積に関連するタンパク質の増加がはるかに速いことを示しています。驚くべきことに、血液検査はPETスキャンよりも早くこれらの変化を検出しました。この結果は、肥満がアルツハイマー病の進行における主要な、修正可能な要因であることを示唆しています。",
    "insightJa": "今回の研究結果から、肥満の予防と改善が、アルツハイマー病のリスク軽減に繋がる可能性が示唆されます。健康的な食生活と運動習慣を心がけることが、将来の健康のために重要になります。",
    "recommendedBooks": [
      "アルツハイマー病 予防",
      "肥満 健康リスク",
      "認知症 血液検査"
    ],
    "tags": [
      "Alzheimer's disease",
      "Obesity",
      "Blood biomarkers",
      "Neurodegeneration",
      "認知症"
    ],
    "imageUrl": "https://images.pexels.com/photos/6823455/pexels-photo-6823455.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "title": "Rising temperatures are slowing early childhood development",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "summary": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "publishedAt": "Wed, 10 Dec 2025 00:59:03 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "titleJa": "気温上昇が幼児期の成長を遅らせる",
    "summaryJa": "研究により、異常な高温が幼児期の成長を妨げることが判明。特に読み書きや算数の発達に影響が見られ、経済的に困難な家庭で顕著でした。",
    "explanationJa": "気温の上昇は、子どもたちが学校に通う前から学習に影響を与える可能性があるということです。",
    "translationJa": "研究者たちは、異常な高温が幼児期の成長を妨げる可能性があることを発見しました。高温の環境で暮らす子どもたちは、特に読み書きや基本的な算数のスキルにおいて、重要な学習の節目に到達しにくい傾向がありました。経済的な困難や限られた資源に直面している子どもたちは、最も大きな打撃を受けました。この研究は、気候変動が子どもたちが学校に通うようになるずっと前から、彼らの学習をどのように形作るかを示しています。",
    "insightJa": "この研究結果から、気候変動対策と並行して、子どもたちの学習環境を整える支援が重要になると考えられます。企業においては、従業員の子育て支援策を充実させることも、社会貢献の一環として有効でしょう。",
    "recommendedBooks": [
      "幼児教育 環境",
      "気候変動 子育て",
      "子どもの発達 心理学"
    ],
    "tags": [
      "Climate Change",
      "Early Childhood Development",
      "Temperature",
      "Education",
      "気温上昇"
    ],
    "imageUrl": "https://images.pexels.com/photos/7491120/pexels-photo-7491120.jpeg?auto=compress&cs=tinysrgb&h=350"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "title": "Scientists reveal a tiny brain chip that streams thoughts in real time",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "summary": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "publishedAt": "Tue, 09 Dec 2025 23:54:39 EST",
    "author": "",
    "category": "Science",
    "originalContent": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "titleJa": "科学者たちが思考をリアルタイムで伝送する極小脳チップを発表",
    "summaryJa": "科学者達が、脳とコンピュータを繋ぐ超薄型脳インプラントBISCを発表。高精度なAIモデルを搭載し、運動、知覚、意図の解読を支援。てんかん、麻痺、失明の治療に革新をもたらす可能性。",
    "explanationJa": "このチップは、脳の活動をリアルタイムで捉え、さまざまな治療に役立つことが期待されます。",
    "translationJa": "BISCは、脳とコンピュータの間に広帯域無線リンクを構築する超薄型ニューラルインプラントです。その小型のシングルチップ設計には、数万個の電極が搭載されており、運動、知覚、意図を解読するための高度なAIモデルをサポートしています。初期の臨床研究では、頭蓋骨の小さな開口部から挿入でき、詳細な神経活動を捉えながら安定した状態を維持できることが示されています。この技術は、てんかん、麻痺、失明の治療を大きく変える可能性があります。",
    "insightJa": "この技術が進歩すれば、脳とコンピュータの連携がよりスムーズになり、リハビリやコミュニケーション支援などの分野で大きな進展が見込まれます。ビジネスにおいては、医療機器開発やAI技術の応用において新たな機会が生まれるでしょう。",
    "recommendedBooks": [
      "脳科学 入門",
      "ニューロテクノロジー 最新",
      "医療 AI 応用"
    ],
    "tags": [
      "Brain-Computer Interface",
      "Neural Implant",
      "AI",
      "脳科学",
      "ニューロテクノロジー"
    ],
    "imageUrl": "https://images.pexels.com/photos/16027824/pexels-photo-16027824.jpeg?auto=compress&cs=tinysrgb&h=350"
  }
]