[
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "title": "Parents call for New York governor to sign landmark AI safety bill",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill",
    "summary": "A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill that would require developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.\nThe bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul reportedly proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the changes made to California's  …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T22:16:09.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STK485_STK414_AI_SAFETY_B.webp?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">A group of more than 150 parents sent a letter on Friday to New York governor Kathy Hochul, urging her to sign the Responsible AI Safety and Education (RAISE) Act without changes. The RAISE Act is a buzzy bill <a href=\"https://legislation.nysenate.gov/pdf/bills/2025/S6953B\">that would require</a> developers of large AI models - like Meta, OpenAI, Deepseek, and Google - to create safety plans and follow transparency rules about reporting safety incidents.</p>\n<p class=\"has-text-align-none\">The bill passed in both the New York State Senate and the Assembly in June. But this week, Hochul <a href=\"https://www.transformernews.ai/p/new-york-governor-hochul-raise-act-sb-53\">reportedly</a> proposed a near-total rewrite of the RAISE Act that would make it more favorable to tech companies, akin to some of the <a href=\"https://www.theverge.com/ai-artificial-intelligence/787918/sb-53-the-landmark-ai-transparency-bill-is-now-law-in-california\">changes made to California's  …</a></p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/844062/parents-call-for-new-york-governor-to-sign-landmark-ai-safety-bill\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "親たちがニューヨーク州知事に画期的なAI安全法案の署名を要求",
    "summaryJa": "150人以上の親が、AI開発企業に安全計画の作成と安全事故の報告を義務付けるRAISE法案の修正なしでの署名をホークル知事に求めました。知事は法案を大幅に修正する提案をしたと報じられています。",
    "explanationJa": "ニューヨーク州でAIの安全性を高めるための法案が議論されており、親たちがその成立を強く求めています。",
    "translationJa": "150人以上の親たちのグループが金曜日、ニューヨーク州知事のキャシー・ホークルに書簡を送り、責任あるAIの安全性と教育（RAISE）法を修正なしで署名するよう強く求めました。RAISE法は、Meta、OpenAI、Deepseek、Googleなどの大規模AIモデルの開発者に対し、安全計画を作成し、安全事故の報告に関する透明性ルールに従うことを義務付ける話題の法案です。\n\nこの法案は6月にニューヨーク州上院と下院の両方で可決されました。しかし今週、ホークルはRAISE法をほぼ全面的に書き換え、テクノロジー企業にとってより有利にするような提案をしたと報じられています。これはカリフォルニア州で行われた変更の一部と同様です。\n\n詳細はThe Vergeの記事をご覧ください。",
    "insightJa": "AI技術の発展に伴い、その安全性への関心が高まっています。この法案が成立すれば、AIがより安全に利用できるようになり、ビジネスにおいてもAI導入の際の安心感が増すことが期待されます。",
    "recommendedBooks": [
      "AI 安全性",
      "AI リスク",
      "AI 規制"
    ],
    "tags": [
      "AI safety",
      "RAISE Act",
      "New York",
      "Kathy Hochul",
      "人工知能 安全性"
    ],
    "imageUrl": "https://picsum.photos/seed/11840/400/300"
  },
  {
    "id": "https://techcrunch.com/?p=3075418",
    "title": "OK, what’s going on with LinkedIn’s algo?",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/ok-whats-going-on-with-linkedins-algo/",
    "summary": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "publishedAt": "Fri, 12 Dec 2025 19:38:16 +0000",
    "author": "Dominic-Madori Davis",
    "category": "AI",
    "originalContent": "Women ran an experiment to see if LinkedIn's new algo was being sexist and thought they proved it. But there's more complexity involved, experts say.",
    "titleJa": "LinkedInのアルゴリズムに何が？",
    "summaryJa": "LinkedInの新しいアルゴリズムが性差別的であるかどうかを女性たちが実験で検証。しかし専門家は、より複雑な要因が関係していると指摘しています。",
    "explanationJa": "LinkedInのアルゴリズムについて、性差別の疑いを含む複雑な問題が議論されているようです。",
    "translationJa": "女性たちが、LinkedInの新しいアルゴリズムが性差別的であるかどうかを検証する実験を行い、それを証明したと考えました。しかし、専門家によれば、より複雑な要因が関与しているとのことです。",
    "insightJa": "もしLinkedInのアルゴリズムに偏りがあれば、キャリア形成やビジネス機会に影響を与える可能性があります。アルゴリズムの透明性と公平性を確保することは、非常に重要な課題です。",
    "recommendedBooks": [
      "アルゴリズムバイアス",
      "ジェンダーとテクノロジー",
      "公平な機械学習"
    ],
    "tags": [
      "LinkedIn",
      "algorithm",
      "sexism",
      "AI bias",
      "gender equality"
    ],
    "imageUrl": "https://picsum.photos/seed/2790/400/300"
  },
  {
    "id": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "title": "Google Translate brings real-time speech translations to any headphones",
    "source": "rss",
    "url": "https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones",
    "summary": "Google Translate's latest update brings live speech translations, originally available only on the Pixel Buds, to any headphones you want, with support for over 70 languages. It's rolling out today in beta and just requires a compatible Android phone with the Translate app (unlike Apple's similar feature, which requires AirPods). \nIt's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T18:11:14.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/google-translate-text-update-12-12-25.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">Google Translate's latest update brings live speech translations, originally available only <a href=\"https://www.theverge.com/2017/11/16/16659314/google-pixel-buds-review-bluetooth-headphones\">on the Pixel Buds</a>, to any headphones you want, with support for over 70 languages. It's <a href=\"https://blog.google/products/search/gemini-capabilities-translation-upgrades/\">rolling out today in beta</a> and just requires a compatible Android phone with the Translate app (unlike <a href=\"https://www.theverge.com/news/629506/apple-airpods-live-translation-ios-19\">Apple's similar feature</a>, which requires AirPods). </p>\n<p class=\"has-text-align-none\">It's one of a few new features coming to Google Translate, along with improved text translations. Using Gemini, Translate will now offer more accurate translations of phrases like idioms and slang, which have a different meaning than what they literally sound like word for word, such as the expression \"stealing my …</p>\n<p><a href=\"https://www.theverge.com/news/843483/google-translate-live-speech-translations-headphones\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "Google翻訳、あらゆるヘッドホンでリアルタイム音声翻訳が可能に",
    "summaryJa": "Google翻訳の最新アップデートで、Pixel Buds限定だったリアルタイム音声翻訳が、70以上の言語に対応し、あらゆるヘッドホンで利用可能になります。テキスト翻訳もGeminiで改善。",
    "explanationJa": "Google翻訳がアップデートされ、どんなヘッドホンでもリアルタイムで翻訳できるようになりました。",
    "translationJa": "Google翻訳の最新アップデートにより、元々Pixel Budsでのみ利用可能だったリアルタイム音声翻訳が、70以上の言語をサポートし、お好みのヘッドホンで利用できるようになります。本日ベータ版として公開され、互換性のあるAndroidフォンと翻訳アプリがあれば利用できます（Appleの同様の機能のようにAirPodsは必要ありません）。\n\nこれは、Google翻訳に追加されるいくつかの新機能の1つで、テキスト翻訳の改善も含まれます。Geminiを使用することで、翻訳はイディオムやスラングなど、文字通りの意味とは異なるフレーズをより正確に翻訳できるようになります。例えば、「stealing my …",
    "insightJa": "このアップデートにより、言語の壁が低くなり、海外旅行やビジネスでのコミュニケーションがよりスムーズになることが期待されます。異なる文化を持つ人々との交流がより身近になり、グローバルなビジネス展開も容易になるでしょう。",
    "recommendedBooks": [
      "多言語翻訳 技術",
      "音声認識 活用",
      "異文化コミュニケーション 入門"
    ],
    "tags": [
      "Google Translate",
      "Real-time translation",
      "AI",
      "Machine Learning",
      "音声翻訳"
    ],
    "imageUrl": "https://picsum.photos/seed/8514/400/300"
  },
  {
    "id": "https://techcrunch.com/?p=3075611",
    "title": "Trump’s AI executive order promises ‘one rulebook’ — startups may get legal limbo instead",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/trumps-ai-executive-order-promises-one-rulebook-startups-may-get-legal-limbo-instead/",
    "summary": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "publishedAt": "Fri, 12 Dec 2025 17:07:22 +0000",
    "author": "Rebecca Bellan",
    "category": "AI",
    "originalContent": "Trump signed an AI executive order targeting state laws and promising one national rulebook. Critics warn it could trigger court battles and prolong uncertainty for startups while Congress debates federal rules.",
    "titleJa": "トランプ大統領のAIに関する大統領令、「単一のルールブック」を約束も、スタートアップは法的空白に陥る可能性",
    "summaryJa": "トランプ大統領が州法を対象としたAIに関する大統領令に署名。全国統一ルールを約束するも、連邦法制定を巡る議会での議論中は、訴訟やスタートアップの不確実性を長引かせる可能性があると批判されています。",
    "explanationJa": "トランプ大統領がAIに関する大統領令を出し、全国で統一されたルールを目指していますが、混乱も予想されます。",
    "translationJa": "トランプ大統領は、州法を対象とし、全国で単一のルールブックを約束するAIに関する大統領令に署名しました。しかし、批評家たちは、この大統領令が法廷闘争を引き起こし、連邦政府によるルール制定を巡る議会での議論が行われている間、スタートアップ企業にとって不確実な状況が長引く可能性があると警告しています。",
    "insightJa": "この大統領令によって、AI関連ビジネスの全国展開が容易になる可能性がありますが、同時に、新しい規制の解釈や訴訟リスクなど、ビジネスの不確実性も高まる可能性があります。今後の動向を注視する必要があります。",
    "recommendedBooks": [
      "AI 法規制",
      "AI スタートアップ",
      "人工知能 リスク"
    ],
    "tags": [
      "AI",
      "Executive Order",
      "Regulation",
      "Startups",
      "人工知能"
    ],
    "imageUrl": "https://picsum.photos/seed/2785/400/300"
  },
  {
    "id": "https://techcrunch.com/?p=3075551",
    "title": "Google Translate now lets you hear real-time translations in your headphones",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/google-translate-now-lets-you-hear-real-time-translations-in-your-headphones/",
    "summary": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "publishedAt": "Fri, 12 Dec 2025 17:00:00 +0000",
    "author": "Aisha Malik",
    "category": "AI",
    "originalContent": "The real-time headphone translations experience keeps each speaker’s tone, emphasis, and cadence intact, so it’s easier to follow the conversation and tell who’s saying what.",
    "titleJa": "Google翻訳、ヘッドホンでリアルタイム翻訳を聞ける新機能",
    "summaryJa": "Google翻訳が、話者の口調や強調、リズムをそのままにリアルタイム翻訳をヘッドホンで聞ける機能を追加。会話の流れや誰が話しているかを把握しやすくなります。",
    "explanationJa": "Google翻訳の新しい機能で、ヘッドホンを通じてより自然なリアルタイム翻訳を体験できるようになりました。",
    "translationJa": "リアルタイムのヘッドホン翻訳体験では、各話者の口調、強調、および話し方のリズムがそのまま保持されるため、会話をより簡単に理解し、誰が何を言っているのかを区別できます。",
    "insightJa": "この機能により、言語の壁を越えたコミュニケーションがよりスムーズになり、国際会議や外国人とのビジネスシーンで非常に役立つと思われます。グローバルな活躍を後押しする技術ですね。",
    "recommendedBooks": [
      "翻訳技術",
      "多言語コミュニケーション",
      "AI音声認識"
    ],
    "tags": [
      "Google Translate",
      "Real-time Translation",
      "Headphones",
      "AI",
      "Communication"
    ],
    "imageUrl": "https://picsum.photos/seed/2788/400/300"
  },
  {
    "id": "https://techcrunch.com/?p=2607630",
    "title": "ChatGPT: Everything you need to know about the AI-powered chatbot",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/12/chatgpt-everything-to-know-about-the-ai-chatbot/",
    "summary": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "publishedAt": "Fri, 12 Dec 2025 16:01:00 +0000",
    "author": "Kyle Wiggers, Cody Corrall, Kate Park, Alyssa Stringer",
    "category": "AI",
    "originalContent": "A timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year.",
    "titleJa": "ChatGPT：AI搭載チャットボットについて知っておくべきこと",
    "summaryJa": "この記事では、ChatGPTの製品アップデートとリリースに関するタイムラインを最新のものから順に紹介します。年間を通して更新されています。",
    "explanationJa": "この記事は、ChatGPTの進化を追跡し、その最新情報をわかりやすく解説しています。",
    "translationJa": "ChatGPTの製品アップデートとリリースに関するタイムラインを、最新のものから順に紹介します。本記事は、年間を通してアップデートされています。",
    "insightJa": "ChatGPTのようなAI技術は、カスタマーサポートやコンテンツ作成など、ビジネスの様々な場面で活用されています。今後、AIの活用はより一層進み、私たちの働き方や生活に大きな影響を与えるでしょう。",
    "recommendedBooks": [
      "ChatGPT 入門",
      "大規模言語モデル",
      "AIチャットボット 活用"
    ],
    "tags": [
      "ChatGPT",
      "AI",
      "Chatbot",
      "人工知能",
      "自然言語処理"
    ],
    "imageUrl": "https://picsum.photos/seed/2786/400/300"
  },
  {
    "id": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "title": "I quit all my AI fitness plans, and I feel free",
    "source": "rss",
    "url": "https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai",
    "summary": "AI sure does use a lot of words to say very little.\t\n\nThis is Optimizer, a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. Optimizer arrives in our subscribers' inboxes at 10AM ET. Opt in for Optimizer here.\nThis time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt amazing. Then life happened. \nA year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T15:00:00.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"Over the shoulder shot of someone reading a lengthy AI insight from the Runna app\" data-caption=\"AI sure does use a lot of words to say very little.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAI sure does use a lot of words to say very little.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>This is </em><a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a><em>, a weekly newsletter sent every Friday from Verge senior reviewer</em> <a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a><em> that dissects and discusses the latest phones, smartwatches, apps, and other gizmos that swear they're going to change your life. </em>Optimizer<em> arrives in our subscribers' inboxes at 10AM ET. Opt in for </em>Optimizer <em><a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">here</a>.</em></p>\n<p class=\"has-drop-cap has-text-align-none\">This time last year, I'd cut 16 minutes off my four-mile run time, was lifting three to four times a week, and had lost 10 pounds after a consistent six months of training. I felt <em>amazing.</em> Then life happened. </p>\n<p class=\"has-text-align-none\">A year later, I haven't run more than a 5K in three months, I gained back those 10 pounds from stress, and have been beset b …</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIフィットネスプランを全てやめたら、解放された気分",
    "summaryJa": "筆者はAIフィットネスプランを利用していたが、生活の変化で中断。AIの指示の多さに疲弊し、全てやめた結果、精神的に解放されたと述べています。",
    "explanationJa": "AIフィットネスプランをやめたことで、筆者は自由な気持ちになったそうです。",
    "translationJa": "<figure>\n\n<img alt=\"Runnaアプリからの長いAIインサイトを読んでいる人の肩越しのショット\" data-caption=\"AIは、ほとんど何も言わないために多くの言葉を使いますね。\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/258195_optimizer_AI_workout_summary_AKrales_0010.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tAIは、ほとんど何も言わないために多くの言葉を使いますね。\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\"><em>これは、The Vergeのシニアレビュアーである<a href=\"https://www.theverge.com/authors/victoria-song\" target=\"_blank\" rel=\"noreferrer noopener\"><em>Victoria Song</em></a>が毎週金曜日に送信する週刊ニュースレター<a href=\"https://www.theverge.com/optimizer-newsletter\" target=\"_blank\" rel=\"noreferrer noopener\">Optimizer</a>です。Optimizerでは、あなたの人生を変えると誓う最新の携帯電話、スマートウォッチ、アプリ、その他のガジェットを分析し、議論します。</em>Optimizer<em>は、東部時間午前10時に購読者の受信箱に届きます。</em>Optimizer<em>の購読は<a href=\"https://www.theverge.com/newsletters\" target=\"_blank\" rel=\"noreferrer noopener\">こちら</a>から。</em></p>\n<p class=\"has-drop-cap has-text-align-none\">去年の今頃、私は4マイルのランニングタイムを16分短縮し、週に3〜4回ウェイトリフティングを行い、6ヶ月の継続的なトレーニングの後、10ポンド減量しました。私は<em>素晴らしい</em>気分でした。それから、人生が起こりました。</p>\n<p class=\"has-text-align-none\">1年後、私は3ヶ月以上5K以上走っていません。ストレスで10ポンド戻ってしまい、苦しめられています…</p>\n<p><a href=\"https://www.theverge.com/column/843420/optimizer-fitness-ai-coaching-plans-quitting-runna-peloton-iq-fitbit-ai\">The Vergeで記事全文を読む</a></p>",
    "insightJa": "AIフィットネスは便利ですが、指示に従うことがストレスになる場合もあります。自分に合った方法を見つけることが、健康的な生活を送る上で大切です。",
    "recommendedBooks": [
      "AIフィットネス",
      "パーソナルトレーニング AI",
      "健康管理 アプリ"
    ],
    "tags": [
      "AI fitness",
      "fitness app",
      "health",
      "トレーニング",
      "人工知能"
    ],
    "imageUrl": "https://picsum.photos/seed/10490/400/300"
  },
  {
    "id": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "title": "How to vibe-write a country hit",
    "source": "rss",
    "url": "https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast",
    "summary": "You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"I Run\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.\nOn this episode of The Vergecast, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent Switched on Pop podcast. Charlie takes us th …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T14:23:18.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"\" data-caption=\"\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/VRG_VST_1212_Site.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\t\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">You may not even know it, but you've almost certainly encountered songs made mostly or even entirely with AI. If you've scrolled on TikTok the last few weeks, you've probably heard \"<a href=\"https://www.digitalmusicnews.com/2025/11/24/havens-i-run-ai-song-explained/\">I Run</a>\" a few times, but there are countless others making their way around social and music platforms. AI tools in general, and Suno in particular, are becoming a big part of the music-making process. And nowhere is that more true than in the home of country music, Nashville.</p>\n<p class=\"has-text-align-none\">On <a href=\"https://link.chtbl.com/vergecast\">this episode of <em>The Vergecast</em></a>, Nilay and David are joined by Charlie Harding, a music journalist and professor who also cohosts the excellent <em>Switched on Pop </em>podcast. Charlie takes us th …</p>\n<p><a href=\"https://www.theverge.com/podcast/843447/ai-music-country-suno-vergecast\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "AIでカントリーヒット曲を作る方法",
    "summaryJa": "AIツール、特にSunoが音楽制作に浸透し、カントリー音楽の本場ナッシュビルで顕著です。TikTokなどでAI生成音楽を耳にする機会が増えています。",
    "explanationJa": "AIを使って簡単に音楽が作れるようになり、特にカントリー音楽の世界でその影響が広がっています。",
    "translationJa": "気づいていないかもしれませんが、あなたはほとんど間違いなく、主に、あるいは完全にAIによって作られた曲に出会ったことがあるでしょう。ここ数週間TikTokをスクロールしていると、おそらく「I Run」を何度か耳にしているはずです。しかし、ソーシャルプラットフォームや音楽プラットフォーム上では、無数の楽曲が生まれています。一般的なAIツール、特にSunoは、音楽制作プロセスにおいて大きな部分を占めるようになっています。そして、それはカントリー音楽の本場、ナッシュビルにおいて、より一層顕著です。\n\nこの『The Vergecast』のエピソードでは、音楽ジャーナリストであり教授、そして優れたポッドキャスト『Switched on Pop』の共同ホストでもあるチャーリー・ハーディングを迎え、NilayとDavidが話を聞きます。チャーリーは、私たちを...",
    "insightJa": "AI音楽制作は、誰でも気軽に音楽を作れる可能性を広げます。ビジネスにおいては、音楽制作コストの削減や、新しい音楽ジャンルの開拓に繋がるかもしれません。",
    "recommendedBooks": [
      "AI音楽生成",
      "Suno 使い方",
      "カントリー音楽 歴史"
    ],
    "tags": [
      "AI music",
      "Suno",
      "Country music",
      "Nashville",
      "音楽生成AI"
    ],
    "imageUrl": "https://picsum.photos/seed/6682/400/300"
  },
  {
    "id": "43pZxbBPbS0s7iDFEyijjR",
    "title": "Ai2's new Olmo 3.1 extends reinforcement learning training for stronger reasoning benchmarks",
    "source": "rss",
    "url": "https://venturebeat.com/ai/ai2s-new-olmo-3-1-extends-reinforcement-learning-training-for-stronger",
    "summary": "The Allen Institute for AI (Ai2) recently released what it calls its most powerful family of models yet, Olmo 3. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.\nThe new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. \nAi2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. \nOlmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. \nAi2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. \n“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a blog post. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”\n\nTo get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.\nOlmo 3.1 Instruct 32B is \"optimized for chat, tool use, & multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a post on X. \nFor now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. \nBetter performance on benchmarks\nThe Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. \nOlmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. \nOlmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.\n“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. \n\nAi2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.\nCommitment to transparency and open source \nAi2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. \nOrganizations could add to the model’s data mix and retrain it to also learn from what’s been added.  \nThis has long been a commitment for Ai2, which also offers a tool called OlmoTrace that tracks how LLM outputs match its training data.  \n\n“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said.",
    "publishedAt": "Fri, 12 Dec 2025 05:00:00 GMT",
    "author": "",
    "category": "AI",
    "originalContent": "<p>The Allen Institute for AI (Ai2) recently released what it calls its most powerful <a href=\"https://venturebeat.com/ai/ai2s-olmo-3-family-challenges-qwen-and-llama-with-efficient-open-reasoning\"><u>family of models yet, Olmo 3</u></a>. But the company kept iterating on the models, expanding its reinforcement learning (RL) runs, to create Olmo 3.1.</p><p>The new Olmo 3.1 models focus on efficiency, transparency, and control for enterprises. </p><p>Ai2 updated two of the three versions of Olmo 2: Olmo 3.1 Think 32B, the flagship model optimized for advanced research, and Olmo 3.1 Instruct 32B, designed for instruction-following, multi-turn dialogue, and tool use. </p><p>Olmo 3 has a third version, Olmo 3-Base for programming, comprehension, and math. It also works well for continue fine-tuning. </p><p>Ai2 said that to upgrade Olmo 3 Think 32B to Olmo 3.1, its researchers extended its best RL run with a longer training schedule. </p><p>“After the original Olmo 3 launch, we resumed our RL training run for Olmo 3 32B Think, training for an additional 21 days on 224 GPUs with extra epochs over our Dolci-Think-RL dataset,” Ai2 said in a <a href=\"https://allenai.org/blog/olmo3\"><u>blog post</u></a>. “This yielded Olmo 3.1 32B Think, which brings substantial gains across math, reasoning, and instruction-following benchmarks: improvements of 5+ points on AIME, 4+ points on ZebraLogic, 4+ points on IFEval, and 20+ points on IFBench, alongside stronger performance on coding and complex multi-step tasks.”</p><div></div><p>To get to Olmo 3.1 Instruct, Ai2 said its researchers applied the recipe behind the smaller Instruct size, 7B, to the larger model.</p><p>Olmo 3.1 Instruct 32B is &quot;optimized for chat, tool use, &amp; multi-turn dialogue—making it a much more performant sibling of Olmo 3 Instruct 7B and ready for real-world applications,” Ai2 said in a <a href=\"https://x.com/allen_ai/status/1999528338365247539\"><u>post on X</u></a>. </p><p>For now, the new checkpoints are available on the Ai2 Playground or Hugging Face, with API access coming soon. </p><h2>Better performance on benchmarks</h2><p>The Olmo 3.1 models performed well on benchmark tests, predictably beating the Olmo 3 models. </p><p>Olmo 3.1 Think outperformed Qwen 3 32B models in the AIME 2025 benchmark and performed close to Gemma 27B. </p><p>Olmo 3.1 Instruct performed strongly against its open-source peers, even beating models like Gemma 3 on the Math benchmark.</p><p>“As for Olmo 3.1 32B Instruct, it’s a larger-scale instruction-tuned model built for chat, tool use, and multi-turn dialogue. Olmo 3.1 32B Instruct is our most capable fully open chat model to date and — in our evaluations — the strongest fully open 32B-scale instruct model,” the company said. </p><div></div><p>Ai2 also upgraded its RL-Zero 7B models for math and coding. The company said on X that both models benefited from longer and more stable training runs.</p><h2>Commitment to transparency and open source </h2><p>Ai2 previously told VentureBeat that it designed the Olmo 3 family of models to offer enterprises and research labs more control and understanding of the data and training that went into the model. </p><p>Organizations could add to the model’s data mix and retrain it to also learn from what’s been added.  </p><p>This has long been a commitment for Ai2, which also offers a <a href=\"https://venturebeat.com/ai/whats-inside-the-llm-ai2-olmotrace-will-trace-the-source\"><u>tool called OlmoTrace</u></a> that tracks how LLM outputs match its training data.  </p><div></div><p>“Together, Olmo 3.1 Think 32B and Olmo 3.1 Instruct 32B show that openness and performance can advance together. By extending the same model flow, we continue to improve capabilities while retaining end-to-end transparency over data, code, and training decisions,” Ai2 said. </p><p>\n\n\n\n\n\n</p>",
    "titleJa": "Ai2の新しいOlmo 3.1、強固な推論ベンチマークに向けて強化学習トレーニングを拡張",
    "summaryJa": "Allen Institute for AI (Ai2)は、Olmo 3.1を発表。Olmo 3を基に、強化学習を拡張し、効率性、透明性、制御性を向上。ベンチマークテストで優れた性能を示した。",
    "explanationJa": "AI研究機関Ai2が、より高性能なAIモデルOlmo 3.1を発表しました。数学や推論能力が向上しているそうです。",
    "translationJa": "アレン人工知能研究所（Ai2）は最近、これまでで最も強力なモデルファミリーであるOlmo 3を発表しました。しかし、同社はモデルの改良を続け、強化学習（RL）の実行を拡大して、Olmo 3.1を開発しました。\n\n新しいOlmo 3.1モデルは、企業向けの効率性、透明性、制御に重点を置いています。\n\nAi2は、Olmo 2の3つのバージョンのうち2つをアップデートしました。高度な研究に最適化されたフラッグシップモデルであるOlmo 3.1 Think 32Bと、指示への従順、複数ターンの対話、ツール利用のために設計されたOlmo 3.1 Instruct 32Bです。\n\nOlmo 3には、プログラミング、理解、数学のための3番目のバージョンであるOlmo 3-Baseがあります。これは継続的なファインチューニングにも適しています。\n\nAi2によると、Olmo 3 Think 32BをOlmo 3.1にアップグレードするために、研究者たちは最高のRL実行をより長いトレーニングスケジュールで拡張しました。\n\n「オリジナルのOlmo 3のローンチ後、Olmo 3 32B ThinkのRLトレーニング実行を再開し、Dolci-Think-RLデータセット上で追加のエポックで224個のGPUを使用してさらに21日間トレーニングしました」とAi2はブログ投稿で述べています。「これにより、Olmo 3.1 32B Thinkが誕生し、数学、推論、指示への従順ベンチマーク全体で大幅な向上をもたらしました。AIMEで5ポイント以上、ZebraLogicで4ポイント以上、IFEvalで4ポイント以上、IFBenchで20ポイント以上の改善があり、コーディングや複雑な多段階タスクでもより強力なパフォーマンスを発揮します。」\n\nOlmo 3.1 Instructを実現するために、Ai2の研究者たちは、より小さなInstructサイズである7Bの背後にあるレシピを、より大きなモデルに適用したと述べています。\n\nOlmo 3.1 Instruct 32Bは、「チャット、ツール利用、および複数ターンの対話に最適化されており、Olmo 3 Instruct 7Bのパフォーマンスが大幅に向上した兄弟であり、実際のアプリケーションに対応できます」とAi2はXへの投稿で述べています。\n\n現在、新しいチェックポイントはAi2 PlaygroundまたはHugging Faceで利用可能であり、APIアクセスはまもなく利用可能になる予定です。\n\nベンチマークでのより良いパフォーマンス\n\nOlmo 3.1モデルは、ベンチマークテストで優れたパフォーマンスを発揮し、予想どおりOlmo 3モデルを上回りました。\n\nOlmo 3.1 Thinkは、AIME 2025ベンチマークでQwen 3 32Bモデルを上回り、Gemma 27Bに近いパフォーマンスを発揮しました。\n\nOlmo 3.1 Instructは、オープンソースの同業者に対して強力なパフォーマンスを発揮し、MathベンチマークではGemma 3のようなモデルさえ上回りました。\n\n「Olmo 3.1 32B Instructに関しては、チャット、ツール利用、複数ターンの対話のために構築された、より大規模な指示調整モデルです。Olmo 3.1 32B Instructは、これまでに最も優れた完全にオープンなチャットモデルであり、私たちの評価では、最も強力な完全にオープンな32Bスケールの指示モデルです」と同社は述べています。\n\nAi2はまた、数学とコーディングのためにRL-Zero 7Bモデルをアップグレードしました。同社はXで、両方のモデルがより長く、より安定したトレーニング実行から恩恵を受けたと述べています。\n\n透明性とオープンソースへのコミットメント\n\nAi2は以前VentureBeatに、Olmo 3モデルファミリーは、企業や研究機関がモデルに入力されたデータとトレーニングをよりコントロールし、理解できるように設計されたと語っています。\n\n組織はモデルのデータミックスに追加し、それを再トレーニングして、追加されたものからも学習できます。\n\nこれはAi2にとって長年のコミットメントであり、LLM出力がトレーニングデータとどのように一致するかを追跡するOlmoTraceと呼ばれるツールも提供しています。\n\n「Olmo 3.1 Think 32BとOlmo 3.1 Instruct 32Bは共に、オープン性とパフォーマンスが共に進歩できることを示しています。同じモデルフローを拡張することで、データ、コード、およびトレーニングの決定に関するエンドツーエンドの透明性を維持しながら、機能を向上させ続けています」とAi2は述べています。",
    "insightJa": "AIモデルの性能向上は、ビジネスにおける業務効率化や新たなサービス創出に繋がります。特に、透明性の高いモデルは、企業が安心して利用できる基盤となるでしょう。",
    "recommendedBooks": [
      "大規模言語モデル",
      "強化学習 実践",
      "AI オープンソース"
    ],
    "tags": [
      "AI",
      "LLM",
      "Reinforcement Learning",
      "Open Source",
      "Olmo 3.1"
    ],
    "imageUrl": "https://picsum.photos/seed/1900/400/300"
  },
  {
    "id": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "title": "Trump signs AI executive order pushing to ban state laws",
    "source": "rss",
    "url": "https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws",
    "summary": "President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t\n\nOn Thursday evening, with White House AI and crypto czar David Sacks looking over his shoulder, Donald Trump signed an executive order aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order can't by itself unilaterally override state AI laws, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.\nIt specifically calls out Colorado's recently passed consumer protection law, making the claim that \"banning 'algorithmic discri …\nRead the full story at The Verge.",
    "publishedAt": "2025-12-12T01:18:46.000Z",
    "author": "",
    "category": "AI",
    "originalContent": "\n\t\t\t\t\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t\n<figure>\n\n<img alt=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks in the Oval Office\" data-caption=\"President Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\" data-portal-copyright=\"\" data-has-syndication-rights=\"1\" src=\"https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/gettyimages-2251458899.jpg?quality=90&#038;strip=all&#038;crop=0,0,100,100\" />\n\t<figcaption>\n\tPresident Donald Trump and Commerce Secretary Howard Lutnick look on as White House artificial intelligence (AI) and crypto czar David Sacks speaks.\t</figcaption>\n</figure>\n<p class=\"has-text-align-none\">On Thursday evening, with White House AI and crypto czar David Sacks <a href=\"https://www.youtube.com/live/rYDbVjXu5os?si=TUpA0_o7ORLU9jZh&amp;t=737\">looking over his shoulder</a>, Donald Trump <a href=\"https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/\">signed an executive order</a> aiming to grab unilateral power over regulating artificial intelligence for the federal government. The order <a href=\"https://www.theverge.com/column/829938/leaked-ai-executive-order-analysis\">can't by itself unilaterally override state AI laws</a>, but it directs federal agencies to take steps to reduce or eliminate their influence, and discourage states from passing laws that the federal government might challenge, or put crucial funding for other programs at risk.</p>\n<p class=\"has-text-align-none\">It specifically calls out Colorado's <a href=\"https://leg.colorado.gov/bills/sb24-205\">recently passed consumer protection law</a>, making the claim that \"banning 'algorithmic discri …</p>\n<p><a href=\"https://www.theverge.com/ai-artificial-intelligence/841817/trump-signs-ai-executive-order-pushing-to-ban-state-laws\">Read the full story at The Verge.</a></p>\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t",
    "titleJa": "トランプ大統領、AIに関する大統領令に署名、州法規制の禁止を推進",
    "summaryJa": "トランプ大統領が、AI規制に関する連邦政府の一方的な権限掌握を目指す大統領令に署名。州法の影響を排除し、連邦政府に異議を唱える可能性のある州法の制定を阻止する狙い。",
    "explanationJa": "トランプ大統領は、AI規制を連邦政府主導で行うため、州法の規制を制限する大統領令に署名しました。",
    "translationJa": "ドナルド・トランプ大統領は木曜日の夕方、ホワイトハウスのAIおよび暗号資産担当顧問であるデビッド・サックス氏が見守る中、人工知能（AI）の規制において連邦政府が一方的な権限を掌握することを目的とした大統領令に署名しました。この大統領令は、それ自体では一方的に州のAI法を無効にすることはできませんが、連邦政府機関に対し、州法の影響を軽減または排除するための措置を講じ、連邦政府が異議を唱える可能性のある法律を州が制定することを阻止し、他のプログラムへの重要な資金提供を危険にさらすことを阻止するよう指示しています。\n\n特に、コロラド州で最近可決された消費者保護法を取り上げ、「アルゴリズムによる差別を禁止する…」と主張しています。\n\nThe Vergeで記事全文をお読みください。",
    "insightJa": "この動きは、AI技術の発展と普及に大きな影響を与える可能性があります。企業は、州ごとの異なる規制に対応する必要がなくなり、ビジネス展開が容易になる一方、消費者保護の面では懸念も残ります。",
    "recommendedBooks": [
      "人工知能 規制",
      "AI ガバナンス",
      "技術政策"
    ],
    "tags": [
      "AI",
      "Artificial Intelligence",
      "Executive Order",
      "Regulation",
      "トランプ大統領"
    ],
    "imageUrl": "https://picsum.photos/seed/10929/400/300"
  },
  {
    "id": "https://techcrunch.com/?p=3075457",
    "title": "Google launched its deepest AI research agent yet — on the same day OpenAI dropped GPT-5.2",
    "source": "rss",
    "url": "https://techcrunch.com/2025/12/11/google-launched-its-deepest-ai-research-agent-yet-on-the-same-day-openai-dropped-gpt-5-2/",
    "summary": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "publishedAt": "Fri, 12 Dec 2025 00:18:56 +0000",
    "author": "Julie Bort",
    "category": "AI",
    "originalContent": "For the first time, developers can embed Google's Deep Research tool, based on Gemini 3 Pro, into their own apps.",
    "titleJa": "Googleが過去最高のAI研究エージェントを発表 - OpenAIがGPT-5.2を公開した同日に",
    "summaryJa": "GoogleはGemini 3 Proを基盤とした深層研究ツールを開発者向けに公開し、アプリへの組み込みを可能にしました。OpenAIのGPT-5.2発表と同日の発表です。",
    "explanationJa": "Googleの最新AI研究ツールが利用可能になり、より高度なアプリ開発が期待されます。",
    "translationJa": "開発者は初めて、Gemini 3 Proを基盤としたGoogleの深層研究ツールを自身のアプリケーションに組み込むことができるようになりました。",
    "insightJa": "このツールによって、より高度なAI機能を組み込んだアプリケーションが開発され、業務効率化や新たな顧客体験の創出に繋がる可能性があります。特に、情報収集や分析業務において大きな影響を与えるかもしれません。",
    "recommendedBooks": [
      "深層学習 実践",
      "AI アプリケーション開発",
      "大規模言語モデル"
    ],
    "tags": [
      "Google",
      "Gemini 3 Pro",
      "AI Research",
      "OpenAI",
      "GPT-5.2"
    ],
    "imageUrl": "https://picsum.photos/seed/2793/400/300"
  },
  {
    "id": "7iBvnTz8OK7lcxexlxh4OW",
    "title": "Google’s new framework helps AI agents spend their compute and tool budget more wisely",
    "source": "rss",
    "url": "https://venturebeat.com/ai/googles-new-framework-helps-ai-agents-spend-their-compute-and-tool-budget",
    "summary": "In a new paper that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple \"Budget Tracker\" and a more comprehensive framework called \"Budget Aware Test-time Scaling.\" These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.\nAs AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.\nFor enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.\nThe challenge of scaling tool use\nTraditional test-time scaling focuses on letting models \"think\" longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.\nThis introduces significant operational overhead for businesses. \"Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,\" Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. \"Tool calls themselves introduce additional API costs.\"\nThe researchers found that simply granting agents more test-time resources does not guarantee better performance. \"In a deep research task, if the agent has no sense of budget, it often goes down blindly,\" Wang and Liu explained. \"It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.\"\nOptimizing resources with Budget Tracker\nTo evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called \"Budget Tracker.\" This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.\nThe team hypothesized that \"providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.\"\nBudget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)\nIn Google's implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.\nTo test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.\nThey tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as Gemini 2.5 Pro, Gemini 2.5 Flash, and Claude Sonnet 4. The experiments show that this simple plug-in improves performance across various budget constraints.\n\"Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,\" the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.\nBATS: A comprehensive framework for budget-aware scaling\nTo further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent's behavior as it formulates its response.\nBATS uses multiple modules to orchestrate the agent's actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to \"dig deeper\" into a promising lead or \"pivot\" to alternative paths based on resource availability.\nGiven an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.\nThe iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.\nThe researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.\nBATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.\nAccording to the authors, this efficiency makes previously expensive workflows viable. \"This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,\" they said.\nAs enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.\n\"We believe the relationship between reasoning and economics will become inseparable,\" Wang and Liu said. \"In the future, [models] must reason about value.\"",
    "publishedAt": "Fri, 12 Dec 2025 00:00:00 GMT",
    "author": "bendee983@gmail.com (Ben Dickson)",
    "category": "AI",
    "originalContent": "<p>In a <a href=\"https://arxiv.org/abs/2511.17006\"><u>new paper</u></a> that studies tool-use in large language model (LLM) agents, researchers at Google and UC Santa Barbara have developed a framework that enables agents to make more efficient use of tool and compute budgets. The researchers introduce two new techniques: a simple &quot;Budget Tracker&quot; and a more comprehensive framework called &quot;Budget Aware Test-time Scaling.&quot; These techniques make agents explicitly aware of their remaining reasoning and tool-use allowance.</p><p>As AI agents rely on tool calls to work in the real world, test-time scaling has become less about smarter models and more about controlling cost and latency.</p><p>For enterprise leaders and developers, budget-aware scaling techniques offer a practical path to deploying effective AI agents without facing unpredictable costs or diminishing returns on compute spend.</p><h2>The challenge of scaling tool use</h2><p>Traditional <a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>test-time scaling</u></a> focuses on letting models &quot;think&quot; longer. However, for agentic tasks like web browsing, the number of tool calls directly determines the depth and breadth of exploration.</p><p>This introduces significant operational overhead for businesses. &quot;Tool calls such as webpage browsing results in more token consumption, increases the context length and introduces additional time latency,&quot; Zifeng Wang and Tengxiao Liu, co-authors of the paper, told VentureBeat. &quot;Tool calls themselves introduce additional API costs.&quot;</p><p>The researchers found that simply granting agents more test-time resources does not guarantee better performance. &quot;In a deep research task, if the agent has no sense of budget, it often goes down blindly,&quot; Wang and Liu explained. &quot;It finds one somewhat related lead, then spends 10 or 20 tool calls digging into it, only to realize that the entire path was a dead end.&quot;</p><h2>Optimizing resources with Budget Tracker</h2><p>To evaluate how they can optimize tool-use budgets, the researchers first tried a lightweight approach called &quot;Budget Tracker.&quot; This module acts as a plug-in that provides the agent with a continuous signal of resource availability, enabling budget-aware tool use.</p><p>The team hypothesized that &quot;providing explicit budget signals enables the model to internalize resource constraints and adapt its strategy without requiring additional training.&quot;</p><p>Budget Tracker operates purely at the prompt level, which makes it easy to implement. (The paper provides full details on the prompts used for Budget Tracker, which makes it easy to implement.)</p><p>In Google&#x27;s implementation, the tracker provides a brief policy guideline describing the budget regimes and corresponding recommendations for using tools. At each step of the response process, Budget Tracker makes the agent explicitly aware of its resource consumption and remaining budget, enabling it to condition subsequent reasoning steps on the updated resource state.</p><p>To test this, the researchers experimented with two paradigms: sequential scaling, where the model iteratively refines its output, and parallel scaling, where multiple independent runs are conducted and aggregated. They ran experiments on search agents equipped with search and browse tools following a ReAct-style loop. ReAct (Reasoning + Acting) is a popular method where the model alternates between internal thinking and external actions. To trace a true cost-performance scaling trend, they developed a unified cost metric that jointly accounts for the costs of both internal token consumption and external tool interactions.</p><p>They tested Budget Tracker on three information-seeking QA datasets requiring external search, including BrowseComp and HLE-Search, using models such as <a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>, Gemini 2.5 Flash, and <a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>. The experiments show that this simple plug-in improves performance across various budget constraints.</p><p>&quot;Adding Budget Tracker achieves comparable accuracy using 40.4% fewer search calls, 19.9% fewer browse calls, and reducing overall cost … by 31.3%,&quot; the authors told VentureBeat. Finally, Budget Tracker continued to scale as the budget increased, whereas plain ReAct plateaued after a certain threshold.</p><h2>BATS: A comprehensive framework for budget-aware scaling</h2><p>To further improve tool-use resource optimization, the researchers introduced Budget Aware Test-time Scaling (BATS), a framework designed to maximize agent performance under any given budget. BATS maintains a continuous signal of remaining resources and uses this information to dynamically adapt the agent&#x27;s behavior as it formulates its response.</p><p>BATS uses multiple modules to orchestrate the agent&#x27;s actions. A planning module adjusts stepwise effort to match the current budget, while a verification module decides whether to &quot;dig deeper&quot; into a promising lead or &quot;pivot&quot; to alternative paths based on resource availability.</p><p>Given an information-seeking question and a tool-call budget, BATS begins by using the planning module to formulate a structured action plan and decide which tools to invoke. When tools are invoked, their responses are appended to the reasoning sequence to provide the context with new evidence. When the agent proposes a candidate answer, the verification module verifies it and decides whether to continue the current sequence or initiate a new attempt with the remaining budget.</p><p>The iterative process ends when budgeted resources are exhausted, at which point an LLM-as-a-judge selects the best answer across all verified answers. Throughout the execution, the Budget Tracker continuously updates both resource usage and remaining budget at every iteration.</p><p>The researchers tested BATS on the BrowseComp, BrowseComp-ZH, and HLE-Search benchmarks against baselines including standard ReAct and various training-based agents. Their experiments show that BATS achieves higher performance while using fewer tool calls and incurring lower overall cost than competing methods. Using Gemini 2.5 Pro as the backbone, BATS achieved 24.6% accuracy on BrowseComp compared to 12.6% for standard ReAct, and 27.0% on HLE-Search compared to 20.5% for ReAct.</p><p>BATS not only improves effectiveness under budget constraints but also yields better cost–performance trade-offs. For example, on the BrowseComp dataset, BATS achieved higher accuracy at a cost of approximately 23 cents compared to a parallel scaling baseline that required over 50 cents to achieve a similar result.</p><p>According to the authors, this efficiency makes previously expensive workflows viable. &quot;This unlocks a range of long-horizon, data-intensive enterprise applications… such as complex codebase maintenance, due-diligence investigations, competitive landscape research, compliance audits, and multi-step document analysis,&quot; they said.</p><p>As enterprises look to deploy agents that manage their own resources, the ability to balance accuracy with cost will become a critical design requirement.</p><p>&quot;We believe the relationship between reasoning and economics will become inseparable,&quot; Wang and Liu said. &quot;In the future, [models] must reason about value.&quot;</p><p>\n</p>",
    "titleJa": "Googleの新フレームワーク、AIエージェントの計算資源とツール利用をより賢く配分",
    "summaryJa": "Googleの研究者らが、LLMエージェントにおけるツール利用効率を高めるフレームワークを開発。Budget TrackerとBATSという2つの技術で、コスト管理を可能にする。",
    "explanationJa": "AIエージェントが計算資源を賢く使い、より効率的にタスクを実行できるようになる技術が開発されました。",
    "translationJa": "<p>大規模言語モデル(LLM)エージェントにおけるツール利用を研究した<a href=\"https://arxiv.org/abs/2511.17006\"><u>新たな論文</u></a>で、Googleとカリフォルニア大学サンタバーバラ校の研究者らは、エージェントがツールと計算資源の予算をより効率的に使えるようにするフレームワークを開発しました。研究者らは、シンプルな「Budget Tracker」と、より包括的なフレームワーク「Budget Aware Test-time Scaling」という2つの新しい技術を導入しました。これらの技術により、エージェントは残りの推論とツール利用の許容量を明確に認識することができます。</p><p>AIエージェントが現実世界で機能するためにツール呼び出しに依存するにつれて、テスト時のスケーリングは、より賢いモデルを作るというよりも、コストとレイテンシーを制御することに重点が置かれるようになりました。</p><p>企業のリーダーや開発者にとって、予算を意識したスケーリング技術は、予測不可能なコストや計算資源の消費における収益逓減に直面することなく、効果的なAIエージェントを導入するための現実的な道を提供します。</p><h2>ツール利用のスケーリングの課題</h2><p>従来の<a href=\"https://venturebeat.com/ai/how-test-time-scaling-unlocks-hidden-reasoning-abilities-in-small-language-models-and-allows-them-to-outperform-llms\"><u>テスト時のスケーリング</u></a>は、モデルに「より長く考える」ことを許可することに焦点を当てています。しかし、ウェブブラウジングのようなエージェントタスクでは、ツール呼び出しの数が、探求の深さと幅を直接決定します。</p><p>これは、企業にとって重大な運用上のオーバーヘッドをもたらします。論文の共著者であるZifeng WangとTengxiao Liuは、VentureBeatに次のように語っています。「ウェブページの閲覧などのツール呼び出しは、より多くのトークン消費、コンテキスト長の増加、および追加の時間レイテンシーにつながります。ツール呼び出し自体が追加のAPIコストをもたらします。」</p><p>研究者らは、エージェントにもっと多くのテスト時のリソースを与えるだけでは、パフォーマンスの向上は保証されないことを発見しました。WangとLiuは、「深い調査タスクでは、エージェントが予算を意識していない場合、しばしば盲目的に進んでしまいます」と説明しています。「やや関連性のある手がかりを見つけ、それに10回または20回のツール呼び出しを費やして掘り下げた後、そのパス全体が行き止まりだったことに気づきます。」</p><h2>Budget Trackerによるリソースの最適化</h2><p>ツール利用の予算をどのように最適化できるかを評価するために、研究者らは最初に「Budget Tracker」と呼ばれる軽量なアプローチを試しました。このモジュールは、エージェントにリソースの可用性に関する継続的なシグナルを提供するプラグインとして機能し、予算を意識したツール利用を可能にします。</p><p>チームは、「明示的な予算シグナルを提供することで、モデルは追加のトレーニングを必要とせずに、リソースの制約を内部化し、その戦略を適応させることができる」と仮説を立てました。</p><p>Budget Trackerは、プロンプトレベルでのみ動作するため、実装が容易です。（論文には、Budget Trackerに使用されるプロンプトの詳細がすべて記載されており、実装が容易になっています。）</p><p>Googleの実装では、トラッカーは、予算体制とそれに対応するツール使用に関する推奨事項を説明する簡単なポリシーガイドラインを提供します。応答プロセスの各ステップで、Budget Trackerはエージェントにリソースの消費量と残りの予算を明示的に認識させ、それによって、後続の推論ステップを更新されたリソース状態に基づいて条件付けできるようにします。</p><p>これをテストするために、研究者らは、モデルが反復的に出力を改良するシーケンシャルスケーリングと、複数の独立した実行が行われ集約されるパラレルスケーリングという2つのパラダイムで実験を行いました。彼らは、ReActスタイルのループに従って検索および閲覧ツールを備えた検索エージェントで実験を行いました。ReAct（Reasoning + Acting）は、モデルが内部思考と外部アクションを交互に行う一般的な手法です。真のコストパフォーマンスのスケーリングトレンドを追跡するために、内部トークン消費と外部ツールインタラクションの両方のコストを共同で考慮する統一されたコストメトリックを開発しました。</p><p>彼らは、<a href=\"https://venturebeat.com/ai/beyond-benchmarks-gemini-2-5-pro-is-probably-the-best-reasoning-model-yet\"><u>Gemini 2.5 Pro</u></a>、Gemini 2.5 Flash、および<a href=\"https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker\"><u>Claude Sonnet 4</u></a>などのモデルを使用して、BrowseCompやHLE-Searchなど、外部検索を必要とする3つの情報検索QAデータセットでBudget Trackerをテストしました。実験の結果、このシンプルなプラグインは、さまざまな予算制約下でパフォーマンスを向上させることが示されました。</p><p>著者らはVentureBeatに、「Budget Trackerを追加すると、検索呼び出しが40.4％少なく、閲覧呼び出しが19.9％少なく、全体的なコストが31.3％削減され、同等の精度が達成されます」と語っています。最後に、Budget Trackerは予算が増加するにつれてスケーリングを続けましたが、プレーンなReActはある閾値を超えると停滞しました。</p><h2>BATS：予算を意識したスケーリングのための包括的なフレームワーク</h2><p>ツール利用のリソース最適化をさらに改善するために、研究者らは、与えられた予算下でエージェントのパフォーマンスを最大化するように設計されたフレームワークであるBudget Aware Test-time Scaling（BATS）を導入しました。BATSは、残りのリソースに関する継続的なシグナルを維持し、この情報を使用して、エージェントが応答を定式化する際に動的にその動作を適応させます。</p><p>BATSは、複数のモジュールを使用してエージェントのアクションを調整します。計画モジュールは、ステップごとの労力を現在の予算に合わせて調整し、検証モジュールは、有望なリードを「より深く掘り下げる」か、リソースの可用性に基づいて代替パスに「ピボット」するかを決定します。</p><p>情報検索の質問とツール呼び出しの予算が与えられた場合、BATSは最初に計画モジュールを使用して、構造化されたアクションプランを策定し、どのツールを呼び出すかを決定します。ツールが呼び出されると、その応答が推論シーケンスに追加され、コンテキストに新しい証拠が提供されます。エージェントが候補の回答を提案すると、検証モジュールがそれを検証し、現在のシーケンスを続行するか、残りの予算で新しい試行を開始するかを決定します。</p><p>予算化されたリソースが使い果たされると、反復プロセスは終了し、その時点でLLM-as-a-judgeがすべての検証済み回答の中から最良の回答を選択します。実行全体を通して、Budget Trackerはすべての反復でリソースの使用量と残りの予算の両方を継続的に更新します。</p><p>研究者らは、BrowseComp、BrowseComp-ZH、およびHLE-Searchベンチマークで、標準のReActやさまざまなトレーニングベースのエージェントを含むベースラインに対してBATSをテストしました。彼らの実験は、BATSがより少ないツール呼び出しを使用し、競合する方法よりも低い全体的なコストを発生させながら、より高いパフォーマンスを達成することを示しています。Gemini 2.5 Proをバックボーンとして使用すると、BATSはBrowseCompで24.6％の精度を達成しましたが、標準のReActでは12.6％、HLE-Searchでは27.0％の精度を達成しましたが、ReActでは20.5％でした。</p><p>BATSは、予算の制約下での有効性を向上させるだけでなく、より優れたコストパフォーマンスのトレードオフも実現します。たとえば、BrowseCompデータセットでは、BATSは約23セントのコストでより高い精度を達成しましたが、同様の結果を達成するために50セント以上を必要とするパラレルスケーリングベースラインと比較してください。</p><p>著者らによると、この効率により、以前は費用のかかるワークフローが実現可能になります。「これにより、複雑なコードベースのメンテナンス、デューデリジェンス調査、競争環境の調査、コンプライアンス監査、多段階のドキュメント分析など、長期的なデータ集約型のエンタープライズアプリケーションが実現します」と彼らは述べています。</p><p>企業が独自のリソースを管理するエージェントの展開を検討するにつれて、コストと精度のバランスを取る能力が重要な設計要件になります。</p><p>WangとLiuは、「推論と経済の関係は切り離せなくなるだろうと信じています」と述べています。「将来的には、[モデルは]価値について推論する必要があります。」</p><p></p>",
    "insightJa": "AIエージェントが賢くリソースを使えることで、これまでコスト的に難しかった業務が自動化され、ビジネスの効率化や新しいサービスの開発につながる可能性があります。将来的にはAIの経済性がより重要になるでしょう。",
    "recommendedBooks": [
      "AIエージェント",
      "大規模言語モデル",
      "AIコスト削減"
    ],
    "tags": [
      "LLM",
      "AI agent",
      "Budget Aware Test-time Scaling",
      "Resource Optimization",
      "コスト最適化"
    ],
    "imageUrl": "https://picsum.photos/seed/2023/400/300"
  },
  {
    "id": "6h3LTzDwRwKFT22aRVaumY",
    "title": "GPT-5.2 first impressions: a powerful update, especially for business tasks and workflows",
    "source": "rss",
    "url": "https://venturebeat.com/ai/gpt-5-2-first-impressions-a-powerful-update-especially-for-business-tasks",
    "summary": "OpenAI has officially released GPT-5.2, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming \"incremental\" update for casual conversationalists.\nFollowing early access periods and today's broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. \nHere is a roundup of the first reactions to OpenAI’s latest flagship model.\n\"AI as a serious analyst\"\nThe strongest praise for GPT-5.2 centers on its ability to handle \"hard problems\" that require extended thinking time.\nMatt Shumer, CEO of HyperWriteAI, did not mince words in his review, calling GPT-5.2 Pro \"the best model in the world.\" \nShumer highlighted the model's tenacity, noting that \"it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.\"\nThis sentiment was echoed by Allie K. Miller, an AI entrepreneur and former AWS executive. Miller described the model as a step toward \"AI as a serious analyst\" rather than a \"friendly companion.\"\n\"The thinking and problem-solving feel noticeably stronger,\" Miller wrote on X. \"It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.\"\nEnterprise gains: Box reports distinct performance jumps\nFor the enterprise sector, the update appears to be even more significant. \nAaron Levie, CEO of Box, revealed on X that his company has been testing GPT-5.2 in early access. Levie reported that the model performs \"7 points better than GPT-5.1\" on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.\n\"The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,\" Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.\nRutuja Rajwade, a Senior Product Marketing Manager at Box, expanded on this in a company blog post, citing specific latency improvements. \n\"Complex extraction\" tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. \nRajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.\nA \"serious leap\" for coding and simulation\nDevelopers are finding GPT-5.2 particularly potent for \"one-shot\" generation of complex code structures.\nPietro Schirano, CEO of magicpathai, shared a video of the model building a full 3D graphics engine in a single file with interactive controls. \"It’s a serious leap forward in complex reasoning, math, coding, and simulations,\" Schirano posted. \"The pace of progress is unreal.\"\n\nSimilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, demonstrated the model's ability to create a visually complex shader—an infinite neo-gothic city in a stormy ocean—via a single prompt.\nThe Agentic Era: Long-running autonomy\nPerhaps the most functional shift is the model's ability to stay on task for hours without losing the thread.\nDan Shipper, CEO of thoughtful AI testing newsletter Every, reported that the model successfully performed a profit and loss (P&L) analysis that required it to work autonomously for two hours. \"It did a P&L analysis where it worked for 2 hours and gave me great results,\" Shipper wrote.\nHowever, Shipper also noted that for day-to-day tasks, the update feels \"mostly incremental.\" \nIn an article for Every, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is \"less resourceful\" than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user's location from email data.\nThe downsides: Speed and Rigidity\nDespite the reasoning capabilities, the \"feel\" of the model has drawn critique.\nShumer highlighted a significant \"speed penalty\" when using the model's Thinking mode. \"In my experience the Thinking mode is very slow for most questions,\" Shumer wrote in his deep-dive review. \"I almost never use Instant.\"\nAllie Miller also pointed out issues with the model's default behavior. \"The downside is tone and format,\" she noted. \"The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.\"\nThe Verdict\nThe early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: \"For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.\"\nHowever, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. \"My favorite model remains Claude Opus 4.5,\" Miller admitted, \"but my complex ChatGPT work will get a nice incremental boost.\"",
    "publishedAt": "Thu, 11 Dec 2025 23:26:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>OpenAI has officially <a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">released GPT-5.2</a>, and the reactions from early testers — among whom OpenAI seeded the model several days prior to public release, in some cases weeks ago — paints a two toned picture: it is a monumental leap forward for deep, autonomous reasoning and coding, yet potentially an underwhelming &quot;incremental&quot; update for casual conversationalists.</p><p>Following early access periods and today&#x27;s broader rollout, executives, developers, and analysts have taken to X (formerly Twitter) and company blogs to share their first testing results. </p><p>Here is a roundup of the first reactions to OpenAI’s latest flagship model.</p><h3><b>&quot;AI as a serious analyst&quot;</b></h3><p>The strongest praise for GPT-5.2 centers on its ability to handle &quot;hard problems&quot; that require extended thinking time.</p><p>Matt Shumer, CEO of HyperWriteAI, did not mince words in <a href=\"https://shumer.dev/gpt52review\">his review</a>, calling GPT-5.2 Pro &quot;the best model in the world.&quot; </p><p>Shumer highlighted the model&#x27;s tenacity, noting that &quot;it thinks for **over an hour** on hard problems. And it nails tasks no other model can touch.&quot;</p><p>This sentiment was<a href=\"https://x.com/alliekmiller/status/1999189893910790427\"> echoed by Allie K. Miller</a>, an AI entrepreneur and former AWS executive. Miller described the model as a step toward &quot;AI as a serious analyst&quot; rather than a &quot;friendly companion.&quot;</p><p>&quot;The thinking and problem-solving feel noticeably stronger,&quot; Miller wrote on X. &quot;It gives much deeper explanations than I’m used to seeing. At one point it literally wrote code to improve its own OCR in the middle of a task.&quot;</p><h3><b>Enterprise gains: Box reports distinct performance jumps</b></h3><p>For the enterprise sector, the update appears to be even more significant. </p><p><a href=\"https://x.com/levie/status/1999191612321391058\">Aaron Levie, CEO of Box, revealed on X</a> that his company has been testing GPT-5.2 in early access. Levie reported that the model performs &quot;7 points better than GPT-5.1&quot; on their expanded reasoning tests, which approximate real-world knowledge work in financial services and life sciences.</p><p>&quot;The model performed the majority of the tasks far faster than GPT-5.1 and GPT-5 as well,&quot; Levie noted, confirming that Box AI will be rolling out GPT-5.2 integration shortly.</p><p>Rutuja Rajwade, a Senior Product Marketing Manager at Box, <a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">expanded on this in a company blog post</a>, citing specific latency improvements. </p><p>&quot;Complex extraction&quot; tasks dropped from 46 seconds on GPT-5 to just 12 seconds with GPT-5.2. </p><p>Rajwade also noted a jump in reasoning capabilities for the Media and Entertainment vertical, rising from 76% accuracy in GPT-5.1 to 81% in the new model.</p><h3><b>A &quot;serious leap&quot; for coding and simulation</b></h3><p>Developers are finding GPT-5.2 particularly potent for &quot;one-shot&quot; generation of complex code structures.</p><p>Pietro Schirano, CEO of magicpathai, <a href=\"https://x.com/skirano/status/1999182295685644366\">shared a video </a>of the model building a full 3D graphics engine in a single file with interactive controls. &quot;It’s a serious leap forward in complex reasoning, math, coding, and simulations,&quot; Schirano posted. &quot;The pace of progress is unreal.&quot;</p><div></div><p>S<!-- -->imilarly, Ethan Mollick, a professor at the Wharton School of Business at the University of Pennsylvania and longtime LLM and AI power user and writer, <a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">demonstrated the model&#x27;s ability to create a visually complex shader</a>—an infinite neo-gothic city in a stormy ocean—via a single prompt.</p><h3><b>The Agentic Era: Long-running autonomy</b></h3><p>Perhaps the most functional shift is the model&#x27;s ability to stay on task for hours without losing the thread.</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">Dan Shipper, CEO of thoughtful AI testing newsletter Every</a>, reported that the model successfully performed a profit and loss (P&amp;L) analysis that required it to work autonomously for two hours. &quot;It did a P&amp;L analysis where it worked for 2 hours and gave me great results,&quot; Shipper wrote.</p><p>However, Shipper also noted that for day-to-day tasks, the update feels &quot;mostly incremental.&quot; </p><p>In <a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">an article for Every</a>, Katie Parrott wrote that while GPT-5.2 excels at instruction following, it is &quot;less resourceful&quot; than competitors like Claude Opus 4.5 in certain contexts, such as deducing a user&#x27;s location from email data.</p><h3><b>The downsides: Speed and Rigidity</b></h3><p>Despite the reasoning capabilities, the &quot;feel&quot; of the model has drawn critique.</p><p>Shumer highlighted a significant &quot;speed penalty&quot; when using the model&#x27;s Thinking mode. &quot;In my experience the Thinking mode is very slow for most questions,&quot; Shumer wrote in his deep-dive review. &quot;I almost never use Instant.&quot;</p><p>Allie Miller also pointed out issues with the model&#x27;s default behavior. &quot;The downside is tone and format,&quot; she noted. &quot;The default voice felt a bit more rigid, and the length/markdown behavior is extreme: a simple question turned into 58 bullets and numbered points.&quot;</p><h3><b>The Verdict</b></h3><p>The early reaction suggests that GPT-5.2 is a tool optimized for power users, developers, and enterprise agents rather than casual chat. As Shumer summarized in his review: &quot;For deep research, complex reasoning, and tasks that benefit from careful thought, GPT-5.2 Pro is the best option available right now.&quot;</p><p>However, for users seeking creative writing or quick, fluid answers, models like Claude Opus 4.5 remain strong competitors. &quot;My favorite model remains Claude Opus 4.5,&quot; Miller admitted, &quot;but my complex ChatGPT work will get a nice incremental boost.&quot;</p>",
    "titleJa": "GPT-5.2の第一印象：特にビジネス業務とワークフローにおいて強力なアップデート",
    "summaryJa": "GPT-5.2は、高度な推論とコーディング能力が大幅に向上。ビジネス分野では目覚ましい性能向上が見られる一方、日常会話では進化は限定的との評価も。",
    "explanationJa": "GPT-5.2は、特にビジネスや専門的な作業において、以前のバージョンよりも優れた性能を発揮するようです。",
    "translationJa": "<p>OpenAIは正式に<a href=\"https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know\">GPT-5.2をリリースしました</a>。早期テスターからの反応（OpenAIが一般公開の数日前、場合によっては数週間前からモデルを提供していた）は、二面性を示しています。それは、深く自律的な推論とコーディングにおいて記念碑的な飛躍ですが、カジュアルな会話者にとっては潜在的に「漸進的な」アップデートです。</p><p>早期アクセス期間と今日の広範な展開を受けて、経営幹部、開発者、アナリストはX（旧Twitter）や企業のブログで最初のテスト結果を共有しています。</p><p>OpenAIの最新フラッグシップモデルに対する最初の反応をまとめました。</p><h3><b>「真剣なアナリストとしてのAI」</b></h3><p>GPT-5.2に対する最も強い称賛は、長時間の思考時間を必要とする「難しい問題」を処理する能力に集中しています。</p><p>HyperWriteAIのCEOであるMatt Shumerは、<a href=\"https://shumer.dev/gpt52review\">彼のレビュー</a>で言葉を濁すことなく、GPT-5.2 Proを「世界最高のモデル」と呼びました。</p><p>Shumerはモデルの粘り強さを強調し、「難しい問題に対して**1時間以上**考えます。そして、他のどのモデルも触れることができないタスクを成し遂げます」と述べています。</p><p>この感情は、AI起業家であり、元AWS幹部の<a href=\"https://x.com/alliekmiller/status/1999189893910790427\">Allie K. Millerによっても繰り返されました</a>。 Millerは、このモデルを「フレンドリーなコンパニオン」ではなく、「真剣なアナリストとしてのAI」への一歩として説明しました。</p><p>「思考と問題解決は著しく強力になったと感じます」とMillerはXに書いています。「私がいつも見ているよりもはるかに深い説明をしてくれます。ある時、タスクの途中で自分のOCRを改善するためのコードを文字通り書きました。」</p><h3><b>エンタープライズの利点：Boxが明確なパフォーマンス向上を報告</b></h3><p>エンタープライズセクターにとって、このアップデートはさらに重要なようです。</p><p><a href=\"https://x.com/levie/status/1999191612321391058\">BoxのCEOであるAaron Levieは、Xで明らかにしました</a>。彼の会社は早期アクセスでGPT-5.2をテストしています。 Levieは、金融サービスとライフサイエンスにおける実際の知識作業を近似する拡張された推論テストで、モデルが「GPT-5.1よりも7ポイント優れている」と報告しました。</p><p>「モデルは、GPT-5.1およびGPT-5よりもはるかに高速にタスクの大部分を実行しました」とLevieは述べ、Box AIがGPT-5.2の統合を間もなく展開することを確認しました。</p><p>BoxのシニアプロダクトマーケティングマネージャーであるRutuja Rajwadeは、<a href=\"https://blog.box.com/how-openais-gpt-52-delivers-lightning-fast-specialist-level-reasoning\">会社のブログ投稿でこれを詳しく説明し</a>、具体的なレイテンシーの改善を挙げています。</p><p>「複雑な抽出」タスクは、GPT-5では46秒から、GPT-5.2ではわずか12秒に短縮されました。</p><p>Rajwadeはまた、メディアおよびエンターテインメント業界の推論能力がGPT-5.1の76％の精度から新しいモデルでは81％に向上したことも指摘しました。</p><h3><b>コーディングとシミュレーションにおける「重大な飛躍」</b></h3><p>開発者は、GPT-5.2が複雑なコード構造の「ワンショット」生成に特に強力であると考えています。</p><p>magicpathaiのCEOであるPietro Schiranoは、インタラクティブなコントロールを備えた完全な3Dグラフィックスエンジンを単一のファイルで構築するモデルの<a href=\"https://x.com/skirano/status/1999182295685644366\">ビデオを共有しました</a>。「複雑な推論、数学、コーディング、シミュレーションにおいて重大な飛躍です」とSchiranoは投稿しました。「進歩のペースは非現実的です。」</p><div></div><p>同様に、ペンシルベニア大学ウォートン・スクールの教授であり、長年のLLMおよびAIパワーユーザー兼ライターであるEthan Mollickは、<a href=\"https://x.com/emollick/status/1999185085719887978?s=20\">モデルが単一のプロンプトを介して、視覚的に複雑なシェーダー（嵐の海に浮かぶ無限のネオゴシック都市）を作成する能力を実証しました</a>。</p><h3><b>エージェントの時代：長期間の自律性</b></h3><p>おそらく最も機能的な変化は、モデルがスレッドを失うことなく何時間もタスクに集中できることです。</p><p><a href=\"https://x.com/danshipper/status/1999180972995281298?s=20\">thougful AI testing newsletter EveryのCEOであるDan Shipper</a>は、モデルが2時間自律的に作業する必要がある損益（P＆L）分析を正常に実行したと報告しました。「2時間作業して素晴らしい結果をもたらしたP＆L分析を行いました」とShipperは書いています。</p><p>ただし、Shipperはまた、日常的なタスクでは、アップデートは「ほとんど漸進的」だと感じると指摘しました。</p><p><a href=\"https://every.to/vibe-check/vibe-check-gpt-5-2-is-an-incremental-upgrade\">Everyの記事</a>で、Katie Parrottは、GPT-5.2は指示に従うことに優れていますが、電子メールデータからユーザーの場所を推測するなど、特定の状況ではClaude Opus 4.5のような競合他社よりも「リソースが少ない」と書いています。</p><h3><b>短所：速度と剛性</b></h3><p>推論能力にもかかわらず、モデルの「感触」は批判を呼んでいます。</p><p>Shumerは、モデルの思考モードを使用するときの重大な「速度ペナルティ」を強調しました。「私の経験では、思考モードはほとんどの質問に対して非常に遅いです」とShumerは詳細なレビューで書いています。「私はほとんどインスタントを使用しません。」</p><p>Allie Millerはまた、モデルのデフォルトの動作に関する問題も指摘しました。「短所はトーンとフォーマットです」と彼女は述べています。「デフォルトの声は少し硬直しているように感じられ、長さ/マークダウンの動作は極端です。簡単な質問が58個の箇条書きと番号付きのポイントになりました。」</p><h3><b>評決</b></h3><p>初期の反応は、GPT-5.2はカジュアルなチャットではなく、パワーユーザー、開発者、エンタープライズエージェント向けに最適化されたツールであることを示唆しています。 Shumerがレビューで要約したように、「綿密な調査、複雑な推論、および注意深い思考から恩恵を受けるタスクの場合、GPT-5.2 Proは現在利用可能な最良のオプションです。」</p><p>ただし、クリエイティブな執筆や迅速で流動的な回答を求めるユーザーにとっては、Claude Opus 4.5のようなモデルが強力な競合他社のままです。「私のお気に入りのモデルはClaude Opus 4.5のままです」とMillerは認めました。「しかし、私の複雑なChatGPT作業は、素晴らしい漸進的な後押しを受けるでしょう。」</p>",
    "insightJa": "GPT-5.2の登場により、企業の業務効率化や高度な分析がより身近になる可能性があります。しかし、日常的なタスクでは他のモデルの方が適している場合もあるため、用途に応じた使い分けが重要になりそうです。",
    "recommendedBooks": [
      "大規模言語モデル",
      "GPT-5 活用",
      "AI ビジネス応用"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "LLM",
      "AI",
      "ビジネス"
    ],
    "imageUrl": "https://picsum.photos/seed/1885/400/300"
  },
  {
    "id": "http://arxiv.org/abs/2512.10957v1",
    "title": "SceneMaker: Open-set 3D Scene Generation with Decoupled De-occlusion and Pose Estimation Model",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10957v1",
    "summary": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "publishedAt": "2025-12-11T18:59:56Z",
    "author": "Yukai Shi",
    "category": "AI",
    "originalContent": "We propose a decoupled 3D scene generation framework called SceneMaker in this work. Due to the lack of sufficient open-set de-occlusion and pose estimation priors, existing methods struggle to simultaneously produce high-quality geometry and accurate poses under severe occlusion and open-set settings. To address these issues, we first decouple the de-occlusion model from 3D object generation, and enhance it by leveraging image datasets and collected de-occlusion datasets for much more diverse open-set occlusion patterns. Then, we propose a unified pose estimation model that integrates global and local mechanisms for both self-attention and cross-attention to improve accuracy. Besides, we construct an open-set 3D scene dataset to further extend the generalization of the pose estimation model. Comprehensive experiments demonstrate the superiority of our decoupled framework on both indoor and open-set scenes. Our codes and datasets is released at https://idea-research.github.io/SceneMaker/.",
    "titleJa": "SceneMaker：分離された遮蔽解除と姿勢推定モデルを用いたオープンセット3Dシーン生成",
    "summaryJa": "本研究では、SceneMakerという分離型3Dシーン生成フレームワークを提案。遮蔽解除と姿勢推定の事前知識不足を解消し、高品質な形状と正確な姿勢を両立。屋内・屋外シーンで優れた性能を示す。",
    "explanationJa": "SceneMakerは、隠れた部分を認識し、物体の位置を正確に推定して、より自然な3Dシーンを生成する技術です。",
    "translationJa": "本研究では、SceneMakerと呼ばれる分離型3Dシーン生成フレームワークを提案します。既存の手法は、十分なオープンセットの遮蔽解除と姿勢推定の事前知識がないため、深刻な遮蔽やオープンセット環境下で高品質な形状と正確な姿勢を同時に生成することが困難です。これらの課題に対処するため、まず、遮蔽解除モデルを3Dオブジェクト生成から分離し、画像データセットと収集された遮蔽解除データセットを活用することで、より多様なオープンセットの遮蔽パターンに対応できるよう強化します。次に、自己注意機構と相互注意機構の両方を統合した統一的な姿勢推定モデルを提案し、精度を向上させます。さらに、姿勢推定モデルの汎化性能を向上させるために、オープンセット3Dシーンデータセットを構築します。広範な実験により、屋内シーンとオープンセットシーンの両方において、提案する分離型フレームワークの優位性が実証されました。コードとデータセットはhttps://idea-research.github.io/SceneMaker/で公開されています。",
    "insightJa": "この技術により、ゲームやVR/ARなどの分野で、よりリアルで自然な3D空間を体験できるようになるでしょう。また、ロボット工学や自動運転の分野においても、周囲の状況を正確に認識し、安全な行動を可能にする上で重要な役割を果たすと期待されます。",
    "recommendedBooks": [
      "3Dモデリング",
      "コンピュータビジョン",
      "深層学習 応用"
    ],
    "tags": [
      "3D Scene Generation",
      "De-occlusion",
      "Pose Estimation",
      "Open-set Learning",
      "SceneMaker"
    ],
    "imageUrl": "https://picsum.photos/seed/2609/400/300"
  },
  {
    "id": "http://arxiv.org/abs/2512.10952v1",
    "title": "Hierarchical Dataset Selection for High-Quality Data Sharing",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10952v1",
    "summary": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "publishedAt": "2025-12-11T18:59:55Z",
    "author": "Xiaona Zhou",
    "category": "AI",
    "originalContent": "The success of modern machine learning hinges on access to high-quality training data. In many real-world scenarios, such as acquiring data from public repositories or sharing across institutions, data is naturally organized into discrete datasets that vary in relevance, quality, and utility. Selecting which repositories or institutions to search for useful datasets, and which datasets to incorporate into model training are therefore critical decisions, yet most existing methods select individual samples and treat all data as equally relevant, ignoring differences between datasets and their sources. In this work, we formalize the task of dataset selection: selecting entire datasets from a large, heterogeneous pool to improve downstream performance under resource constraints. We propose Dataset Selection via Hierarchies (DaSH), a dataset selection method that models utility at both dataset and group (e.g., collections, institutions) levels, enabling efficient generalization from limited observations. Across two public benchmarks (Digit-Five and DomainNet), DaSH outperforms state-of-the-art data selection baselines by up to 26.2% in accuracy, while requiring significantly fewer exploration steps. Ablations show DaSH is robust to low-resource settings and lack of relevant datasets, making it suitable for scalable and adaptive dataset selection in practical multi-source learning workflows.",
    "titleJa": "高品質データ共有のための階層的データセット選択",
    "summaryJa": "機械学習の成功は高品質な学習データへのアクセスにかかっています。DaSHは、データセットとグループレベルで有用性をモデル化し、リソース制約下で性能を向上させます。",
    "explanationJa": "機械学習において、どのデータセットを使うかを賢く選ぶことで、より良い結果が得られるようになる、という研究です。",
    "translationJa": "現代の機械学習の成功は、高品質な学習データへのアクセスに大きく依存しています。公共リポジトリからのデータ取得や機関間での共有など、多くの現実世界のシナリオでは、データは本質的に離散的なデータセットとして編成され、関連性、品質、および有用性が異なります。したがって、有用なデータセットを検索するためにどのリポジトリまたは機関を選択するか、どのデータセットをモデルのトレーニングに組み込むかを決定することは非常に重要な決定事項ですが、既存のほとんどの方法は個々のサンプルを選択し、すべてのデータを同様に関連するものとして扱い、データセットとそのソース間の違いを無視しています。本研究では、データセット選択のタスクを定式化します。大規模で異質なプールからデータセット全体を選択し、リソース制約下でのダウンストリームパフォーマンスを向上させます。データセットとグループ（コレクション、機関など）の両方のレベルで有用性をモデル化するデータセット選択手法であるDataset Selection via Hierarchies (DaSH)を提案し、限られた観測からの効率的な汎化を可能にします。2つの公開ベンチマーク（Digit-FiveとDomainNet）において、DaSHは最先端のデータ選択ベースラインを最大26.2％精度で上回り、必要な探索ステップ数を大幅に削減します。アブレーションの結果、DaSHは低リソース環境や関連データセットの不足に対して堅牢であり、実用的なマルチソース学習ワークフローにおけるスケーラブルで適応的なデータセット選択に適していることが示されています。",
    "insightJa": "この技術は、企業がAIモデルを構築する際に、どのデータを利用すべきか効率的に判断することを可能にします。無駄なデータ探索を減らし、より少ないリソースで高精度なAIを実現することで、ビジネスの競争力向上に貢献する可能性があります。",
    "recommendedBooks": [
      "データサイエンス 入門",
      "機械学習 実践",
      "AI戦略"
    ],
    "tags": [
      "Machine Learning",
      "Dataset Selection",
      "Data Quality",
      "Hierarchical Learning",
      "機械学習"
    ],
    "imageUrl": "https://picsum.photos/seed/2604/400/300"
  },
  {
    "id": "http://arxiv.org/abs/2512.10949v1",
    "title": "Are We Ready for RL in Text-to-3D Generation? A Progressive Investigation",
    "source": "arxiv",
    "url": "http://arxiv.org/abs/2512.10949v1",
    "summary": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "publishedAt": "2025-12-11T18:59:52Z",
    "author": "Yiwen Tang",
    "category": "AI",
    "originalContent": "Reinforcement learning (RL), earlier proven to be effective in large language and multi-modal models, has been successfully extended to enhance 2D image generation recently. However, applying RL to 3D generation remains largely unexplored due to the higher spatial complexity of 3D objects, which require globally consistent geometry and fine-grained local textures. This makes 3D generation significantly sensitive to reward designs and RL algorithms. To address these challenges, we conduct the first systematic study of RL for text-to-3D autoregressive generation across several dimensions. (1) Reward designs: We evaluate reward dimensions and model choices, showing that alignment with human preference is crucial, and that general multi-modal models provide robust signal for 3D attributes. (2) RL algorithms: We study GRPO variants, highlighting the effectiveness of token-level optimization, and further investigate the scaling of training data and iterations. (3) Text-to-3D Benchmarks: Since existing benchmarks fail to measure implicit reasoning abilities in 3D generation models, we introduce MME-3DR. (4) Advanced RL paradigms: Motivated by the natural hierarchy of 3D generation, we propose Hi-GRPO, which optimizes the global-to-local hierarchical 3D generation through dedicated reward ensembles. Based on these insights, we develop AR3D-R1, the first RL-enhanced text-to-3D model, expert from coarse shape to texture refinement. We hope this study provides insights into RL-driven reasoning for 3D generation. Code is released at https://github.com/Ivan-Tang-3D/3DGen-R1.",
    "titleJa": "テキストから3D生成における強化学習の準備はできているか？進歩的な調査",
    "summaryJa": "テキストから3D生成に強化学習を適用する研究。報酬設計、RLアルゴリズム、ベンチマークを評価し、階層的な生成のための手法を提案。RL強化モデルAR3D-R1を開発。",
    "explanationJa": "テキストから3Dモデルを作る技術に強化学習を応用することで、より高品質な3Dモデルが生成できるようになるかもしれませんね。",
    "translationJa": "強化学習(RL)は、大規模言語モデルやマルチモーダルモデルにおいて有効であることが以前に証明されており、最近では2D画像生成を強化するために拡張されています。しかし、3Dオブジェクトの空間的な複雑さが高いため、3D生成へのRLの適用はほとんど探求されていません。3Dオブジェクトは、グローバルに一貫したジオメトリと、きめ細かいローカルテクスチャを必要とします。これにより、3D生成は報酬設計とRLアルゴリズムに著しく敏感になります。これらの課題に対処するために、我々はテキストから3Dの自己回帰生成に対するRLの最初の体系的な研究をいくつかの次元にわたって行います。(1)報酬設計: 報酬の次元とモデルの選択を評価し、人間の好みに合わせることが重要であること、そして一般的なマルチモーダルモデルが3D属性に対してロバストなシグナルを提供することを示します。(2)RLアルゴリズム: GRPOのバリアントを研究し、トークンレベルの最適化の有効性を強調し、さらにトレーニングデータとイテレーションのスケーリングを調査します。(3)テキストから3Dのベンチマーク: 既存のベンチマークは3D生成モデルにおける暗黙的な推論能力を測定できないため、MME-3DRを導入します。(4)高度なRLパラダイム: 3D生成の自然な階層構造に動機づけられ、グローバルからローカルへの階層的な3D生成を専用の報酬アンサンブルを通じて最適化するHi-GRPOを提案します。これらの洞察に基づいて、粗い形状からテクスチャの洗練までを専門とする、最初のRL強化テキストから3DモデルであるAR3D-R1を開発しました。この研究が、3D生成のためのRL駆動型推論への洞察を提供することを願っています。コードはhttps://github.com/Ivan-Tang-3D/3DGen-R1で公開されています。",
    "insightJa": "この研究が進むことで、ゲーム、デザイン、製造業など、様々な分野でより手軽に高品質な3Dモデルを作成できるようになるかもしれません。特に、個人のニーズに合わせたカスタマイズされた3Dモデルの作成が容易になる可能性があり、私たちの生活を豊かにするかもしれません。",
    "recommendedBooks": [
      "3Dモデリング 入門",
      "強化学習 実践",
      "画像生成AI 最新"
    ],
    "tags": [
      "Text-to-3D",
      "Reinforcement Learning",
      "3D Generation",
      "AR3D-R1",
      "MME-3DR"
    ],
    "imageUrl": "https://picsum.photos/seed/2610/400/300"
  },
  {
    "id": "5AH2xqcQJzMolV09W5VM43",
    "title": "OpenAI's GPT-5.2 is here: what enterprises need to know",
    "source": "rss",
    "url": "https://venturebeat.com/ai/openais-gpt-5-2-is-here-what-enterprises-need-to-know",
    "summary": "The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, GPT-5.2.\nIt comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival Google’s Gemini 3 LLM seized the top spot on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.\nOpenAI describes GPT-5.2 as its \"most capable model series yet for professional knowledge work,\" aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.\n\"It’s our most advanced frontier model and the strongest yet in the market for professional use,\" Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. \"We designed 5.2 to unlock even more economic value for people. It's better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.\"\nGPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.\nThe model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes \"Reasoning token support,\" confirming the underlying architecture uses the chain-of-thought processing popularized by the \"o1\" series.\nThe 'Code Red' Reality Check\nThe release arrives following The Information's report of an emergency \"Code Red\" directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the \"quality gap\" exposed by Gemini 3. The Verge similarly reported on the timing of GPT-5.2's release ahead of the official announcement. \nDuring the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.\n\"It is important to note this has been in the works for many, many months,\" Simo told reporters. She clarified that while the \"Code Red\" helped focus the company, it wasn't the sole driver of the timeline. \n\"We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that's not the reason it's coming out this week in particular.\"\nMax Schwarzer, lead of OpenAI's post-training team, echoed this sentiment to dispel the idea of a panic launch. \"We've been planning for this release since a very long time ago... this specific week we talked about many months ago.\"\nA spokesperson from OpenAI further clarified that the \"Code Red\" call applied to ChatGPT as a product, not solely underlying model development or the release of new models.\nUnder the Hood: Instant, Thinking, and Pro\nOpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of \"reasoning\" models with user demand for speed:\n\nGPT-5.2 Instant: Optimized for speed and daily tasks like writing, translation, and information seeking.\n\nGPT-5.2 Thinking: Designed for \"complex, structured work\" and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.\n\nGPT-5.2 Pro: The new heavyweight champion. OpenAI describes this as its \"smartest and most trustworthy option,\" delivering the highest accuracy for difficult questions where quality outweighs latency.\n\nFor developers, the models are available immediately in the application programming interface (API) as gpt-5.2, gpt-5.2-chat-latest (Instant), and gpt-5.2-pro.\nThe Numbers: Beating the Benchmarks\nThe GPT-5.2 release includes leading metrics across most domains — specifically those that target the \"professional knowledge work\" gap where competitors have recently gained ground.\nOpenAI highlighted a new benchmark called GDPval, which measures performance on \"well-specified knowledge work tasks\" across 44 occupations. \n\"GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,\" Simo said.\nIn the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. \nHe emphasized that this benchmark is \"more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.\"Other key benchmark results include:\n\nGPQA Diamond (Science): GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).\n\nFrontierMath: On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.\n\nARC-AGI-1: GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring 90.5%\n\nThe Price of Intelligence\nPerformance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of \"thinking\" mode. They're also on the upper-end of API costs for the industry.  \n\nGPT-5.2 Thinking: Priced at $1.75 per 1 million input tokens and $14 per 1 million output tokens.\n\nGPT-5.2 Pro: The costs jump significantly to $21 per 1 million input tokens and $168 per 1 million output tokens.\n\nGPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.\nThe high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.\nOpenAI argues that despite the higher per-token cost, the model’s \"greater token efficiency\" and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.\nHere's how it compares to the current API costs for other competing models across the LLM field:\n\n\nModel\n\nInput (/1M)\n\nOutput (/1M)\n\nTotal Cost\n\nSource\n\n\nQwen 3 Turbo\n\n$0.05\n\n$0.20\n\n$0.25\n\nAlibaba Cloud\n\n\nGrok 4.1 Fast (reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\nGrok 4.1 Fast (non-reasoning)\n\n$0.20\n\n$0.50\n\n$0.70\n\nxAI\n\n\ndeepseek-chat (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\ndeepseek-reasoner (V3.2-Exp)\n\n$0.28\n\n$0.42\n\n$0.70\n\nDeepSeek\n\n\nQwen 3 Plus\n\n$0.40\n\n$1.20\n\n$1.60\n\nAlibaba Cloud\n\n\nERNIE 5.0\n\n$0.85\n\n$3.40\n\n$4.25\n\nQianfan\n\n\nClaude Haiku 4.5\n\n$1.00\n\n$5.00\n\n$6.00\n\nAnthropic\n\n\nQwen-Max\n\n$1.60\n\n$6.40\n\n$8.00\n\nAlibaba Cloud\n\n\nGemini 3 Pro (≤200K)\n\n$2.00\n\n$12.00\n\n$14.00\n\nGoogle\n\n\nGPT-5.2\n\n$1.75\n\n$14.00\n\n$15.75\n\nOpenAI\n\n\nGemini 3 Pro (>200K)\n\n$4.00\n\n$18.00\n\n$22.00\n\nGoogle\n\n\nClaude Sonnet 4.5\n\n$3.00\n\n$15.00\n\n$18.00\n\nAnthropic\n\n\nClaude Opus 4.5\n\n$5.00\n\n$25.00\n\n$30.00\n\nAnthropic\n\n\nGPT-5.2 Pro\n\n$21.00\n\n$168.00\n\n$189.00\n\nOpenAI\n\n\nImage Generation: Nothing New Yet...But 'More to Come'\nDuring the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google's Gemini 3 Image aka Nano Banana Pro. \nUnfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI's integrated DALL-E 3 and gpt-4o native image generation models.\n\"On image Gen, nothing to announce today, but more to come,\" Simo said. She acknowledged the popularity of the feature, adding, \"We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.\" \nAidan Clark, OpenAI's lead of training, also declined to comment on visual generation specifics, stating simply, \"I can't really speak to image Gen myself.\" \nThe 'Mega-Agent' Era\nBeyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of \"long-running agents\" capable of executing multi-step workflows without human hand-holding.\"\nBox found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,\" Simo said. \nShe also noted that Notion reported the model \"outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.\"Schwarzer added that coding startups like Augment Code found the model \"delivered substantially stronger deep code capabilities than any prior model,\" which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. \nOpenAI's release blog post shows an example where \"a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.\"\nThe outcome? \"GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.\"\nA new evaluation called ScreenSpot-Pro, which tests a model's ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.\nScience and Reliability\nOpenAI leaders also stressed the model's utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. \nAidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.\n\"They tested it by asking it to generate the most important unanswered questions about the immune system,\" Clark said. \"That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.\n\"Reliability was another key focus. Schwarzer claimed the new model \"hallucinates substantially less than GPT-5.1,\" noting that on a set of de-identified queries, \"responses contained errors 38% less often.\"\nThe 'Vibe' Shift\nInterestingly, OpenAI acknowledged that not every user might immediately prefer the new models. \nWhen asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that \"models change a little bit every time.\n\"Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,\" Schwarzer said. He also noted that for some enterprise customers who have \"really fine-tuned a prompt for a specific model,\" there might be \"small regressions,\" necessitating access to the older versions.\nSafety, 'Adult Mode,' and Future Roadmap\nAddressing safety concerns, Simo confirmed that the company is preparing to roll out an \"Adult Mode\" in the first quarter of next year, following the implementation of a new age prediction system.\n\"We're in the process of improving that,\" Simo said regarding the age prediction technology. \n\"We want to do that ahead of launching adult mode.\"Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename \"Project Garlic,\" targeting a flagship release in early 2026. \nWhile executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.\n\"If you look at historical trends, compute has increased about 3x every year for the last three years,\" she explained. \"Revenue has also increased at the same pace... creating this virtuous cycle.\"\nClark added that efficiency is improving rapidly: \"The model we're releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it\" compared to models from a year ago.\nGPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.",
    "publishedAt": "Thu, 11 Dec 2025 18:16:00 GMT",
    "author": "carl.franzen@venturebeat.com (Carl Franzen)",
    "category": "AI",
    "originalContent": "<p>The rumors were true: OpenAI on Thursday announced the release of its new frontier large language model (LLM) family, <a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>.</p><p>It comes at a pivotal moment for the AI pioneer, which has faced intensifying pressure since rival <a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">Google’s Gemini 3 LLM seized the top spot</a> on major third-party performance leaderboards and many key benchmarks last month, though OpenAI leaders stressed in a press briefing that the timing of this release had been discussed and worked on well in advance of the release of Gemini 3.</p><p>OpenAI describes GPT-5.2 as its &quot;most capable model series yet for professional knowledge work,&quot; aiming to reclaim the performance crown with significant gains in reasoning, coding, and agentic workflows.</p><p>&quot;It’s our most advanced frontier model and the strongest yet in the market for professional use,&quot; Fidji Simo, OpenAI’s CEO of Applications, said during a press briefing today. &quot;We designed 5.2 to unlock even more economic value for people. It&#x27;s better at creating spreadsheets, building presentations, writing code, perceiving images, understanding long context, using tools, and handling complex, multi-step projects.&quot;</p><p>GPT-5.2 features a massive 400,000-token context window — allowing it to ingest hundreds of documents or large code repositories at once — and a 128,000 max output token limit, enabling it to generate extensive reports or full applications in a single go.</p><p>The model also features a knowledge cutoff of August 31, 2025, ensuring it is up-to-date with relatively recent world events and technical documentation. It explicitly includes &quot;Reasoning token support,&quot; confirming the underlying architecture uses the chain-of-thought processing popularized by the &quot;o1&quot; series.</p><h3><b>The &#x27;Code Red&#x27; Reality Check</b></h3><p>The release arrives following<i> </i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\"><i>The Information</i>&#x27;s report</a> of an emergency &quot;Code Red&quot; directive to OpenAI staff from CEO Sam Altman to improve ChaTGPT — a move reportedly designed to mobilize resources following the &quot;quality gap&quot; exposed by Gemini 3.<a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\"><i> The Verge</i></a> similarly reported on the timing of GPT-5.2&#x27;s release ahead of the official announcement. </p><p>During the briefing, OpenAI executives acknowledged the directive but pushed back on the narrative that the model was rushed solely to answer Google.</p><p>&quot;It is important to note this has been in the works for many, many months,&quot; Simo told reporters. She clarified that while the &quot;Code Red&quot; helped focus the company, it wasn&#x27;t the sole driver of the timeline. </p><p>&quot;We announced this Code Red to really signal to the company that we want to marshal resources in one particular area... but that&#x27;s not the reason it&#x27;s coming out this week in particular.&quot;</p><p>Max Schwarzer, lead of OpenAI&#x27;s post-training team, echoed this sentiment to dispel the idea of a panic launch. &quot;We&#x27;ve been planning for this release since a very long time ago... this specific week we talked about many months ago.&quot;</p><p>A spokesperson from OpenAI further clarified that the &quot;Code Red&quot; call applied to ChatGPT as a product, not solely underlying model development or the release of new models.</p><h3><b>Under the Hood: Instant, Thinking, and Pro</b></h3><p>OpenAI is segmenting the GPT-5.2 release into three distinct tiers within ChatGPT, a strategy likely designed to balance the massive compute costs of &quot;reasoning&quot; models with user demand for speed:</p><ul><li><p><b>GPT-5.2 Instant:</b> Optimized for speed and daily tasks like writing, translation, and information seeking.</p></li><li><p><b>GPT-5.2 Thinking:</b> Designed for &quot;complex, structured work&quot; and long-running agents, this model leverages deeper reasoning chains to handle coding, math, and multi-step projects.</p></li><li><p><b>GPT-5.2 Pro:</b> The new heavyweight champion. OpenAI describes this as its &quot;smartest and most trustworthy option,&quot; delivering the highest accuracy for difficult questions where quality outweighs latency.</p></li></ul><p>For developers, the models are available immediately in the application programming interface (API) as <code>gpt-5.2</code>, <code>gpt-5.2-chat-latest</code> (Instant), and <code>gpt-5.2-pro</code>.</p><h3><b>The Numbers: Beating the Benchmarks</b></h3><p>The GPT-5.2 release includes leading metrics across most domains — specifically those that target the &quot;professional knowledge work&quot; gap where competitors have recently gained ground.</p><p>OpenAI highlighted a new benchmark called GDPval, which measures performance on &quot;well-specified knowledge work tasks&quot; across 44 occupations. </p><p>&quot;GPT-5.2 Thinking is now state-of-the-art on that benchmark... and beats or ties top industry professionals on 70.9% of well-specified professional tasks like spreadsheets, presentations, and document creation, according to expert human judges,&quot; Simo said.</p><p>In the critical arena of coding, OpenAI is claiming a decisive lead. Schwarzer noted that on SWE-bench Pro, a rigorous evaluation of real-world software engineering, GPT-5.2 Thinking sets a new state-of-the-art score of 55.6%. </p><p>He emphasized that this benchmark is &quot;more contamination resistant, challenging, diverse, and industrially relevant than previous benchmarks like SWE-bench Verified.&quot;Other key benchmark results include:</p><ul><li><p><b>GPQA Diamond (Science):</b> GPT-5.2 Pro scored 93.2%, edging out GPT-5.2 Thinking (92.4%) and surpassing GPT-5.1 Thinking (88.1%).</p></li><li><p><b>FrontierMath:</b> On Tier 1-3 problems, GPT-5.2 Thinking solved 40.3%, a significant jump from the 31.0% achieved by its predecessor.</p></li><li><p><b>ARC-AGI-1:</b> GPT-5.2 Pro is reportedly the first model to cross the 90% threshold on this general reasoning benchmark, scoring <b>90.5%</b></p></li></ul><h3><b>The Price of Intelligence</b></h3><p>Performance comes at a premium. While ChatGPT subscription pricing remains unchanged for now, the API costs for the new flagship models are steep compared to previous generations, reflecting the high compute demands of &quot;thinking&quot; mode. They&#x27;re also on the upper-end of API costs for the industry.  </p><ul><li><p><b>GPT-5.2 Thinking:</b> Priced at <b>$1.75</b> per 1 million input tokens and <b>$14</b> per 1 million output tokens.</p></li><li><p><b>GPT-5.2 Pro:</b> The costs jump significantly to <b>$21</b> per 1 million input tokens and <b>$168</b> per 1 million output tokens.</p></li></ul><p>GPT-5.2 Thinking is priced 40% higher in the API than the standard GPT-5.1 ($1.25/$10), signaling that OpenAI views the new reasoning capabilities as a tangible value-add rather than a mere efficiency update.</p><p>The high-end GPT-5.2 Pro follows the same pattern, costing 40% more than the previous GPT-5 Pro ($15/$120). While expensive, it still undercuts OpenAI’s most specialized reasoning model, o1-pro, which remains the most costly offering on the menu at a staggering $150 per million input tokens and $600 per million output tokens.</p><p>OpenAI argues that despite the higher per-token cost, the model’s &quot;greater token efficiency&quot; and ability to solve tasks in fewer turns make it economically viable for high-value enterprise workflows.</p><p>Here&#x27;s how it compares to the current API costs for other competing models across the LLM field:</p><table><tbody><tr><td><p><b>Model</b></p></td><td><p><b>Input (/1M)</b></p></td><td><p><b>Output (/1M)</b></p></td><td><p><b>Total Cost</b></p></td><td><p><b>Source</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>Image Generation: Nothing New Yet...But &#x27;More to Come&#x27;</b></h3><p>During the briefing, VentureBeat asked the OpenAI participants if the new release included any boost to image generation capabilities, noting the excitement around similar features in recent competitor launches like Google&#x27;s Gemini 3 Image aka Nano Banana Pro. </p><p>Unfortunately for those seeking to recreate the kind of text-and-information heavy graphics and image editing capabilities, OpenAI executives clarified that GPT-5.2 comes with no current image improvements over the prior GPT-5.1 and OpenAI&#x27;s integrated DALL-E 3 and gpt-4o native image generation models.</p><p>&quot;On image Gen, nothing to announce today, but more to come,&quot; Simo said. She acknowledged the popularity of the feature, adding, &quot;We know this is a very important use case that people love, that we introduced [to] the market, and so definitely more to come there.&quot; </p><p>Aidan Clark, OpenAI&#x27;s lead of training, also declined to comment on visual generation specifics, stating simply, &quot;I can&#x27;t really speak to image Gen myself.&quot; </p><h3><b>The &#x27;Mega-Agent&#x27; Era</b></h3><p>Beyond raw scores, OpenAI is positioning GPT-5.2 as the engine for a new generation of &quot;long-running agents&quot; capable of executing multi-step workflows without human hand-holding.&quot;</p><p>Box found that 5.2 can extract information from long, complex documents about 40% faster, and also saw a 40% boost in reasoning accuracy for Life Sciences and healthcare,&quot; Simo said. </p><p>She also noted that Notion reported the model &quot;outperforms 5.1 across every dimension... and it excels at the kind of really ambiguous, longer rising tasks that define real knowledge work.&quot;Schwarzer added that coding startups like Augment Code found the model &quot;delivered substantially stronger deep code capabilities than any prior model,&quot; which is why it was selected to power their new code review agent.Visual capabilities have also seen an upgrade. </p><p>OpenAI&#x27;s release blog post shows an example where &quot;a traveler reports a delayed flight, a missed connection, an overnight stay in New York, and a medical seating requirement.&quot;</p><p>The outcome? &quot;GPT‑5.2 manages the entire chain of tasks—rebooking, special-assistance seating, and compensation—delivering a more complete outcome than GPT‑5.1.&quot;</p><p>A new evaluation called ScreenSpot-Pro, which tests a model&#x27;s ability to understand GUI screenshots, shows GPT-5.2 Thinking achieving 86.3% accuracy, compared to just 64.2% for GPT-5.1.</p><h3><b>Science and Reliability</b></h3><p>OpenAI leaders also stressed the model&#x27;s utility for scientific research, attempting to move the conversation beyond simple chatbots to research assistants. </p><p>Aidan Clark, lead of the training team, shared an example of a senior immunology researcher testing the model.</p><p>&quot;They tested it by asking it to generate the most important unanswered questions about the immune system,&quot; Clark said. &quot;That immunology researcher reported that GPT-5.2 produced sharper questions and stronger explanations for why those questions... matter compared to any previous pro model.</p><p>&quot;Reliability was another key focus. Schwarzer claimed the new model &quot;hallucinates substantially less than GPT-5.1,&quot; noting that on a set of de-identified queries, &quot;responses contained errors 38% less often.&quot;</p><h3><b>The &#x27;Vibe&#x27; Shift</b></h3><p>Interestingly, OpenAI acknowledged that not every user might immediately prefer the new models. </p><p>When asked why legacy models like GPT-5.1 would remain available, Schwarzer admitted that &quot;models change a little bit every time.</p><p>&quot;Some users may find that they prefer the vibes of the previous model, even though we think the latest one is across the board generally much better,&quot; Schwarzer said. He also noted that for some enterprise customers who have &quot;really fine-tuned a prompt for a specific model,&quot; there might be &quot;small regressions,&quot; necessitating access to the older versions.</p><h3><b>Safety, &#x27;Adult Mode,&#x27; and Future Roadmap</b></h3><p>Addressing safety concerns, Simo confirmed that the company is preparing to roll out an &quot;Adult Mode&quot; in the first quarter of next year, following the implementation of a new age prediction system.</p><p>&quot;We&#x27;re in the process of improving that,&quot; Simo said regarding the age prediction technology. </p><p>&quot;We want to do that ahead of launching adult mode.&quot;Looking further ahead, industry reports suggest OpenAI is working on a more fundamental architectural shift under the codename &quot;Project Garlic,&quot; targeting a flagship release in early 2026. </p><p>While executives did not comment on specific future roadmaps during the briefing, Simo remained optimistic about the economics of their current trajectory.</p><p>&quot;If you look at historical trends, compute has increased about 3x every year for the last three years,&quot; she explained. &quot;Revenue has also increased at the same pace... creating this virtuous cycle.&quot;</p><p>Clark added that efficiency is improving rapidly: &quot;The model we&#x27;re releasing today achieves an even better score [on ARC-AGI] with almost 400 times less cost and less compute associated with it&quot; compared to models from a year ago.</p><p>GPT-5.2 Instant, Thinking, and Pro begin rolling out in ChatGPT today to paid users (Plus, Pro, Team, and Enterprise). The company notes the rollout will be gradual to maintain stability.</p>",
    "titleJa": "OpenAIのGPT-5.2発表：企業が知っておくべきこと",
    "summaryJa": "OpenAIがGPT-5.2を発表。推論、コーディング、エージェント機能が向上。3つのモデルを提供し、API価格は高め。科学研究への応用や安全性も重視。",
    "explanationJa": "OpenAIが新しいGPT-5.2を発表し、より高度な推論やコーディング能力で、ビジネスでの活用が期待されます。",
    "translationJa": "<p>噂は本当でした。OpenAIは木曜日、新しい最先端の大規模言語モデル（LLM）ファミリー、<a href=\"https://openai.com/index/introducing-gpt-5-2/\"><b>GPT-5.2</b></a>を発表しました。</p><p>これは、AIのパイオニアであるOpenAIにとって重要な時期に発表されました。競合の<a href=\"https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and\">GoogleのGemini 3 LLMが主要な第三者機関のパフォーマンスリーダーボードや多くの主要なベンチマークでトップの座を奪った</a>ため、OpenAIは激化するプレッシャーに直面していました。しかし、OpenAIのリーダーたちは記者会見で、今回のリリース時期はGemini 3のリリースよりもずっと前から議論され、準備されていたと強調しました。</p><p>OpenAIはGPT-5.2を「プロフェッショナルな知識労働にとってこれまでで最も有能なモデルシリーズ」と表現し、推論、コーディング、エージェントのワークフローにおける大幅な改善によって、パフォーマンスの王座を奪還することを目指しています。</p><p>OpenAIのアプリケーション担当CEOであるFidji Simoは、今日の記者会見で「これは当社の最も高度な最先端モデルであり、プロフェッショナルな用途において市場で最も強力なものです」と述べました。「5.2は、人々にとってさらに多くの経済的価値を引き出すように設計しました。スプレッドシートの作成、プレゼンテーションの作成、コードの記述、画像の認識、長いコンテキストの理解、ツールの使用、複雑な複数ステップのプロジェクトの処理において、より優れています。」</p><p>GPT-5.2は、400,000トークンという大規模なコンテキストウィンドウを備えており、一度に数百のドキュメントまたは大規模なコードリポジトリを取り込むことができます。また、最大128,000トークンの出力制限により、広範なレポートや完全なアプリケーションを一度に生成できます。</p><p>このモデルは、2025年8月31日の知識カットオフ日も特徴としており、比較的新しい世界の出来事や技術ドキュメントに対応していることが保証されています。また、「推論トークンのサポート」を明示的に含み、基盤となるアーキテクチャが「o1」シリーズによって普及した連鎖的思考処理を使用していることを確認しています。</p><h3><b>「コードレッド」の現実</b></h3><p>このリリースは、<i><a href=\"https://www.theinformation.com/articles/openai-ceo-declares-code-red-combat-threats-chatgpt-delays-ads-effort\">The Informationの記事</a></i>で、ChatGPTを改善するためにCEOのSam AltmanからOpenAIのスタッフに緊急の「コードレッド」指示が出されたという報道に続いて発表されました。これは、Gemini 3によって露呈した「品質のギャップ」を受けてリソースを動員するように設計された動きであると伝えられています。<i><a href=\"https://www.theverge.com/report/838857/openai-gpt-5-2-release-date-code-red-google-response\">The Verge</a></i>も同様に、公式発表に先立ってGPT-5.2のリリース時期について報道しました。</p><p>記者会見中、OpenAIの幹部は指示があったことを認めましたが、このモデルがGoogleへの対抗のためだけに急いで開発されたという見方を否定しました。</p><p>Simoは記者団に対し、「これは何ヶ月も前から取り組んできたものであることに注意することが重要です」と述べました。彼女は、「コードレッド」が会社を集中させるのに役立った一方で、それがタイムラインの唯一の推進力ではなかったことを明確にしました。</p><p>「このコードレッドを発表したのは、特定の分野にリソースを投入したいというシグナルを会社に送るためでしたが...それが特に今週リリースされる理由ではありません。」</p><p>OpenAIのポストトレーニングチームのリーダーであるMax Schwarzerは、パニックローンチという考えを払拭するために、この感情を繰り返しました。「このリリースは非常に長い間計画してきました...この特定の週については、何ヶ月も前に話し合いました。」</p><p>OpenAIの広報担当者はさらに、「コードレッド」の呼びかけは、製品としてのChatGPTに適用されるものであり、基盤となるモデルの開発や新しいモデルのリリースのみに適用されるものではないことを明確にしました。</p><h3><b>内部構造：Instant、Thinking、Pro</b></h3><p>OpenAIは、GPT-5.2のリリースをChatGPT内で3つの異なる層に分割しています。これは、「推論」モデルの大規模な計算コストと、ユーザーのスピードに対する要求とのバランスを取るように設計された戦略であると考えられます。</p><ul><li><p><b>GPT-5.2 Instant：</b>書き込み、翻訳、情報検索などの日常的なタスク向けに最適化されたスピード重視のモデルです。</p></li><li><p><b>GPT-5.2 Thinking：</b>「複雑で構造化された作業」や長期実行エージェント向けに設計されたこのモデルは、より深い推論チェーンを活用して、コーディング、数学、複数ステップのプロジェクトを処理します。</p></li><li><p><b>GPT-5.2 Pro：</b>新しいヘビー級チャンピオン。OpenAIはこれを「最もスマートで最も信頼できるオプション」と説明し、品質がレイテンシーよりも重要な難しい質問に対して最高の精度を提供します。</p></li></ul><p>開発者向けには、これらのモデルは、アプリケーションプログラミングインターフェース（API）で、<code>gpt-5.2</code>、<code>gpt-5.2-chat-latest</code>（Instant）、<code>gpt-5.2-pro</code>としてすぐに利用できます。</p><h3><b>数値：ベンチマークを上回る</b></h3><p>GPT-5.2のリリースには、ほとんどのドメインにわたる主要な指標が含まれています。特に、競合他社が最近勢いを増している「プロフェッショナルな知識労働」のギャップをターゲットとしたものです。</p><p>OpenAIは、GDPvalと呼ばれる新しいベンチマークを強調しました。これは、44の職業にわたる「明確に指定された知識労働タスク」のパフォーマンスを測定します。</p><p>Simoは、「GPT-5.2 Thinkingは現在、そのベンチマークで最先端であり...スプレッドシート、プレゼンテーション、ドキュメント作成などの明確に指定されたプロフェッショナルタスクの70.9％で、専門家の人間による判断によると、業界のトッププロフェッショナルと同等またはそれ以上のパフォーマンスを発揮します」と述べました。</p><p>コーディングの重要な分野において、OpenAIは決定的なリードを主張しています。Schwarzerは、実際のソフトウェアエンジニアリングの厳密な評価であるSWE-bench Proで、GPT-5.2 Thinkingが55.6％という新しい最先端のスコアを設定したと指摘しました。</p><p>彼は、このベンチマークが「SWE-bench Verifiedのような以前のベンチマークよりも汚染耐性があり、挑戦的で、多様で、業界に関連性がある」ことを強調しました。その他の主要なベンチマークの結果は次のとおりです。</p><ul><li><p><b>GPQA Diamond（科学）：</b>GPT-5.2 Proは93.2％のスコアを獲得し、GPT-5.2 Thinking（92.4％）をわずかに上回り、GPT-5.1 Thinking（88.1％）を上回りました。</p></li><li><p><b>FrontierMath：</b>Tier 1〜3の問題で、GPT-5.2 Thinkingは40.3％を解決し、前任者の31.0％から大幅に向上しました。</p></li><li><p><b>ARC-AGI-1：</b>GPT-5.2 Proは、この一般的な推論ベンチマークで90％のしきい値を超える最初のモデルであると報告されており、<b>90.5％</b>のスコアを獲得しています。</p></li></ul><h3><b>インテリジェンスの代償</b></h3><p>パフォーマンスにはプレミアムが付きます。ChatGPTのサブスクリプション価格は今のところ変更されていませんが、新しいフラッグシップモデルのAPIコストは、以前の世代と比較して高額であり、「思考」モードの高い計算需要を反映しています。また、業界のAPIコストの上限に位置しています。</p><ul><li><p><b>GPT-5.2 Thinking：</b>100万入力トークンあたり<b>1.75ドル</b>、100万出力トークンあたり<b>14ドル</b>で価格設定されています。</p></li><li><p><b>GPT-5.2 Pro：</b>コストは大幅に上昇し、100万入力トークンあたり<b>21ドル</b>、100万出力トークンあたり<b>168ドル</b>になります。</p></li></ul><p>GPT-5.2 Thinkingは、標準のGPT-5.1（1.25ドル/10ドル）よりもAPIで40％高い価格設定になっており、OpenAIが新しい推論機能を単なる効率の向上ではなく、具体的な付加価値と見なしていることを示しています。</p><p>ハイエンドのGPT-5.2 Proも同じパターンに従い、以前のGPT-5 Pro（15ドル/120ドル）よりも40％高いコストがかかります。高価ではありますが、それでもOpenAIの最も専門的な推論モデルであるo1-proを下回っており、100万入力トークンあたり150ドル、100万出力トークンあたり600ドルという驚異的な価格で、メニューの中で最も高価な製品となっています。</p><p>OpenAIは、トークンあたりのコストは高いものの、モデルの「トークン効率の向上」と、より少ないターンでタスクを解決できる能力により、価値の高いエンタープライズワークフローにとって経済的に実行可能であると主張しています。</p><p>以下は、LLM分野の他の競合モデルの現在のAPIコストとの比較です。</p><table><tbody><tr><td><p><b>モデル</b></p></td><td><p><b>入力（/1M）</b></p></td><td><p><b>出力（/1M）</b></p></td><td><p><b>合計コスト</b></p></td><td><p><b>ソース</b></p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p>$0.25</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast（推論）</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast（非推論）</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p>$0.70</p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p>$0.70</p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Qwen 3 Plus</p></td><td><p>$0.40</p></td><td><p>$1.20</p></td><td><p>$1.60</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p>$4.25</p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p>$6.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen-Max</p></td><td><p>$1.60</p></td><td><p>$6.40</p></td><td><p>$8.00</p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p>$14.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p><b>GPT-5.2</b></p></td><td><p><b>$1.75</b></p></td><td><p><b>$14.00</b></p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p>$22.00</p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p>$18.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Claude Opus 4.5</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p>$30.00</p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p><b>GPT-5.2 Pro</b></p></td><td><p><b>$21.00</b></p></td><td><p><b>$168.00</b></p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\"><b>OpenAI</b></a></p></td></tr></tbody></table><h3><b>画像生成：まだ新しいものはありません...しかし「今後さらに多くのことが起こる」</b></h3><p>記者会見中、VentureBeatはOpenAIの参加者に、今回のリリースにGoogleのGemini 3 Image aka Nano Banana Proのような最近の競合他社の発表における同様の機能に対する興奮に触れ、画像生成機能の向上が含まれているかどうかを尋ねました。</p><p>テキストと情報が豊富なグラフィックスや画像編集機能を再現しようとしている人にとっては残念ながら、OpenAIの幹部は、GPT-5.2には、以前のGPT-5.1およびOpenAIの統合されたDALL-E 3とgpt-4oネイティブ画像生成モデルと比較して、現在の画像改善はないことを明らかにしました。</p><p>Simoは、「画像生成に関しては、今日発表することはありませんが、今後さらに多くのことが起こります」と述べました。彼女は、この機能の人気を認め、「これは人々が愛する非常に重要なユースケースであり、私たちが市場に導入したものであり、間違いなく今後さらに多くのことが起こります。」と付け加えました。</p><p>OpenAIのトレーニングのリーダーであるAidan Clarkも、視覚的生成の具体的な内容についてはコメントを控え、「私自身は画像生成についてあまり話すことができません。」と述べました。</p><h3><b>「メガエージェント」時代</b></h3><p>OpenAIは、生のスコアを超えて、GPT-5.2を人間の手を介さずに複数ステップのワークフローを実行できる新世代の「長期実行エージェント」のエンジンとして位置付けています。</p><p>Boxは、5.2が長くて複雑なドキュメントから情報を約40％速く抽出できることを発見し、ライフサイエンスおよびヘルスケアの推論精度も40％向上しました。」とSimoは述べています。</p><p>彼女はまた、Notionがモデルは「あらゆる面で5.1よりも優れており...実際の知識労働を定義するような、本当に曖昧でより長い上昇タスクに優れています」と報告したと指摘しました。Schwarzerは、Augment Codeのようなコーディングスタートアップが、モデルは「以前のどのモデルよりも実質的に強力なディープコード機能を提供した」ため、新しいコードレビューエージェントを強化するために選択されたことを発見したと付け加えました。視覚機能もアップグレードされました。</p><p>OpenAIのリリースブログ投稿では、「旅行者が遅延したフライト、乗り継ぎの失敗、ニューヨークでの一泊、および医療上の座席要件を報告する」例を示しています。</p><p>結果は？「GPT‑5.2は、再予約、特別支援座席、および補償というタスクチェーン全体を管理し、GPT‑5.1よりも完全な結果を提供します。」</p><p>モデルのGUIスクリーンショットを理解する能力をテストする新しい評価であるScreenSpot-Proでは、GPT-5.2 Thinkingが86.3％の精度を達成しましたが、GPT-5.1ではわずか64.2％でした。</p><h3><b>科学と信頼性</b></h3><p>OpenAIのリーダーはまた、科学研究におけるモデルの有用性を強調し、単純なチャットボットから研究助手への会話を移行しようと試みました。</p><p>トレーニングチームのリーダーであるAidan Clarkは、モデルをテストしている免疫学の上級研究者の例を共有しました。</p><p>Clarkは、「彼らは、免疫系に関する最も重要な未解決の質問を生成するように依頼することでそれをテストしました。」と述べています。「その免疫学の研究者は、GPT-5.2が、以前のどのプロモデルと比較しても、より鋭い質問と、それらの質問が重要な理由のより強力な説明を生み出したと報告しました。</p><p>「信頼性ももう1つの重要な焦点でした。Schwarzerは、新しいモデルは「GPT-5.1よりも実質的に幻覚が少ない」と主張し、匿名化されたクエリのセットで、「応答にエラーが含まれる頻度が38％少なくなった」と指摘しました。</p><h3><b>「雰囲気」の変化</b></h3><p>興味深いことに、OpenAIは、すべてのユーザーがすぐに新しいモデルを好むとは限らないことを認めました。</p><p>GPT-5.1のようなレガシーモデルが利用可能なままである理由を尋ねられたSchwarzerは、「モデルは毎回少しずつ変化します」と認めました。</p><p>「一部のユーザーは、最新のモデルが全体的にはるかに優れていると考えていても、以前のモデルの雰囲気を好むかもしれません」とSchwarzerは述べています。彼はまた、「特定のモデルに対してプロンプトを細かく調整した」一部のエンタープライズ顧客にとっては、「小さなリグレッション」がある可能性があり、古いバージョンへのアクセスが必要になる可能性があると指摘しました。</p><h3><b>安全性、「アダルトモード」、および今後のロードマップ</b></h3><p>安全性の懸念に対処するため、Simoは、新しい年齢予測システムの実装後、来年の第1四半期に「アダルトモード」を展開する準備をしていることを確認しました。</p><p>Simoは、年齢予測技術について「それを改善する過程にあります」と述べています。</p><p>「アダルトモードを開始する前にそれを行いたいと考えています。」将来を見据えて、業界レポートは、OpenAIが「プロジェクトガーリック」というコードネームで、2026年初頭のフラッグシップリリースを目標に、より根本的なアーキテクチャの移行に取り組んでいることを示唆しています。</p><p>幹部は記者会見中に特定の今後のロードマップについてはコメントしませんでしたが、Simoは現在の軌道の経済性について楽観的なままでした。</p><p>彼女は、「過去の傾向を見ると、計算量は過去3年間で毎年約3倍に増加しています」と説明しました。「収益も同じペースで増加しており...この好循環を生み出しています。」</p><p>Clarkは、効率が急速に向上していると付け加えました。「今日リリースするモデルは、1年前のモデルと比較して、ほぼ400分の1のコストと計算量で、[ARC-AGI]でさらに優れたスコアを達成しています。」</p><p>GPT-5.2 Instant、Thinking、およびProは、今日からChatGPTで有料ユーザー（Plus、Pro、Team、およびEnterprise）にロールアウトを開始します。同社は、安定性を維持するために、ロールアウトは段階的に行われることに注意しています。</p>",
    "insightJa": "GPT-5.2の登場は、企業の業務効率化だけでなく、私たちの働き方や学習方法にも変化をもたらす可能性があります。AIがより身近になり、高度なタスクをこなせるようになることで、創造的な仕事に集中できるようになるでしょう。",
    "recommendedBooks": [
      "GPT-5.2 企業活用",
      "大規模言語モデル ビジネス",
      "OpenAI 最新情報"
    ],
    "tags": [
      "GPT-5.2",
      "OpenAI",
      "LLM",
      "AI",
      "Large Language Model"
    ],
    "imageUrl": "https://picsum.photos/seed/1742/400/300"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "title": "Stressed rats keep returning to cannabis and scientists know why",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251211100615.htm",
    "summary": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "publishedAt": "Thu, 11 Dec 2025 12:15:09 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Rats with naturally high stress levels were far more likely to self-administer cannabis when given access. Behavioral testing showed that baseline stress hormones were the strongest predictor of cannabis-seeking behavior. Lower cognitive flexibility and low endocannabinoid levels also contributed to increased use. The results hint at possible early indicators of vulnerability to drug misuse.",
    "titleJa": "ストレスを感じやすいラットは、なぜ大麻に戻ってしまうのか？科学者がその理由を解明",
    "summaryJa": "ストレスレベルが高いラットは、大麻を自発的に摂取しやすい。行動実験で、ストレスホルモンが最も強い予測因子と判明。認知の柔軟性低下やエンドカンナビノイドの低レベルも影響。薬物乱用の脆弱性を示す可能性。",
    "explanationJa": "ストレスを感じやすいラットは大麻を求める傾向があり、その原因が科学的に解明されつつあるようです。",
    "translationJa": "生まれつきストレスレベルが高いラットは、自由にアクセスできる状況下で、大麻を自発的に摂取する可能性がはるかに高いことがわかりました。行動実験の結果、ベースラインのストレスホルモンが、大麻を求める行動の最も強力な予測因子であることが示されました。認知の柔軟性の低下とエンドカンナビノイドの低レベルも、使用量の増加に寄与していました。この結果は、薬物乱用に対する脆弱性の早期指標の可能性を示唆しています。",
    "insightJa": "この研究は大麻依存症のリスクを早期に特定する手がかりとなるかもしれません。ストレスマネジメントや認知機能の改善が、薬物乱用の予防に繋がる可能性を示唆しています。",
    "recommendedBooks": [
      "ストレス 科学",
      "大麻依存症",
      "脳科学 ストレス"
    ],
    "tags": [
      "Cannabis",
      "Stress",
      "Rats",
      "Endocannabinoid",
      "Addiction",
      "大麻",
      "ストレス",
      "依存症"
    ],
    "imageUrl": "https://picsum.photos/seed/5060/400/300"
  },
  {
    "id": "7nAN91YGj5oC8TMc2YBtjK",
    "title": "Marble enters the race to bring AI to tax work, armed with $9 million and a free research tool",
    "source": "rss",
    "url": "https://venturebeat.com/ai/marble-enters-the-race-to-bring-ai-to-tax-work-armed-with-usd9-million-and-a",
    "summary": "Marble, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.\nThe round, led by Susa Ventures with participation from MXV Capital and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.\n\"When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,\" said Bhavin Shah, Marble's chief executive officer, in an exclusive interview with VentureBeat. \"Accounting generates $250 billion in fee-based billing in the US every year. There's a tremendous opportunity to increase efficiency and improve margins for accounting firms.\"\nThe company has launched a free AI-powered tax research tool on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.\nMarble's backers share Shah's conviction about the market. \"Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,\" Chad Byers, general partner at Susa Ventures, told VentureBeat. \"We've known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.\"\nThe accounting industry lost 340,000 workers in four years — and replacements aren't coming\nMarble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.\nThe accounting profession has shed roughly 340,000 workers since 2019, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to AICPA data, and 2022 saw the lowest number of exam takers in 17 years.\nThe exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately 75% of all licensed CPAs reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.\n“Fewer CPAs are getting certified year over year,\" Shah said. \"The industry is compressing at the same time that there's more work to be done and the tax code is getting more complicated.\"\nThe National Pipeline Advisory Group, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the 150-hour education requirement for CPA licensure as a significant barrier to entry. A separate survey by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.\nRecent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.\nWhy AI transformed law and software development but left accounting behind\nDespite the profession's challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. Harvey and Legora have raised hundreds of millions to bring AI to legal work. Cursor and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.\nGeordie Konrad, Marble's executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI's capabilities.\n“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,\" Konrad said. \" That requires a bit more of a two-step analysis to see why it's a big opportunity.\"\nThe technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.\n\"If you want to put AI through its paces and ask how far it's come in replicating cognitive functions, this is an unbelievable playground to work in,\" Konrad said.\nA dramatic shift: AI adoption among tax and finance teams doubles in one year\nRecent data suggests the accounting profession's stance toward AI is shifting rapidly.\nA 2025 survey from Hanover Research and Avalara found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from Thomson Reuters Institute found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.\nLarge accounting firms have invested heavily in AI infrastructure. Deloitte has developed generative AI capabilities within its audit platform. BDO announced a $1B investment in AI over the next five years. EY launched an AI platform combining technology with strategy, transactions, and tax services. PwC estimates a complete AI-driven audit solution will launch by 2026.\nBut adoption at smaller firms remains uneven. According to Thomson Reuters research, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.\nMarble's founders believe the hesitance stems not from technophobia but from a lack of compelling options.\n“Firms want to embrace AI,\" Shah said. “They just haven't seen great software and tooling made for them. That's part of the opportunity — to work with them and build something they're excited to use on a day-to-day basis.”\nCan artificial intelligence rescue accounting's billable-hour business model?\nAI's arrival in accounting raises questions about the profession's billing structure.\nAccounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?\nMarble's founders argue the opposite. The chronic staffing shortage has already constrained firms' ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.\n\"Everyone in the industry agrees that an enormous amount of advisory work simply isn't getting done,\" Konrad said. \"Customers want it. Firms want to do it because it's high-margin, great work. But nobody gets to it.\"\nThe 2025 AICPA National Management of an Accounting Practice Survey supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.\nThe survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.\nAccountants won't adopt AI tools they can't trust with sensitive client data\nFor AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.\nAccording to Avalara's survey, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.\nMarble has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.\n\"Security is at the core of what we are building,\" Shah said. \"Every employee knows that security is critical. It's a part of our onboarding and something that we consider in everything we do.\"\nFrom number crunchers to strategic advisors: How AI could reshape accounting careers\nMarble's founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. \nThey draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.\n\"If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you're a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that's just a lot more fun to operate in,\" Konrad said.\nThe shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.\n\"Not only does the work become more enjoyable because of what you can focus on, but that's also what your clients are going to value more from you,\" Shah said.\nThe competitive landscape: Marble faces well-funded rivals and legacy giants\nMarble enters a market with formidable incumbents and well-funded competitors. BlueJ, a global tax research platform, has raised over $100 million. Thomson Reuters, CCH, and Intuit have deep customer relationships built over decades.\nBut the founders see opportunity in the transition moment.\n\"AI has changed what’s possible in the industry,\" Shah said. \"We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?\"\"\nThe decision to offer a free research tool reflects Marble's go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.\n\"It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don't know how to integrate it into their workflow,\" Shah said.\nThe $250 billion question: Can a startup transform how America does its taxes?\nMarble's roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.\nThe founders frame success not in terms of disruption but rebalancing. Today's tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble's bet is that AI can flip that equation.\n\"Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,\" Konrad said. \"How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?\"\nWhether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.\nBut the founders are betting that the industry's demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.\n\"AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,\" Shah said.\nThe accounting profession, it seems, is about to find out which side of that equation it lands on.",
    "publishedAt": "Thu, 11 Dec 2025 14:00:00 GMT",
    "author": "michael.nunez@venturebeat.com (Michael Nuñez)",
    "category": "AI",
    "originalContent": "<p><a href=\"http://marble.ai/\">Marble</a>, a startup building artificial intelligence agents for tax professionals, has raised $9 million in seed funding as the accounting industry grapples with a deepening labor shortage and mounting regulatory complexity.</p><p>The round, led by <a href=\"https://www.susaventures.com/\">Susa Ventures</a> with participation from <a href=\"https://mxv.vc/\">MXV Capital</a> and Konrad Capital, positions Marble to compete in a market where AI adoption has lagged significantly behind other knowledge industries like law and software development.</p><p>&quot;When we looked at the economy and asked ourselves where AI is going to transform the way businesses operate, we focused on knowledge industries — specifically businesses with hourly fee-based service models,&quot; said Bhavin Shah, Marble&#x27;s chief executive officer, in an exclusive interview with VentureBeat. &quot;Accounting generates $250 billion in fee-based billing in the US every year. There&#x27;s a tremendous opportunity to increase efficiency and improve margins for accounting firms.&quot;</p><p>The company has launched a <a href=\"https://marble.ai/\">free AI-powered tax research tool</a> on its website that converts complex government tax data into accessible, citation-backed answers for practitioners. Marble plans to expand into AI agents that can analyze compliance scenarios and eventually automate portions of tax preparation workflows.</p><p>Marble&#x27;s backers share Shah&#x27;s conviction about the market. &quot;Marble is rethinking the accounting system from the ground up. Accounting is one of the biggest — and most overlooked — markets in professional services,&quot; Chad Byers, general partner at Susa Ventures, told VentureBeat. &quot;We&#x27;ve known Bhavin from his time as an executive in the Susa portfolio, and have seen firsthand how sharp and execution-driven he is. He and Geordie bring the perfect mix of operational depth and product instinct to a space long overdue for change — and they see the same massive opportunity we do.&quot;</p><h2><b>The accounting industry lost 340,000 workers in four years — and replacements aren&#x27;t coming</b></h2><p>Marble enters a market shaped by structural forces that have fundamentally altered the economics of professional accounting.</p><p>The accounting profession has <a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">shed roughly 340,000 workers since 2019</a>, a 17% decline that has left firms scrambling to meet client demands. First-time candidates for the Certified Public Accountant exam dropped 33% between 2016 and 2021, according to <a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPA data</a>, and 2022 saw the lowest number of exam takers in 17 years.</p><p>The exodus comes as baby boomers exit en masse. The American Institute of CPAs estimates that approximately <a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">75% of all licensed CPAs</a> reached retirement age by 2019, creating a demographic cliff that the profession has struggled to address.</p><p>“Fewer CPAs are getting certified year over year,&quot; Shah said. &quot;The industry is compressing at the same time that there&#x27;s more work to be done and the tax code is getting more complicated.&quot;</p><p>The <a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>, a multi-stakeholder body formed by the AICPA in July 2023, released a report identifying the <a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150-hour education requirement</a> for CPA licensure as a significant barrier to entry. A separate <a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">survey</a> by the Center for Audit Quality found that 57% of business majors who chose not to pursue accounting cited the additional credit hours as a deterrent.</p><p>Recent legislative changes reflect the urgency. Ohio now offers alternatives to the 150-hour requirement, signaling that states are willing to experiment with pathways that could reverse enrollment declines.</p><h2><b>Why AI transformed law and software development but left accounting behind</b></h2><p>Despite the profession&#x27;s challenges, AI adoption in accounting has moved more slowly than in adjacent knowledge industries. <a href=\"https://www.harvey.ai/\">Harvey</a> and <a href=\"https://legora.com/\">Legora</a> have raised hundreds of millions to bring AI to legal work. <a href=\"https://cursor.com/agents\">Cursor</a> and other coding assistants have transformed software development. Accounting, by contrast, remains largely dependent on legacy research platforms and manual processes.</p><p>Geordie Konrad, Marble&#x27;s executive chairman and a co-founder of restaurant software company TouchBistro, attributes the gap to how people conceptualize AI&#x27;s capabilities.</p><p>“It was obvious to many people that LLMs could do meaningful work by manipulating code for software developers and manipulating words for lawyers. In the accounting industry, LLMs are going to be used as reasoning agents,&quot; Konrad said. &quot; That requires a bit more of a two-step analysis to see why it&#x27;s a big opportunity.&quot;</p><p>The technical challenge is substantial. Tax regulations form one of the most complex, interconnected information systems that humans have created — tens of thousands of interlocking rules, guidance documents, and jurisdiction-specific requirements that frequently overlap or conflict.</p><p>&quot;If you want to put AI through its paces and ask how far it&#x27;s come in replicating cognitive functions, this is an unbelievable playground to work in,&quot; Konrad said.</p><h2><b>A dramatic shift: AI adoption among tax and finance teams doubles in one year</b></h2><p>Recent data suggests the accounting profession&#x27;s stance toward AI is shifting rapidly.</p><p>A 2025 survey from <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a> found that 84% of finance and tax teams now use AI heavily in their operations, up from 47% in 2024. The 2025 Generative AI in Professional Services Report from <a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a> found that 21% of tax firms already use generative AI technology, with 53% either planning to adopt it or actively considering it.</p><p>Large accounting firms have invested heavily in AI infrastructure. <a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a> has developed generative AI capabilities within its audit platform. <a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a> announced a $1B investment in AI over the next five years. <a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a> launched an AI platform combining technology with strategy, transactions, and tax services. <a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a> estimates a complete AI-driven audit solution will launch by 2026.</p><p>But adoption at smaller firms remains uneven. According to <a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reuters research</a>, 52% of tax firm respondents who use generative AI rely on open-source tools like ChatGPT rather than industry-specific solutions—a pattern that could shift as purpose-built alternatives emerge.</p><p>Marble&#x27;s founders believe the hesitance stems not from technophobia but from a lack of compelling options.</p><p>“Firms want to embrace AI,&quot; Shah said. “They just haven&#x27;t seen great software and tooling made for them. That&#x27;s part of the opportunity — to work with them and build something they&#x27;re excited to use on a day-to-day basis.”</p><h2><b>Can artificial intelligence rescue accounting&#x27;s billable-hour business model?</b></h2><p>AI&#x27;s arrival in accounting raises questions about the profession&#x27;s billing structure.</p><p>Accounting firms have traditionally generated profits by billing clients for staff time, often at multiples of employee compensation costs. Junior associates performing compliance work represent a significant revenue stream. If AI can automate that work, does it undercut the business model firms depend on?</p><p>Marble&#x27;s founders argue the opposite. The chronic staffing shortage has already constrained firms&#x27; ability to capture available revenue. Advisory and consulting work — higher-margin services that clients actively want — goes undone because practitioners are buried in compliance tasks.</p><p>&quot;Everyone in the industry agrees that an enormous amount of advisory work simply isn&#x27;t getting done,&quot; Konrad said. &quot;Customers want it. Firms want to do it because it&#x27;s high-margin, great work. But nobody gets to it.&quot;</p><p>The <a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025 AICPA National Management of an Accounting Practice Survey</a> supports this view. Firms reported a median 6.7% increase in net client fees over the prior year, with growth in audit, assurance, tax services, and client accounting advisory. Net remaining per partner climbed 11.9% from fiscal year 2022 to fiscal year 2024, reaching $252,663.</p><p>The survey also found growing interest in AI adoption, though most firms have yet to allocate formal budgets or develop structured training programs. Continued adoption, the survey suggested, could help expand services and fuel continued growth.</p><h2><b>Accountants won&#x27;t adopt AI tools they can&#x27;t trust with sensitive client data</b></h2><p>For AI to succeed in accounting, it must clear a high bar for data security. Accounting firms handle some of the most sensitive financial information in the economy. Practitioners cannot adopt tools that create compliance or confidentiality risks.</p><p>According to <a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalara&#x27;s survey</a>, 63% of respondents cited data security and privacy concerns as the top barriers to automating tax and finance functions. The concern persists throughout the adoption lifecycle, from initial selection through implementation and ongoing use.</p><p><a href=\"https://marble.ai/\">Marble</a> has made security a foundational priority. The company obtained software compliance certification before releasing any product and maintains that data privacy is embedded in its operational culture from day one.</p><p>&quot;Security is at the core of what we are building,&quot; Shah said. &quot;Every employee knows that security is critical. It&#x27;s a part of our onboarding and something that we consider in everything we do.&quot;</p><h2><b>From number crunchers to strategic advisors: How AI could reshape accounting careers</b></h2><p>Marble&#x27;s founders reject the narrative that AI will only take away from accounting jobs. They propose instead that AI will result in accounting jobs becoming more strategic and less characterized by repetitive execution. </p><p>They draw an analogy to architecture, where computer-aided design replaced laborious manual drafting. Architects did not disappear — they gained tools that let them spend more time on creative design and less on mechanical reproduction.</p><p>&quot;If you take some of the hours-intensive, less creative work out of what being a junior or intermediate accountant is, and you replace it with a role where you&#x27;re a professional who is being creative, synthesizing ideas, and able to delegate a lot of tasks to AI assistant platform solutions, you end up with an industry that&#x27;s just a lot more fun to operate in,&quot; Konrad said.</p><p>The shift could also improve client outcomes. When accountants spend less time on compliance, they can invest more in the strategic advisory work that clients value.</p><p>&quot;Not only does the work become more enjoyable because of what you can focus on, but that&#x27;s also what your clients are going to value more from you,&quot; Shah said.</p><h2><b>The competitive landscape: Marble faces well-funded rivals and legacy giants</b></h2><p><b></b><a href=\"http://marble.ai/\">Marble</a> enters a market with formidable incumbents and well-funded competitors. <a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>, a global tax research platform, has raised over $100 million. <a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>, <a href=\"https://www.cch.com/\">CCH</a>, and <a href=\"https://www.intuit.com/\">Intuit</a> have deep customer relationships built over decades.</p><p>But the founders see opportunity in the transition moment.</p><p>&quot;AI has changed what’s possible in the industry,&quot; Shah said. &quot;We are going to work with and integrate with some technology players in the industry and also compete with other players with new products powered by AI. In some cases we are going to forget about the existing technology solution for doing things and go back to the task itself. We have totally new technological capabilities — how would you design something from a blank canvas that works with humans to accomplish that task?&quot;&quot;</p><p>The decision to offer a free research tool reflects Marble&#x27;s go-to-market philosophy. By giving practitioners access without a paywall, the company aims to build trust and demonstrate capability.</p><p>&quot;It allows us to expose a really compelling product that is purpose-built to those that are worried about how to use AI or question how to adopt it.  Now they don’t have to think about purchasing something that is cost-prohibitive when they don&#x27;t know how to integrate it into their workflow,&quot; Shah said.</p><h2><b>The $250 billion question: Can a startup transform how America does its taxes?</b></h2><p>Marble&#x27;s roadmap extends beyond research. The company plans to develop AI agents capable of analyzing complex tax scenarios, identifying compliance issues, and eventually automating significant portions of compliance workflows — all while keeping practitioners in control.</p><p>The founders frame success not in terms of disruption but rebalancing. Today&#x27;s tax work skews heavily toward compliance, leaving the strategic advisory services that clients crave — and that generate higher margins—perpetually undone. Marble&#x27;s bet is that AI can flip that equation.</p><p>&quot;Everyone wants it to look more like compliance is done simpler, and you spend time talking about strategy and planning,&quot; Konrad said. &quot;How do we change that blend of compliance versus strategy and planning to strategy and planning first—with compliance as something that has been made dramatically simpler?&quot;</p><p>Whether Marble can execute on that vision remains to be seen. The company faces entrenched competitors, a profession that has historically resisted technological change, and the inherent unpredictability of building AI systems for high-stakes financial work.</p><p>But the founders are betting that the industry&#x27;s demographic shift will accelerate adoption in ways that previous technology waves could not. With fewer accountants entering the profession each year and client demands only growing, firms may have an increased appetite to embrace tools that let their remaining staff do more.</p><p>&quot;AI is going to change every industry — in some cases in ways that will help business models and in some cases in ways that will challenge them. We believe AI is ultimately going to make accounting firms’ businesses better and more profitable and at the same time end clients will get better services at better prices,&quot; Shah said.</p><p>The accounting profession, it seems, is about to find out which side of that equation it lands on.</p>",
    "titleJa": "Marble、税務業務へのAI導入競争に参入、900万ドルの資金と無料の研究ツールを武器に",
    "summaryJa": "税務専門家向けAIエージェントを開発するMarble社が900万ドルの資金を調達。AI税務研究ツールを公開し、コンプライアンス分析や自動化を目指す。",
    "explanationJa": "Marble社はAIを使って税務業務を効率化しようとしており、税理士さんの仕事をサポートする可能性があります。",
    "translationJa": "<p><a href=\"http://marble.ai/\">Marble</a>は、税務専門家向けの人工知能エージェントを構築しているスタートアップで、会計業界が深刻な労働力不足と増大する規制の複雑さに苦しむ中、900万ドルのシード資金を調達しました。</p><p>Susa Venturesが主導し、MXV CapitalとKonrad Capitalが参加した今回のラウンドにより、Marbleは、AIの導入が法律やソフトウェア開発などの他の知識産業に比べて大幅に遅れている市場で競争する立場となりました。</p><p>Marbleの最高経営責任者（CEO）であるBhavin Shahは、VentureBeatとの独占インタビューで、「経済を検討し、AIがビジネスの運営方法をどのように変革するかを自問したとき、私たちは知識産業、特に時間料金制のサービスモデルを持つビジネスに焦点を当てました」と述べています。「会計は米国で毎年2500億ドルの料金ベースの請求を生み出しています。会計事務所の効率を高め、利益率を向上させる絶好の機会があります。」</p><p>同社は、ウェブサイト上で<a href=\"https://marble.ai/\">無料のAIを活用した税務調査ツール</a>を公開しました。これは、複雑な政府の税務データを、専門家がアクセスしやすい引用付きの回答に変換するものです。Marbleは、コンプライアンスシナリオを分析し、最終的には税務申告ワークフローの一部を自動化できるAIエージェントに拡張する予定です。</p><p>Marbleの出資者は、Shahの市場に対する確信を共有しています。Susa VenturesのジェネラルパートナーであるChad ByersはVentureBeatに対し、「Marbleは会計システムを根本から再考しています。会計は、専門サービスの中で最大であり、最も見過ごされている市場の1つです」と述べています。「私たちはBhavinがSusaのポートフォリオのエグゼクティブであった時代から彼を知っており、彼がいかに鋭敏で実行力があるかを直接見てきました。彼とGeordieは、長らく変化が遅れている分野に、運営の深さと製品に対する直感の完璧な組み合わせをもたらしています。そして、彼らは私たちと同じように巨大な機会を見ているのです。」</p><h2><b>会計業界は4年間で34万人の労働者を失い、補充はされていない</b></h2><p>Marbleは、専門会計の経済を根本的に変えた構造的な力によって形成された市場に参入します。</p><p>会計業界は<a href=\"https://www.bls.gov/ooh/office-and-administrative-support/bookkeeping-accounting-and-auditing-clerks.htm\">2019年以降、約34万人の労働者を削減しました</a>。これは17％の減少であり、企業はクライアントの要求に応えるのに苦労しています。公認会計士試験の初回受験者は、<a href=\"https://www.cpajournal.com/2025/08/15/the-accounting-profession-is-in-crisis-3/\">AICPAのデータ</a>によると、2016年から2021年の間に33％減少し、2022年には17年間で最も少ない受験者数となりました。</p><p>この流出は、ベビーブーマー世代の一斉退職と重なっています。米国公認会計士協会は、<a href=\"https://www.forbes.com/councils/forbesfinancecouncil/2025/05/12/disruption-in-accounting-the-cpa-shortage-meets-the-rise-of-ai/\">すべての公認会計士の約75％</a>が2019年までに定年年齢に達し、業界が対処に苦労している人口動態的な崖が生じていると推定しています。</p><p>「公認会計士の資格を取得する人は年々少なくなっています」とShahは述べています。「業界は縮小していると同時に、やるべき仕事が増え、税法がより複雑になっています。」</p><p>AICPAが2023年7月に設立したマルチステークホルダー機関である<a href=\"https://www.accountingpipeline.org/\">National Pipeline Advisory Group</a>は、CPA資格取得のための<a href=\"https://sc.cpa/2025/01/10/national-pipeline-advisory-group-npag-releases-official-report/\">150時間の教育要件</a>が参入の大きな障壁となっていることを特定した報告書を発表しました。Center for Audit Qualityによる別の<a href=\"https://www.thecaq.org/increasing-diversity-in-the-accounting-profession-pipeline-2022\">調査</a>では、会計を追求しないことを選択したビジネス専攻の57％が、追加の単位時間を抑止力として挙げています。</p><p>最近の法改正は、その緊急性を反映しています。オハイオ州は現在、150時間の要件に代わる代替手段を提供しており、州が登録者数の減少を逆転させる可能性のある経路を試す意欲があることを示しています。</p><h2><b>なぜAIは法律とソフトウェア開発を変革したが、会計を置き去りにしたのか</b></h2><p>業界の課題にもかかわらず、会計におけるAIの導入は、隣接する知識産業よりもゆっくりと進んでいます。<a href=\"https://www.harvey.ai/\">Harvey</a>と<a href=\"https://legora.com/\">Legora</a>は、AIを法律業務に導入するために数億ドルを調達しました。<a href=\"https://cursor.com/agents\">Cursor</a>やその他のコーディングアシスタントは、ソフトウェア開発を変革しました。対照的に、会計は依然として従来の調査プラットフォームと手作業に大きく依存しています。</p><p>Marbleのエグゼクティブチェアマンであり、レストランソフトウェア会社TouchBistroの共同創業者であるGeordie Konradは、このギャップを、人々がAIの能力をどのように概念化しているかに関連付けています。</p><p>「LLMがソフトウェア開発者向けのコードを操作したり、弁護士向けの言葉を操作したりすることで意味のある仕事ができることは、多くの人々にとって明らかでした。会計業界では、LLMは推論エージェントとして使用されるでしょう」とKonradは述べています。「それが大きな機会である理由を理解するには、もう少し2段階の分析が必要です。」</p><p>技術的な課題は相当なものです。税法は、人間が作成した最も複雑で相互接続された情報システムの1つを構成しています。それは、頻繁に重複または矛盾する、数万もの相互接続されたルール、ガイダンス文書、および管轄区域固有の要件です。</p><p>「AIを試して、認知機能を複製する上でどこまで進んでいるかを尋ねたい場合、これは信じられないほどの遊び場です」とKonradは述べています。</p><h2><b>劇的な変化：税務および財務チームにおけるAIの導入が1年間で倍増</b></h2><p>最近のデータは、会計業界のAIに対する姿勢が急速に変化していることを示唆しています。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Hanover Research and Avalara</a>による2025年の調査では、現在、財務および税務チームの84％が業務でAIを多用していることがわかりました。これは2024年の47％から増加しています。<a href=\"https://www.cpapracticeadvisor.com/2025/04/15/79-of-tax-and-accounting-firms-expect-significant-genai-integration-by-2027/159172/\">Thomson Reuters Institute</a>による2025年のプロフェッショナルサービスにおける生成AIに関するレポートでは、税務事務所の21％がすでに生成AIテクノロジーを使用しており、53％が採用を計画しているか、積極的に検討していることがわかりました。</p><p>大手会計事務所はAIインフラストラクチャに多額の投資を行っています。<a href=\"https://www.deloitte.com/us/en/what-we-do/capabilities/applied-artificial-intelligence/articles/agentic-ai-enterprise-2028.html?id=us:2ps:3gl:aisgm26:awa:CONS:nonem:K0218784:111725:kwd-2025710122928:188372336109:784136672833::Brand_AI-SGO_BU_K0218784_Google:Brand_AI-SGO-Advisory:deloitte-generative-ai:&amp;gclsrc=aw.ds&amp;gad_source=1&amp;gad_campaignid=23269751515&amp;gbraid=0AAAAADenGPA6ZvC8cLRrT031O1up6RiOj&amp;gclid=Cj0KCQiAi9rJBhCYARIsALyPDtudMaZrpHm8026n16yuyeM0sYKCTm24yHqR4Dyg_s6yZBgPnxfjDOwaAvN5EALw_wcB\">Deloitte</a>は、監査プラットフォーム内で生成AI機能を開発しました。<a href=\"https://www.bdo.com/insights/press-releases/bdo-usa-unveils-comprehensive-artificial-intelligence-strategy-fusing-practical-innovation\">BDO</a>は、今後5年間でAIに10億ドルを投資すると発表しました。<a href=\"https://www.ey.com/en_gl/newsroom/2025/11/ey-unveils-suite-of-powerful-ai-capabilities-to-accelerate-tax-transformation-and-deliver-strategic-value\">EY</a>は、テクノロジーと戦略、トランザクション、税務サービスを組み合わせたAIプラットフォームを立ち上げました。<a href=\"https://www.pwc.com/us/en/tech-effect/ai-analytics/ai-predictions.html\">PwC</a>は、完全なAI駆動型監査ソリューションが2026年までに開始されると予測しています。</p><p>しかし、中小企業での採用は依然として不均一です。<a href=\"http://thomsonreuters.com/en-us/posts/technology/genai-professional-services-report-2025/\">Thomson Reutersの調査</a>によると、生成AIを使用している税務事務所の回答者の52％が、業界固有のソリューションではなく、ChatGPTのようなオープンソースツールに依存しています。このパターンは、目的に合った代替手段が登場するにつれて変化する可能性があります。</p><p>Marbleの創設者は、ためらいは技術恐怖症からではなく、説得力のある選択肢の欠如から生じていると考えています。</p><p>「企業はAIを取り入れたいと思っています」とShahは述べています。「彼らはただ、自分たち向けに作られた優れたソフトウェアやツールを見ていないだけです。それが機会の一部であり、彼らと協力して、日々使うのが楽しみなものを構築することです。」</p><h2><b>人工知能は会計の請求時間ビジネスモデルを救うことができるか？</b></h2><p>AIの会計への参入は、業界の請求構造に関する疑問を提起します。</p><p>会計事務所は伝統的に、従業員の給与コストの数倍で、スタッフの時間に対してクライアントに請求することで利益を上げてきました。コンプライアンス作業を行うジュニアアソシエイトは、重要な収入源となります。AIがその作業を自動化できる場合、それは企業が依存するビジネスモデルを弱体化させるのでしょうか？</p><p>Marbleの創設者は、その逆だと主張しています。慢性的な人員不足により、企業は利用可能な収入を獲得する能力がすでに制限されています。クライアントが積極的に求めているアドバイザリーおよびコンサルティング業務（利益率の高いサービス）は、実務者がコンプライアンス業務に埋もれているために行われていません。</p><p>「業界の誰もが、莫大な量のアドバイザリー業務が単に行われていないことに同意しています」とKonradは述べています。「顧客はそれを望んでいます。企業は利益率が高く、優れた仕事なので、それをやりたいと思っています。しかし、誰もそれにたどり着きません。」</p><p><a href=\"https://www.aicpa-cima.com/news/article/cpa-firms-report-steady-growth-in-revenue-and-profit-aicpa-research-finds\">2025年のAICPA National Management of an Accounting Practice Survey</a>は、この見解を支持しています。企業は、前年比でクライアントからの純手数料が中央値で6.7％増加したと報告しており、監査、保証、税務サービス、およびクライアント会計アドバイザリーの成長が見られました。パートナー1人当たりの純残余は、会計年度2022年から会計年度2024年にかけて11.9％増加し、252,663ドルに達しました。</p><p>この調査では、AIの導入に対する関心も高まっていることがわかりましたが、ほとんどの企業はまだ正式な予算を割り当てたり、構造化されたトレーニングプログラムを開発したりしていません。調査によると、継続的な導入はサービスの拡大と継続的な成長を促進するのに役立つ可能性があります。</p><h2><b>会計士は、機密性の高いクライアントデータを信頼できないAIツールを採用しない</b></h2><p>AIが会計で成功するためには、データセキュリティの高い基準を満たす必要があります。会計事務所は、経済において最も機密性の高い財務情報を扱います。実務者は、コンプライアンスまたは機密保持のリスクを生み出すツールを採用することはできません。</p><p><a href=\"https://www.avalara.com/us/en/learn/ai-reinventing-finance-and-tax-state-of-finance-report.html\">Avalaraの調査</a>によると、回答者の63％が、データセキュリティとプライバシーの懸念を、税務および財務機能の自動化に対する最大の障壁として挙げています。この懸念は、最初の選択から実装、継続的な使用まで、採用ライフサイクル全体にわたって残ります。</p><p><a href=\"https://marble.ai/\">Marble</a>は、セキュリティを基本的な優先事項としてきました。同社は、製品をリリースする前にソフトウェアコンプライアンス認証を取得し、データプライバシーが初日から運用文化に組み込まれていることを主張しています。</p><p>「セキュリティは、私たちが構築しているものの中心にあります」とShahは述べています。「すべての従業員が、セキュリティが重要であることを知っています。それは私たちのオンボーディングの一部であり、私たちが行うすべてのことにおいて考慮するものです。」</p><h2><b>数字を処理する人から戦略アドバイザーへ：AIは会計のキャリアをどのように再構築できるか</b></h2><p>Marbleの創設者は、AIが会計の仕事を奪うだけだという話を否定します。彼らは代わりに、AIは会計の仕事をより戦略的にし、反復的な実行によって特徴付けられなくなるだろうと提案しています。</p><p>彼らは建築のアナロジーを引き合いに出し、コンピュータ支援設計が骨の折れる手作業による製図に取って代わりました。建築家は姿を消しませんでした。彼らは、創造的なデザインにより多くの時間を費やし、機械的な複製に費やす時間を減らすことができるツールを手に入れたのです。</p><p>「ジュニアまたは中級会計士であることの、時間集約的で創造性の低い作業の一部を取り除き、それを、創造的でアイデアを統合し、多くのタスクをAIアシスタントプラットフォームソリューションに委任できる専門家としての役割に置き換える場合、最終的には業界はより楽しく運営できるようになります」とKonradは述べています。</p><p>この変化は、クライアントの結果も改善する可能性があります。会計士がコンプライアンスに費やす時間を減らすと、クライアントが重視する戦略的なアドバイザリー業務により多くの投資をすることができます。</p><p>「何に焦点を当てることができるかによって、仕事がより楽しくなるだけでなく、クライアントがあなたからより高く評価するものにもなります」とShahは述べています。</p><h2><b>競争環境：Marbleは資金力のあるライバルと従来の巨人に対峙する</b></h2><p><a href=\"http://marble.ai/\">Marble</a>は、手ごわい既成勢力と資金力のある競争相手がいる市場に参入します。グローバルな税務調査プラットフォームである<a href=\"https://venturebeat.com/ai/how-ai-tax-startup-blue-j-torched-its-entire-business-model-for-chatgpt-and\">BlueJ</a>は、1億ドル以上を調達しました。<a href=\"https://www.thomsonreuters.com/en\">Thomson Reuters</a>、<a href=\"https://www.cch.com/\">CCH</a>、および<a href=\"https://www.intuit.com/\">Intuit</a>は、数十年にわたって構築された深い顧客関係を持っています。</p><p>しかし、創設者は移行期に機会を見出しています。</p><p>「AIは業界で何が可能かを変えました」とShahは述べています。「業界の一部のテクノロジープレーヤーと協力して統合すると同時に、AIを搭載した新製品で他のプレーヤーと競争します。場合によっては、物事を行うための既存のテクノロジーソリューションを忘れ、タスク自体に戻ります。私たちはまったく新しい技術的機能を持っています。人間と協力してタスクを完了するものを、空白のキャンバスからどのように設計しますか？」</p><p>無料の調査ツールを提供するという決定は、Marbleの市場参入の哲学を反映しています。有料の壁なしに実務者がアクセスできるようにすることで、同社は信頼を築き、能力を実証することを目指しています。</p><p>「AIの使用方法を心配している人や、AIの採用方法に疑問を持っている人に、目的に合わせて構築された本当に魅力的な製品を公開することができます。ワークフローへの統合方法がわからない場合に、費用がかかりすぎるものを購入することを考える必要はありません」とShahは述べています。</p><h2><b>2500億ドルの疑問：スタートアップはアメリカの税金の仕組みを変えることができるか？</b></h2><p>Marbleのロードマップは調査にとどまりません。同社は、複雑な税務シナリオを分析し、コンプライアンスの問題を特定し、最終的にはコンプライアンスワークフローの重要な部分を自動化できるAIエージェントを開発する予定です。すべては実務者の管理下にとどまります。</p><p>創設者は、成功を混乱という観点ではなく、リバランスという観点から捉えています。今日の税務業務はコンプライアンスに大きく偏っており、クライアントが切望し、より高い利益を生み出す戦略的なアドバイザリーサービスは、恒久的に行われていません。Marbleの賭けは、AIがその方程式を覆すことができるということです。</p><p>「誰もがコンプライアンスがよりシンプルに行われるようにし、戦略と計画について話し合う時間を費やしたいと考えています」とKonradは述べています。「コンプライアンス対戦略と計画のブレンドを、戦略と計画を最初にし、コンプライアンスを劇的に簡素化されたものにするにはどうすればよいでしょうか？」</p><p>Marbleがそのビジョンを実行できるかどうかは、まだわかりません。同社は、根強い競合他社、歴史的に技術革新に抵抗してきた業界、そして高リスクの金融業務のためにAIシステムを構築することに伴う固有の予測不可能性に直面しています。</p><p>しかし、創設者は、業界の人口動態の変化が、以前のテクノロジーの波ではできなかった方法で採用を加速させると確信しています。毎年、業界に参入する会計士が減少し、クライアントの要求が高まるばかりであるため、企業は残りのスタッフがより多くのことを行えるようにするツールを受け入れる意欲が高まる可能性があります。</p><p>「AIはすべての業界を変えるでしょう。ビジネスモデルを支援する形で変えることもあれば、ビジネスモデルに挑戦する形で変えることもあります。AIは最終的に会計事務所のビジネスをより良く、より収益性の高いものにし、同時にエンドクライアントはより良いサービスをより良い価格で得られるようになると信じています」とShahは述べています。</p><p>会計業界は、その方程式のどちら側に着地するかを知ろうとしているようです。</p>",
    "insightJa": "この記事のAI税務ツールは、税理士の業務効率化だけでなく、中小企業の税務コスト削減にも貢献する可能性があります。今後は、AIが税務申告の自動化を進め、企業経営の意思決定を支援することが期待されます。",
    "recommendedBooks": [
      "AI 税務",
      "会計 自動化",
      "税理士 AI"
    ],
    "tags": [
      "AI",
      "Tax",
      "Accounting",
      "Marble",
      "Automation"
    ],
    "imageUrl": "https://picsum.photos/seed/1729/400/300"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "title": "New research reveals how everyday cues secretly shape your habits",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210223635.htm",
    "summary": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "publishedAt": "Wed, 10 Dec 2025 22:41:05 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers uncovered how shifting levels of a brain protein called KCC2 can reshape the way cues become linked with rewards, sometimes making habits form more quickly or more powerfully than expected. When this protein drops, dopamine neurons fire more intensely, strengthening new associations in ways that resemble how addictive behaviors take hold. Rat studies showed that even brief, synchronized bursts of neural activity can amplify reward learning, offering insight into why everyday triggers, like a morning routine, can provoke strong cravings.",
    "titleJa": "日常の合図がどのように習慣を秘密裏に形成するのかを解明する新たな研究",
    "summaryJa": "脳タンパク質KCC2のレベル変化が報酬と合図の結びつきを再形成し、習慣形成を促進。ドーパミン神経の活動が強まり、中毒性行動に似た形で新たな関連性を強化。",
    "explanationJa": "日常の何気ないきっかけが、脳のタンパク質の働きを通じて、思った以上に強い習慣を作り上げている可能性があるのです。",
    "translationJa": "研究者たちは、KCC2と呼ばれる脳タンパク質のレベルの変化が、合図が報酬と結びつく方法を再形成し、時に予想以上に速く、または強く習慣が形成されることを明らかにしました。このタンパク質が減少すると、ドーパミン神経はより強く発火し、中毒性行動が生じるのと似た方法で、新しい関連性を強化します。ラットの研究では、短い時間だけ同期した神経活動のバーストでさえ、報酬学習を増幅させることが示されており、朝のルーティンのような日常的なトリガーが強い欲求を引き起こす理由への洞察が得られました。",
    "insightJa": "この研究から、無意識のうちに行っている行動の背後にあるメカニズムが理解できます。習慣化を促進したい場合は、特定の合図と報酬を意識的に結びつけることで、より効果的に目標を達成できるかもしれません。",
    "recommendedBooks": [
      "習慣の力",
      "脳科学 行動経済学",
      "ドーパミン 報酬系"
    ],
    "tags": [
      "habit formation",
      "KCC2",
      "dopamine",
      "reward learning",
      "習慣形成"
    ],
    "imageUrl": "https://picsum.photos/seed/5067/400/300"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "title": "Blood tests reveal obesity rapidly accelerates Alzheimer’s progression",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251210092019.htm",
    "summary": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "publishedAt": "Wed, 10 Dec 2025 12:23:51 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Obesity accelerates the rise of Alzheimer’s-related blood biomarkers far more rapidly than previously recognized. Long-term imaging and plasma data show that obese individuals experience much faster increases in proteins linked to neurodegeneration and amyloid buildup. Surprisingly, blood tests detected these changes earlier than PET scans. The results point to obesity as a major, modifiable contributor to Alzheimer’s progression.",
    "titleJa": "血液検査で判明：肥満がアルツハイマー病の進行を加速",
    "summaryJa": "肥満者はアルツハイマー病関連の血液バイオマーカーの上昇が、従来考えられていたよりも急速に進行。PETスキャンよりも早く血液検査で変化を検出。肥満が主要な修正可能な要因。",
    "explanationJa": "血液検査の結果、肥満はアルツハイマー病の進行を早める可能性があることがわかりました。",
    "translationJa": "肥満は、アルツハイマー病に関連する血液バイオマーカーの上昇を、これまで認識されていたよりもはるかに急速に加速させます。長期的な画像データと血漿データは、肥満者が神経変性およびアミロイド蓄積に関連するタンパク質の増加をより速く経験することを示しています。驚くべきことに、血液検査はPETスキャンよりも早くこれらの変化を検出しました。これらの結果は、肥満がアルツハイマー病の進行に対する主要な、修正可能な要因であることを示唆しています。",
    "insightJa": "この研究結果は、肥満予防がアルツハイマー病のリスク低減に重要であることを示唆しています。健康的な食生活と適度な運動習慣を維持することで、将来的な認知症リスクを軽減できる可能性があります。",
    "recommendedBooks": [
      "アルツハイマー病 予防",
      "肥満 健康リスク",
      "脳の健康 食事"
    ],
    "tags": [
      "Alzheimer's disease",
      "Obesity",
      "Blood biomarkers",
      "アルツハイマー病",
      "肥満"
    ],
    "imageUrl": "https://picsum.photos/seed/5067/400/300"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "title": "Rising temperatures are slowing early childhood development",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234247.htm",
    "summary": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "publishedAt": "Wed, 10 Dec 2025 00:59:03 EST",
    "author": "",
    "category": "Science",
    "originalContent": "Researchers discovered that unusually high temperatures can hinder early childhood development. Children living in hotter conditions were less likely to reach key learning milestones, especially in reading and basic math skills. Those facing economic hardship or limited resources were hit the hardest. The study underscores how climate change may shape children’s learning long before they reach school age.",
    "titleJa": "気温上昇が幼児の発達を遅らせる",
    "summaryJa": "研究によると、異常な高温は幼児の発達を阻害し、特に読み書きや算数の基礎能力の発達を遅らせる可能性があります。経済的に困窮している子供ほど影響を受けやすいことが示唆されています。",
    "explanationJa": "気温の上昇は、子供たちの学習能力に悪影響を与える可能性があることがわかりました。",
    "translationJa": "研究者たちは、異常に高い気温が幼児期の発達を妨げる可能性があることを発見しました。高温の環境で暮らす子供たちは、特に読み書きや算数の基礎能力において、重要な学習の節目に到達しにくい傾向にありました。経済的な困難や限られた資源に直面している子供たちは、最も大きな打撃を受けました。この研究は、気候変動が子供たちが学校に通うずっと前から、彼らの学習に影響を与える可能性があることを強調しています。",
    "insightJa": "地球温暖化は子供たちの成長にも影響を与えることがわかりました。企業は、環境負荷低減への取り組みを強化するとともに、子供たちの教育を支援するプログラムへの投資も検討する必要があるかもしれません。",
    "recommendedBooks": [
      "幼児教育 環境",
      "気候変動 子育て",
      "発達心理学"
    ],
    "tags": [
      "climate change",
      "early childhood development",
      "temperature",
      "learning",
      "教育",
      "気候変動",
      "幼児教育"
    ],
    "imageUrl": "https://picsum.photos/seed/5076/400/300"
  },
  {
    "id": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "title": "Scientists reveal a tiny brain chip that streams thoughts in real time",
    "source": "rss",
    "url": "https://www.sciencedaily.com/releases/2025/12/251209234139.htm",
    "summary": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "publishedAt": "Tue, 09 Dec 2025 23:54:39 EST",
    "author": "",
    "category": "Science",
    "originalContent": "BISC is an ultra-thin neural implant that creates a high-bandwidth wireless link between the brain and computers. Its tiny single-chip design packs tens of thousands of electrodes and supports advanced AI models for decoding movement, perception, and intent. Initial clinical work shows it can be inserted through a small opening in the skull and remain stable while capturing detailed neural activity. The technology could reshape treatments for epilepsy, paralysis, and blindness.",
    "titleJa": "科学者らが思考をリアルタイムで伝送する超小型脳チップを発表",
    "summaryJa": "BISCは脳とコンピュータを高帯域無線接続する超薄型インプラント。数万の電極とAIを搭載し、運動や知覚を解読。てんかん、麻痺、失明治療を変革する可能性。",
    "explanationJa": "思考をリアルタイムでコンピュータに伝送できる、とても小さな脳チップが開発されたそうです。",
    "translationJa": "BISCは、脳とコンピュータの間に高帯域幅の無線リンクを構築する超薄型ニューラルインプラントです。その小型シングルチップ設計には数万の電極が搭載されており、運動、知覚、意図を解読するための高度なAIモデルをサポートしています。初期の臨床研究では、頭蓋骨の小さな開口部から挿入でき、詳細な神経活動を捉えながら安定した状態を維持できることが示されています。この技術は、てんかん、麻痺、失明の治療を再構築する可能性があります。",
    "insightJa": "この技術が発展すれば、障がいを持つ方の生活の質を大幅に向上させる可能性があります。また、脳とコンピュータの連携が進むことで、新たなビジネスモデルやサービスの創出も期待されます。",
    "recommendedBooks": [
      "脳科学 入門",
      "ブレイン・マシン・インターフェース",
      "医療機器開発"
    ],
    "tags": [
      "brain chip",
      "neural implant",
      "BMI",
      "脳チップ",
      "ニューラルインプラント"
    ],
    "imageUrl": "https://picsum.photos/seed/5076/400/300"
  }
]